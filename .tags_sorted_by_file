!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_PROGRAM_VERSION	5.8	//
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
AWS_ACCESS_ID	awscrawler/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	awscrawler/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
REGION_NAME	awscrawler/awsapi/download_s3bucket.py	/^REGION_NAME = 'ap-northeast-1'$/;"	v
S3	awscrawler/awsapi/download_s3bucket.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
boto3	awscrawler/awsapi/download_s3bucket.py	/^import boto3$/;"	i
bucketname	awscrawler/awsapi/download_s3bucket.py	/^    bucketname = 'fudankg-json'$/;"	v
compare_time	awscrawler/awsapi/download_s3bucket.py	/^    compare_time = datetime(2016,7,1,2,0,0,).strftime('%Y%m%d%H%M%S') $/;"	v
count_bucket	awscrawler/awsapi/download_s3bucket.py	/^def count_bucket(bucketname):$/;"	f
datetime	awscrawler/awsapi/download_s3bucket.py	/^from datetime import datetime$/;"	i
delete_bucket	awscrawler/awsapi/download_s3bucket.py	/^def delete_bucket(bucketname):$/;"	f
division	awscrawler/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
down_fudankg	awscrawler/awsapi/download_s3bucket.py	/^def down_fudankg(bucketname):$/;"	f
empty_bucket	awscrawler/awsapi/download_s3bucket.py	/^def empty_bucket(bucketname, compare_time=None):$/;"	f
os	awscrawler/awsapi/download_s3bucket.py	/^import os$/;"	i
print_function	awscrawler/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
save_to_local	awscrawler/awsapi/download_s3bucket.py	/^def save_to_local(bucketname):$/;"	f
AWS_ACCESS_ID	awscrawler/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	awscrawler/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
Ec2Manager	awscrawler/awsapi/ec2manager.py	/^class Ec2Manager(object):$/;"	c
__init__	awscrawler/awsapi/ec2manager.py	/^    def __init__(self, region_name, tag='crawler', amiid=None):$/;"	m	class:Ec2Manager
boto3	awscrawler/awsapi/ec2manager.py	/^import boto3$/;"	i
config	awscrawler/awsapi/ec2manager.py	/^    config = {$/;"	v	class:Ec2Manager
create_instances	awscrawler/awsapi/ec2manager.py	/^    def create_instances(self, MachineNum=1):$/;"	m	class:Ec2Manager
deque	awscrawler/awsapi/ec2manager.py	/^from collections import deque$/;"	i
division	awscrawler/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
get_ids_in_status	awscrawler/awsapi/ec2manager.py	/^    def get_ids_in_status(self, status):$/;"	m	class:Ec2Manager
get_idx_by_id	awscrawler/awsapi/ec2manager.py	/^    def get_idx_by_id(self, one_id):$/;"	m	class:Ec2Manager
get_ipaddr	awscrawler/awsapi/ec2manager.py	/^    def get_ipaddr(self, one_id):$/;"	m	class:Ec2Manager
get_keypair	awscrawler/awsapi/ec2manager.py	/^    def get_keypair(self):$/;"	m	class:Ec2Manager
print_function	awscrawler/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
start	awscrawler/awsapi/ec2manager.py	/^    def start(self, ids):$/;"	m	class:Ec2Manager
stop	awscrawler/awsapi/ec2manager.py	/^    def stop(self, ids):$/;"	m	class:Ec2Manager
stop_and_start	awscrawler/awsapi/ec2manager.py	/^    def stop_and_start(self, group_num):$/;"	m	class:Ec2Manager
stop_one_and_restart	awscrawler/awsapi/ec2manager.py	/^    def stop_one_and_restart(self):$/;"	m	class:Ec2Manager
terminate	awscrawler/awsapi/ec2manager.py	/^    def terminate(self, ids):$/;"	m	class:Ec2Manager
time	awscrawler/awsapi/ec2manager.py	/^import time$/;"	i
AWS_ACCESS_ID	awscrawler/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	awscrawler/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
S3Object	awscrawler/awsapi/s3object.py	/^class S3Object(object):$/;"	c
__init__	awscrawler/awsapi/s3object.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:S3Object
boto3	awscrawler/awsapi/s3object.py	/^import boto3$/;"	i
botocore	awscrawler/awsapi/s3object.py	/^import botocore$/;"	i
create_bucket	awscrawler/awsapi/s3object.py	/^    def create_bucket(self):$/;"	m	class:S3Object
division	awscrawler/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
get_cache	awscrawler/awsapi/s3object.py	/^    def get_cache(self, filename):$/;"	m	class:S3Object
hashlib	awscrawler/awsapi/s3object.py	/^import hashlib$/;"	i
head_cache	awscrawler/awsapi/s3object.py	/^    def head_cache(self, filename):$/;"	m	class:S3Object
print_function	awscrawler/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
put_cache	awscrawler/awsapi/s3object.py	/^    def put_cache(self, filename, content):$/;"	m	class:S3Object
CACHE_REDIS	awscrawler/awscrawler.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
MANAGER	awscrawler/awscrawler.py	/^MANAGER = RedisManager(RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS)$/;"	v
QUEUE_REDIS	awscrawler/awscrawler.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
RECORD_REDIS	awscrawler/awscrawler.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
RedisManager	awscrawler/awscrawler.py	/^from rediscluster.redismanager import RedisManager$/;"	i
delete_distributed_queue	awscrawler/awscrawler.py	/^def delete_distributed_queue(greenlet):$/;"	f
division	awscrawler/awscrawler.py	/^from __future__ import print_function, division$/;"	i
gevent	awscrawler/awscrawler.py	/^import gevent$/;"	i
hashlib	awscrawler/awscrawler.py	/^import hashlib$/;"	i
json	awscrawler/awscrawler.py	/^import json$/;"	i
main	awscrawler/awscrawler.py	/^def main():$/;"	f
monkey	awscrawler/awscrawler.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
patch_all	awscrawler/awscrawler.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
post_job	awscrawler/awscrawler.py	/^def post_job(batch_id, method, gap, js, total_count, urls_func=None, priority=1, queue_timeout=10, failure_times=3, start_delay=0):$/;"	f
print_function	awscrawler/awscrawler.py	/^from __future__ import print_function, division$/;"	i
division	awscrawler/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
filename_in_logger_out	awscrawler/crawlerlog/cachelog.py	/^    def filename_in_logger_out(the_batch_id, cachedir):$/;"	f	function:get_logger
get_logger	awscrawler/crawlerlog/cachelog.py	/^def get_logger(batch_id, today_str, cachedir='.'):$/;"	f
ip	awscrawler/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
log	awscrawler/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
logging	awscrawler/crawlerlog/cachelog.py	/^import logging$/;"	i
os	awscrawler/crawlerlog/cachelog.py	/^import os$/;"	i
path	awscrawler/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
print_function	awscrawler/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
division	awscrawler/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
get_local_ip_address	awscrawler/crawlerlog/ip.py	/^def get_local_ip_address():$/;"	f
print_function	awscrawler/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
socket	awscrawler/crawlerlog/ip.py	/^import socket$/;"	i
handlers	awscrawler/crawlerlog/log.py	/^    import logging.handlers$/;"	i
init	awscrawler/crawlerlog/log.py	/^def init(log_name, log_file, level=logging.DEBUG, size=1024*1024, count=10):$/;"	f
log_print	awscrawler/crawlerlog/log.py	/^def log_print(msg, logger=None, level=logging.ERROR):$/;"	f
log_traceback	awscrawler/crawlerlog/log.py	/^def log_traceback(logger=None, msg=None):$/;"	f
logging	awscrawler/crawlerlog/log.py	/^    import logging.handlers$/;"	i
logging	awscrawler/crawlerlog/log.py	/^import logging$/;"	i
sys	awscrawler/crawlerlog/log.py	/^    import sys, traceback$/;"	i
traceback	awscrawler/crawlerlog/log.py	/^    import sys, traceback$/;"	i
division	awscrawler/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
makedir	awscrawler/crawlerlog/path.py	/^def makedir(absdir):$/;"	f
os	awscrawler/crawlerlog/path.py	/^import os$/;"	i
print_function	awscrawler/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
Cache	awscrawler/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	awscrawler/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	awscrawler/downloader/cache.py	/^import base64$/;"	i
division	awscrawler/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	awscrawler/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	awscrawler/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	awscrawler/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	awscrawler/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/downloader/cache.py	/^import requests$/;"	i
urlparse	awscrawler/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	awscrawler/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	awscrawler/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	awscrawler/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	awscrawler/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	awscrawler/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	awscrawler/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	awscrawler/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	awscrawler/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	awscrawler/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	awscrawler/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	awscrawler/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	awscrawler/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	awscrawler/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	awscrawler/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	awscrawler/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	awscrawler/downloader/caches3.py	/^import hashlib$/;"	i
post	awscrawler/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	awscrawler/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	awscrawler/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	awscrawler/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	awscrawler/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	awscrawler/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	awscrawler/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	awscrawler/downloader/downloader.py	/^            import chardet$/;"	i
close	awscrawler/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	awscrawler/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	awscrawler/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	awscrawler/downloader/downloader.py	/^import os$/;"	i
print_function	awscrawler/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/downloader/downloader.py	/^import re$/;"	i
request_download	awscrawler/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	awscrawler/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	awscrawler/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	awscrawler/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	awscrawler/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	awscrawler/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	awscrawler/downloader/downloader.py	/^import sys$/;"	i
time	awscrawler/downloader/downloader.py	/^import time$/;"	i
update_header	awscrawler/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	awscrawler/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	awscrawler/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	awscrawler/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	awscrawler/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	awscrawler/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	awscrawler/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	awscrawler/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	awscrawler/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	awscrawler/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	awscrawler/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	awscrawler/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	awscrawler/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	awscrawler/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	awscrawler/downloader/test_cacheperiod.py	/^import json$/;"	i
main	awscrawler/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	awscrawler/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	awscrawler/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	awscrawler/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	awscrawler/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	awscrawler/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	awscrawler/downloader/test_download.py	/^    import chardet$/;"	i
codecs	awscrawler/downloader/test_download.py	/^import codecs$/;"	i
collections	awscrawler/downloader/test_download.py	/^import collections$/;"	i
datetime	awscrawler/downloader/test_download.py	/^import datetime$/;"	i
json	awscrawler/downloader/test_download.py	/^import json$/;"	i
main	awscrawler/downloader/test_download.py	/^def main():$/;"	f
os	awscrawler/downloader/test_download.py	/^import os$/;"	i
re	awscrawler/downloader/test_download.py	/^import re$/;"	i
requests	awscrawler/downloader/test_download.py	/^    import requests$/;"	i
sys	awscrawler/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	awscrawler/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	awscrawler/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	awscrawler/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	awscrawler/downloader/test_download.py	/^import time$/;"	i
urllib	awscrawler/downloader/test_download.py	/^import urllib$/;"	i
DEPLOY_ENV	awscrawler/fabfile.py	/^DEPLOY_ENV = 'PRODUCTION'$/;"	v
_aws	awscrawler/fabfile.py	/^def _aws():$/;"	f
build_env	awscrawler/fabfile.py	/^def build_env():$/;"	f
debug	awscrawler/fabfile.py	/^def debug(host):$/;"	f
deploy_run	awscrawler/fabfile.py	/^def deploy_run(param):$/;"	f
deploy_worker	awscrawler/fabfile.py	/^def deploy_worker():$/;"	f
division	awscrawler/fabfile.py	/^from __future__ import print_function, division$/;"	i
kill	awscrawler/fabfile.py	/^def kill():$/;"	f
print_function	awscrawler/fabfile.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/fabfile.py	/^import re$/;"	i
runapp	awscrawler/fabfile.py	/^def runapp(flag_run, job, param=None):$/;"	f
sync_download	awscrawler/fabfile.py	/^def sync_download():$/;"	f
sync_upload	awscrawler/fabfile.py	/^def sync_upload():$/;"	f
upload	awscrawler/fabfile.py	/^def upload():$/;"	f
CACHE_REDIS	awscrawler/failed/fudankg_failed.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
CacheS3	awscrawler/failed/fudankg_failed.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/failed/fudankg_failed.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/failed/fudankg_failed.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
QUEUE_REDIS	awscrawler/failed/fudankg_failed.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
Queue	awscrawler/failed/fudankg_failed.py	/^from rediscluster.queues import Queue$/;"	i
RECORD_REDIS	awscrawler/failed/fudankg_failed.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
REGION_NAME	awscrawler/failed/fudankg_failed.py	/^from settings import REGION_NAME$/;"	i
RedisPool	awscrawler/failed/fudankg_failed.py	/^from rediscluster.redispool import RedisPool$/;"	i
SITE	awscrawler/failed/fudankg_failed.py	/^SITE = 'https:\/\/crl.ptopenlab.com:8800'$/;"	v
batch_id	awscrawler/failed/fudankg_failed.py	/^batch_id = 'fudankg-20160625'$/;"	v
division	awscrawler/failed/fudankg_failed.py	/^from __future__ import print_function, division$/;"	i
json	awscrawler/failed/fudankg_failed.py	/^import json$/;"	i
print_function	awscrawler/failed/fudankg_failed.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/failed/fudankg_failed.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/failed/fudankg_failed.py	/^import re$/;"	i
redispool	awscrawler/failed/fudankg_failed.py	/^redispool = RedisPool.instance(RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS)$/;"	v
run	awscrawler/failed/fudankg_failed.py	/^def run():$/;"	f
time	awscrawler/failed/fudankg_failed.py	/^import time$/;"	i
until_true	awscrawler/failed/fudankg_failed.py	/^def until_true(url):$/;"	f
urllib	awscrawler/failed/fudankg_failed.py	/^import urllib$/;"	i
urlparse	awscrawler/failed/fudankg_failed.py	/^import urlparse$/;"	i
DATA_DIR	awscrawler/failed/fudankg_missing.py	/^DATA_DIR = '\/data\/fudankg_saved'$/;"	v
division	awscrawler/failed/fudankg_missing.py	/^from __future__ import print_function, division$/;"	i
extract_entities	awscrawler/failed/fudankg_missing.py	/^def extract_entities():$/;"	f
json	awscrawler/failed/fudankg_missing.py	/^import json$/;"	i
os	awscrawler/failed/fudankg_missing.py	/^import os$/;"	i
print_function	awscrawler/failed/fudankg_missing.py	/^from __future__ import print_function, division$/;"	i
CACHE_REDIS	awscrawler/failed/get_failed_url.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
QUEUE_REDIS	awscrawler/failed/get_failed_url.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
Queue	awscrawler/failed/get_failed_url.py	/^from rediscluster.queues import Queue$/;"	i
RECORD_REDIS	awscrawler/failed/get_failed_url.py	/^from settings import QUEUE_REDIS, RECORD_REDIS, CACHE_REDIS$/;"	i
REGION_NAME	awscrawler/failed/get_failed_url.py	/^from settings import REGION_NAME$/;"	i
RedisPool	awscrawler/failed/get_failed_url.py	/^from rediscluster.redispool import RedisPool$/;"	i
batch_id	awscrawler/failed/get_failed_url.py	/^batch_id = 'searchzhidao2-20160728'$/;"	v
division	awscrawler/failed/get_failed_url.py	/^from __future__ import print_function, division$/;"	i
get_failed_url	awscrawler/failed/get_failed_url.py	/^def get_failed_url():$/;"	f
json	awscrawler/failed/get_failed_url.py	/^import json$/;"	i
print_function	awscrawler/failed/get_failed_url.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/failed/get_failed_url.py	/^import re$/;"	i
redispool	awscrawler/failed/get_failed_url.py	/^redispool = RedisPool.instance(RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS)$/;"	v
time	awscrawler/failed/get_failed_url.py	/^import time$/;"	i
urllib	awscrawler/failed/get_failed_url.py	/^import urllib$/;"	i
urlparse	awscrawler/failed/get_failed_url.py	/^import urlparse$/;"	i
cleansing	awscrawler/invoker/hcrawler_schedule.py	/^def cleansing():$/;"	f
datetime	awscrawler/invoker/hcrawler_schedule.py	/^from datetime import datetime$/;"	i
division	awscrawler/invoker/hcrawler_schedule.py	/^from __future__ import print_function, division$/;"	i
get_hcrawler_conf_dir	awscrawler/invoker/hcrawler_schedule.py	/^def get_hcrawler_conf_dir():$/;"	f
insert_to_es	awscrawler/invoker/hcrawler_schedule.py	/^def insert_to_es():$/;"	f
json	awscrawler/invoker/hcrawler_schedule.py	/^import json$/;"	i
main	awscrawler/invoker/hcrawler_schedule.py	/^def main():$/;"	f
multiprocessing	awscrawler/invoker/hcrawler_schedule.py	/^import multiprocessing$/;"	i
os	awscrawler/invoker/hcrawler_schedule.py	/^import os$/;"	i
print_function	awscrawler/invoker/hcrawler_schedule.py	/^from __future__ import print_function, division$/;"	i
run	awscrawler/invoker/hcrawler_schedule.py	/^from multitask import run$/;"	i
run_crawler	awscrawler/invoker/hcrawler_schedule.py	/^def run_crawler(config_file):$/;"	f
split_crawl_jobs	awscrawler/invoker/hcrawler_schedule.py	/^def split_crawl_jobs():$/;"	f
time	awscrawler/invoker/hcrawler_schedule.py	/^import time$/;"	i
Queue	awscrawler/invoker/multitask.py	/^from rediscluster.queues import Queue$/;"	i
Schedule	awscrawler/invoker/multitask.py	/^from schedule import Schedule$/;"	i
VERSION	awscrawler/invoker/multitask.py	/^VERSION ='v20160620'$/;"	v
catch_terminate_instances_signal	awscrawler/invoker/multitask.py	/^def catch_terminate_instances_signal(schedule):$/;"	f
config_all	awscrawler/invoker/multitask.py	/^        config_all = json.load(f)$/;"	v
config_index	awscrawler/invoker/multitask.py	/^    config_index = sys.argv[2]$/;"	v
datetime	awscrawler/invoker/multitask.py	/^import datetime$/;"	i
delete_distributed_queue	awscrawler/invoker/multitask.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
division	awscrawler/invoker/multitask.py	/^from __future__ import print_function, division$/;"	i
filename_config	awscrawler/invoker/multitask.py	/^    filename_config = getTheFile("..\/config_prefetch\/" + sys.argv[1])$/;"	v
getTheFile	awscrawler/invoker/multitask.py	/^def getTheFile(filename):$/;"	f
get_failed_url	awscrawler/invoker/multitask.py	/^def get_failed_url(batch_id):$/;"	f
get_urls_length	awscrawler/invoker/multitask.py	/^def get_urls_length(fname):$/;"	f
gevent	awscrawler/invoker/multitask.py	/^import gevent$/;"	i
itemgetter	awscrawler/invoker/multitask.py	/^from operator import itemgetter$/;"	i
json	awscrawler/invoker/multitask.py	/^import json$/;"	i
load_urls	awscrawler/invoker/multitask.py	/^def load_urls(fname, partial_url=None):$/;"	f
monkey	awscrawler/invoker/multitask.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
os	awscrawler/invoker/multitask.py	/^import os$/;"	i
partial	awscrawler/invoker/multitask.py	/^from functools import partial$/;"	i
patch_all	awscrawler/invoker/multitask.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
post_job	awscrawler/invoker/multitask.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
print_function	awscrawler/invoker/multitask.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/invoker/multitask.py	/^import requests$/;"	i
run	awscrawler/invoker/multitask.py	/^def run(config):$/;"	f
signal	awscrawler/invoker/multitask.py	/^import signal$/;"	i
slack	awscrawler/invoker/multitask.py	/^def slack(msg):$/;"	f
sys	awscrawler/invoker/multitask.py	/^import sys$/;"	i
time	awscrawler/invoker/multitask.py	/^import time$/;"	i
urllib	awscrawler/invoker/multitask.py	/^    import urllib$/;"	i
Schedule	awscrawler/invoker/prefetch_tool.py	/^from schedule import Schedule$/;"	i
VERSION	awscrawler/invoker/prefetch_tool.py	/^VERSION ='v20160620'$/;"	v
catch_terminate_instances_signal	awscrawler/invoker/prefetch_tool.py	/^def catch_terminate_instances_signal(schedule):$/;"	f
config_all	awscrawler/invoker/prefetch_tool.py	/^        config_all = json.load(f)$/;"	v
config_index	awscrawler/invoker/prefetch_tool.py	/^    config_index = sys.argv[2]$/;"	v
datetime	awscrawler/invoker/prefetch_tool.py	/^import datetime$/;"	i
delete_distributed_queue	awscrawler/invoker/prefetch_tool.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
division	awscrawler/invoker/prefetch_tool.py	/^from __future__ import print_function, division$/;"	i
filename_config	awscrawler/invoker/prefetch_tool.py	/^    filename_config = getTheFile("..\/config_prefetch\/" + sys.argv[1])$/;"	v
getTheFile	awscrawler/invoker/prefetch_tool.py	/^def getTheFile(filename):$/;"	f
get_urls_length	awscrawler/invoker/prefetch_tool.py	/^def get_urls_length(fname):$/;"	f
gevent	awscrawler/invoker/prefetch_tool.py	/^import gevent$/;"	i
itemgetter	awscrawler/invoker/prefetch_tool.py	/^from operator import itemgetter$/;"	i
json	awscrawler/invoker/prefetch_tool.py	/^import json$/;"	i
load_urls	awscrawler/invoker/prefetch_tool.py	/^def load_urls(fname, partial_url=None):$/;"	f
monkey	awscrawler/invoker/prefetch_tool.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
os	awscrawler/invoker/prefetch_tool.py	/^import os$/;"	i
partial	awscrawler/invoker/prefetch_tool.py	/^from functools import partial$/;"	i
patch_all	awscrawler/invoker/prefetch_tool.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
post_job	awscrawler/invoker/prefetch_tool.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
print_function	awscrawler/invoker/prefetch_tool.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/invoker/prefetch_tool.py	/^import requests$/;"	i
run	awscrawler/invoker/prefetch_tool.py	/^def run(config):$/;"	f
signal	awscrawler/invoker/prefetch_tool.py	/^import signal$/;"	i
slack	awscrawler/invoker/prefetch_tool.py	/^def slack(msg):$/;"	f
sys	awscrawler/invoker/prefetch_tool.py	/^import sys$/;"	i
time	awscrawler/invoker/prefetch_tool.py	/^import time$/;"	i
urllib	awscrawler/invoker/prefetch_tool.py	/^    import urllib$/;"	i
Schedule	awscrawler/invoker/prefetch_zhidao_search.py	/^from schedule import Schedule$/;"	i
THE_CONFIG	awscrawler/invoker/prefetch_zhidao_search.py	/^THE_CONFIG = {$/;"	v
datetime	awscrawler/invoker/prefetch_zhidao_search.py	/^import datetime$/;"	i
delete_distributed_queue	awscrawler/invoker/prefetch_zhidao_search.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
division	awscrawler/invoker/prefetch_zhidao_search.py	/^from __future__ import print_function, division$/;"	i
getTheFile	awscrawler/invoker/prefetch_zhidao_search.py	/^def getTheFile(filename):$/;"	f
gevent	awscrawler/invoker/prefetch_zhidao_search.py	/^import gevent$/;"	i
json	awscrawler/invoker/prefetch_zhidao_search.py	/^import json$/;"	i
load_urls	awscrawler/invoker/prefetch_zhidao_search.py	/^def load_urls(fname):$/;"	f
monkey	awscrawler/invoker/prefetch_zhidao_search.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
os	awscrawler/invoker/prefetch_zhidao_search.py	/^import os$/;"	i
patch_all	awscrawler/invoker/prefetch_zhidao_search.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
post_job	awscrawler/invoker/prefetch_zhidao_search.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
print_function	awscrawler/invoker/prefetch_zhidao_search.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/invoker/prefetch_zhidao_search.py	/^import requests$/;"	i
run	awscrawler/invoker/prefetch_zhidao_search.py	/^def run(config):$/;"	f
slack	awscrawler/invoker/prefetch_zhidao_search.py	/^def slack(msg):$/;"	f
sys	awscrawler/invoker/prefetch_zhidao_search.py	/^import sys$/;"	i
time	awscrawler/invoker/prefetch_zhidao_search.py	/^import time$/;"	i
getTheFile	awscrawler/invoker/test_prefetch.py	/^def getTheFile(filename):$/;"	f
json	awscrawler/invoker/test_prefetch.py	/^import json$/;"	i
os	awscrawler/invoker/test_prefetch.py	/^import os$/;"	i
prefetch	awscrawler/invoker/test_prefetch.py	/^from  workers import prefetch$/;"	i
re	awscrawler/invoker/test_prefetch.py	/^import re$/;"	i
sys	awscrawler/invoker/test_prefetch.py	/^import sys$/;"	i
test_preftch	awscrawler/invoker/test_prefetch.py	/^def test_preftch(filename, prefetch_index):$/;"	f
BATCH_ID	awscrawler/invoker/zhidao.py	/^from invoker.zhidao_constant import BATCH_ID$/;"	i
Schedule	awscrawler/invoker/zhidao.py	/^from schedule import Schedule$/;"	i
delete_distributed_queue	awscrawler/invoker/zhidao.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
division	awscrawler/invoker/zhidao.py	/^from __future__ import print_function, division$/;"	i
gevent	awscrawler/invoker/zhidao.py	/^import gevent$/;"	i
load_urls	awscrawler/invoker/zhidao.py	/^def load_urls(fname):$/;"	f
monkey	awscrawler/invoker/zhidao.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
patch_all	awscrawler/invoker/zhidao.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
post_job	awscrawler/invoker/zhidao.py	/^from awscrawler import post_job, delete_distributed_queue$/;"	i
print_function	awscrawler/invoker/zhidao.py	/^from __future__ import print_function, division$/;"	i
run_zhidao	awscrawler/invoker/zhidao.py	/^def run_zhidao():$/;"	f
time	awscrawler/invoker/zhidao.py	/^import time$/;"	i
BATCH_ID	awscrawler/invoker/zhidao_constant.py	/^BATCH_ID = {$/;"	v
division	awscrawler/invoker/zhidao_constant.py	/^from __future__ import print_function, division$/;"	i
print_function	awscrawler/invoker/zhidao_constant.py	/^from __future__ import print_function, division$/;"	i
Downloader	awscrawler/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	awscrawler/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	awscrawler/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	awscrawler/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	awscrawler/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	awscrawler/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	awscrawler/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	awscrawler/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	awscrawler/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	awscrawler/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	awscrawler/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	awscrawler/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	awscrawler/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	awscrawler/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	awscrawler/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	awscrawler/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	awscrawler/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	awscrawler/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	awscrawler/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	awscrawler/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	awscrawler/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	awscrawler/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	awscrawler/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	awscrawler/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	awscrawler/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/parsers/qichacha2.py	/^import re$/;"	i
traceback	awscrawler/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	awscrawler/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	awscrawler/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	awscrawler/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	awscrawler/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	awscrawler/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	awscrawler/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	awscrawler/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	awscrawler/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	awscrawler/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	awscrawler/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	awscrawler/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/parsers/qiparser2.py	/^import re$/;"	i
string	awscrawler/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	awscrawler/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	awscrawler/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	awscrawler/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	awscrawler/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	awscrawler/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	awscrawler/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	awscrawler/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	awscrawler/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	awscrawler/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	awscrawler/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	awscrawler/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	awscrawler/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	awscrawler/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	awscrawler/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	awscrawler/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	awscrawler/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	awscrawler/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	awscrawler/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	awscrawler/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	awscrawler/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
HashQueue	awscrawler/rediscluster/queues.py	/^class HashQueue(object):$/;"	c
Queue	awscrawler/rediscluster/queues.py	/^class Queue(object):$/;"	c
Record	awscrawler/rediscluster/queues.py	/^from record import Record$/;"	i
RedisPool	awscrawler/rediscluster/queues.py	/^from redispool import RedisPool$/;"	i
__init__	awscrawler/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:HashQueue
__init__	awscrawler/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:Queue
background_cleaning	awscrawler/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:HashQueue
background_cleaning	awscrawler/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:Queue
clean_task	awscrawler/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:HashQueue
clean_task	awscrawler/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:Queue
clear	awscrawler/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:HashQueue
clear	awscrawler/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:Queue
datetime	awscrawler/rediscluster/queues.py	/^from datetime import datetime$/;"	i
delete	awscrawler/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:HashQueue
delete	awscrawler/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:Queue
flush	awscrawler/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:HashQueue
flush	awscrawler/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:Queue
get	awscrawler/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:HashQueue
get	awscrawler/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:Queue
get_background_cleaning_status	awscrawler/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:HashQueue
get_background_cleaning_status	awscrawler/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:Queue
get_failed_fields	awscrawler/rediscluster/queues.py	/^    def get_failed_fields(self):$/;"	m	class:Queue
get_failed_times	awscrawler/rediscluster/queues.py	/^    def get_failed_times(self, field):$/;"	m	class:Queue
poll	awscrawler/rediscluster/queues.py	/^def poll(queues, timeout=None):$/;"	f
put	awscrawler/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:HashQueue
put	awscrawler/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:Queue
put_init	awscrawler/rediscluster/queues.py	/^    def put_init(self, *items):$/;"	m	class:HashQueue
qsize	awscrawler/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:HashQueue
qsize	awscrawler/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:Queue
set_failed_times_to_url	awscrawler/rediscluster/queues.py	/^    def set_failed_times_to_url(self, field, url):$/;"	m	class:Queue
task_done	awscrawler/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:HashQueue
task_done	awscrawler/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:Queue
task_start	awscrawler/rediscluster/queues.py	/^    def task_start(self, result):$/;"	m	class:Queue
task_start	awscrawler/rediscluster/queues.py	/^    def task_start(self, result, count):$/;"	m	class:HashQueue
task_start_batch	awscrawler/rediscluster/queues.py	/^    def task_start_batch(self, results):$/;"	m	class:Queue
time	awscrawler/rediscluster/queues.py	/^import time$/;"	i
Record	awscrawler/rediscluster/record.py	/^class Record(object):$/;"	c
RedisPool	awscrawler/rediscluster/record.py	/^from redispool import RedisPool$/;"	i
ResponseError	awscrawler/rediscluster/record.py	/^from redis import ResponseError$/;"	i
__init__	awscrawler/rediscluster/record.py	/^    def __init__(self):$/;"	m	class:Record
add_exception	awscrawler/rediscluster/record.py	/^    def add_exception(self, batch_id, url, error):$/;"	m	class:Record
begin	awscrawler/rediscluster/record.py	/^    def begin(self, batch_id, parameter, total, priority):$/;"	m	class:Record
connect	awscrawler/rediscluster/record.py	/^    def connect(self):$/;"	m	class:Record
datetime	awscrawler/rediscluster/record.py	/^from datetime import datetime$/;"	i
division	awscrawler/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
get_parameter	awscrawler/rediscluster/record.py	/^    def get_parameter(self, batch_id):$/;"	m	class:Record
get_priority	awscrawler/rediscluster/record.py	/^    def get_priority(self, batch_id):$/;"	m	class:Record
get_total_number	awscrawler/rediscluster/record.py	/^    def get_total_number(self, batch_id):$/;"	m	class:Record
get_unfinished_batch	awscrawler/rediscluster/record.py	/^    def get_unfinished_batch(self):$/;"	m	class:Record
if_not_finish_set	awscrawler/rediscluster/record.py	/^    def if_not_finish_set(self, batch_id):$/;"	m	class:Record
increase_failed	awscrawler/rediscluster/record.py	/^    def increase_failed(self, batch_id, count=1):$/;"	m	class:Record
increase_success	awscrawler/rediscluster/record.py	/^    def increase_success(self, batch_id, count=1):$/;"	m	class:Record
instance	awscrawler/rediscluster/record.py	/^    def instance(cls):$/;"	m	class:Record
is_finished	awscrawler/rediscluster/record.py	/^    def is_finished(self, batch_id):$/;"	m	class:Record
print_function	awscrawler/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
Queue	awscrawler/rediscluster/redismanager.py	/^from rediscluster.queues import Queue$/;"	i
Record	awscrawler/rediscluster/redismanager.py	/^from rediscluster.record import Record$/;"	i
RedisManager	awscrawler/rediscluster/redismanager.py	/^class RedisManager(object):$/;"	c
RedisPool	awscrawler/rediscluster/redismanager.py	/^from rediscluster.redispool import RedisPool$/;"	i
ThinHash	awscrawler/rediscluster/redismanager.py	/^from rediscluster.thinredis import ThinHash$/;"	i
__check_empty_queue	awscrawler/rediscluster/redismanager.py	/^    def __check_empty_queue(self, queue):$/;"	m	class:RedisManager	file:
__init__	awscrawler/rediscluster/redismanager.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisManager
delete_queue	awscrawler/rediscluster/redismanager.py	/^    def delete_queue(self, batch_id):$/;"	m	class:RedisManager
division	awscrawler/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
get_distributed_queue	awscrawler/rediscluster/redismanager.py	/^    def get_distributed_queue(self, batch_id):$/;"	m	class:RedisManager
get_queue_with_priority	awscrawler/rediscluster/redismanager.py	/^    def get_queue_with_priority(self):$/;"	m	class:RedisManager
get_status	awscrawler/rediscluster/redismanager.py	/^    def get_status(self, batch_id):$/;"	m	class:RedisManager
hashlib	awscrawler/rediscluster/redismanager.py	/^import hashlib$/;"	i
init_distributed_queue	awscrawler/rediscluster/redismanager.py	/^    def init_distributed_queue(self,$/;"	m	class:RedisManager
itemgetter	awscrawler/rediscluster/redismanager.py	/^from operator import itemgetter$/;"	i
print_function	awscrawler/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
put_url_enqueue	awscrawler/rediscluster/redismanager.py	/^    def put_url_enqueue(self, batch_id, url):$/;"	m	class:RedisManager
put_urls_enqueue	awscrawler/rediscluster/redismanager.py	/^    def put_urls_enqueue(self, batch_id, urls):$/;"	m	class:RedisManager
set_distributed_queue	awscrawler/rediscluster/redismanager.py	/^    def set_distributed_queue(self, batch_id, queue, thinhash, priority, refresh=True):$/;"	m	class:RedisManager
worker_init_distributed_queue	awscrawler/rediscluster/redismanager.py	/^    def worker_init_distributed_queue(self, batch_id, total_count):$/;"	m	class:RedisManager
CACHE_REDIS	awscrawler/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
QUEUE_REDIS	awscrawler/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Queue	awscrawler/rediscluster/redismonitor.py	/^from rediscluster.queues import Queue$/;"	i
RECORD_REDIS	awscrawler/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Record	awscrawler/rediscluster/redismonitor.py	/^from rediscluster.record import Record$/;"	i
RedisPool	awscrawler/rediscluster/redismonitor.py	/^from rediscluster.redispool import RedisPool$/;"	i
argparse	awscrawler/rediscluster/redismonitor.py	/^    import argparse$/;"	i
division	awscrawler/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
get_status	awscrawler/rediscluster/redismonitor.py	/^def get_status(batch_id):$/;"	f
init	awscrawler/rediscluster/redismonitor.py	/^def init():$/;"	f
interval	awscrawler/rediscluster/redismonitor.py	/^def interval(val, func, arg):$/;"	f
main	awscrawler/rediscluster/redismonitor.py	/^def main():$/;"	f
os	awscrawler/rediscluster/redismonitor.py	/^import os$/;"	i
parse_args	awscrawler/rediscluster/redismonitor.py	/^def parse_args():$/;"	f
print_function	awscrawler/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
sys	awscrawler/rediscluster/redismonitor.py	/^import sys$/;"	i
time	awscrawler/rediscluster/redismonitor.py	/^import time$/;"	i
RedisPool	awscrawler/rediscluster/redispool.py	/^class RedisPool(object):$/;"	c
__init__	awscrawler/rediscluster/redispool.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisPool
contextlib	awscrawler/rediscluster/redispool.py	/^import contextlib$/;"	i
division	awscrawler/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
instance	awscrawler/rediscluster/redispool.py	/^    def instance(cls, *args):$/;"	m	class:RedisPool
print_function	awscrawler/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/rediscluster/redispool.py	/^import re$/;"	i
redis	awscrawler/rediscluster/redispool.py	/^import redis$/;"	i
HashRing	awscrawler/rediscluster/shardredis.py	/^from hash_ring import HashRing$/;"	i
Redis	awscrawler/rediscluster/shardredis.py	/^from redis import Redis$/;"	i
ShardRedis	awscrawler/rediscluster/shardredis.py	/^class ShardRedis(object):$/;"	c
__getattribute__	awscrawler/rediscluster/shardredis.py	/^    def __getattribute__(self, name):$/;"	m	class:ShardRedis	file:
__init__	awscrawler/rediscluster/shardredis.py	/^    def __init__(self, conns, pipelines=None):$/;"	m	class:ShardRedis
cache	awscrawler/rediscluster/shardredis.py	/^    cache = {}$/;"	v	class:ShardRedis
cmd_hashes	awscrawler/rediscluster/shardredis.py	/^cmd_hashes = {'hdel', 'hincrby', 'hmget', 'hvals', 'hexists', 'hincrbyfloat', 'hmset', 'hget',$/;"	v
cmd_keys	awscrawler/rediscluster/shardredis.py	/^cmd_keys = {'delete', 'keys', 'pexpire', 'renamenx', 'dump', 'migrate', 'pexpireat', $/;"	v
cmd_lists	awscrawler/rediscluster/shardredis.py	/^cmd_lists = {'blpop', 'llen', 'lrem', 'rpush', 'brpop', 'lpop', 'lset', 'rpushx', 'brpoplpush',$/;"	v
cmd_mods	awscrawler/rediscluster/shardredis.py	/^cmd_mods = cmd_hashes | cmd_lists | cmd_sets | cmd_zsets | cmd_strings | cmd_supports$/;"	v
cmd_sets	awscrawler/rediscluster/shardredis.py	/^cmd_sets = {'sadd', 'sinter', 'smove', 'sunion', 'scard', 'sinterstore', 'spop', 'sunionstore',$/;"	v
cmd_strings	awscrawler/rediscluster/shardredis.py	/^cmd_strings = {'append', 'getbit', 'mget', 'setex', 'bitcount', 'getrange', 'mset', 'setnx',$/;"	v
cmd_supports	awscrawler/rediscluster/shardredis.py	/^cmd_supports = {'delete', 'type'}$/;"	v
cmd_zsets	awscrawler/rediscluster/shardredis.py	/^cmd_zsets = {'zadd', 'zinterstore', 'zrem', 'zrevrangebyscore', 'zcard', 'zrange', 'zremrangebyrank',$/;"	v
func	awscrawler/rediscluster/shardredis.py	/^                def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__.func
func	awscrawler/rediscluster/shardredis.py	/^            def func():$/;"	f	function:ShardRedis.__getattribute__
func	awscrawler/rediscluster/shardredis.py	/^            def func(*args, **kwargs): $/;"	f	function:ShardRedis.__getattribute__
func	awscrawler/rediscluster/shardredis.py	/^            def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__
get_redis	awscrawler/rediscluster/shardredis.py	/^    def get_redis(self, skey):$/;"	m	class:ShardRedis
getconn	awscrawler/rediscluster/shardredis.py	/^    def getconn(self, index):$/;"	m	class:ShardRedis
conn	awscrawler/rediscluster/test_hscan.py	/^conn = redis.StrictRedis()$/;"	v
division	awscrawler/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
get	awscrawler/rediscluster/test_hscan.py	/^def get():$/;"	f
key	awscrawler/rediscluster/test_hscan.py	/^key = 'test'$/;"	v
print_function	awscrawler/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
redis	awscrawler/rediscluster/test_hscan.py	/^import redis$/;"	i
CappedSortedSet	awscrawler/rediscluster/thinredis.py	/^class CappedSortedSet(object):$/;"	c
RedisPool	awscrawler/rediscluster/thinredis.py	/^from redispool import RedisPool$/;"	i
ShardRedis	awscrawler/rediscluster/thinredis.py	/^from shardredis import ShardRedis$/;"	i
ThinHash	awscrawler/rediscluster/thinredis.py	/^class ThinHash(object):$/;"	c
ThinSet	awscrawler/rediscluster/thinredis.py	/^class ThinSet(object):$/;"	c
__init__	awscrawler/rediscluster/thinredis.py	/^    def __init__(self, key, cap, conn, **kwargs):$/;"	m	class:CappedSortedSet
__init__	awscrawler/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinHash
__init__	awscrawler/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinSet
_get_bucket	awscrawler/rediscluster/thinredis.py	/^    def _get_bucket(self, field):$/;"	m	class:ThinHash
_get_bucket	awscrawler/rediscluster/thinredis.py	/^    def _get_bucket(self, item):$/;"	m	class:ThinSet
add	awscrawler/rediscluster/thinredis.py	/^    def add(self, *items):$/;"	m	class:ThinSet
contains	awscrawler/rediscluster/thinredis.py	/^    def contains(self, *items):$/;"	m	class:ThinSet
count	awscrawler/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinHash
count	awscrawler/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinSet
delete	awscrawler/rediscluster/thinredis.py	/^    def delete(self):$/;"	m	class:ThinHash
delete	awscrawler/rediscluster/thinredis.py	/^    def delete(self, *items):$/;"	m	class:ThinSet
hashlib	awscrawler/rediscluster/thinredis.py	/^import hashlib$/;"	i
hdel	awscrawler/rediscluster/thinredis.py	/^    def hdel(self, field):$/;"	m	class:ThinHash
hget	awscrawler/rediscluster/thinredis.py	/^    def hget(self, field):$/;"	m	class:ThinHash
hgetall	awscrawler/rediscluster/thinredis.py	/^    def hgetall(self):$/;"	m	class:ThinHash
hkeys	awscrawler/rediscluster/thinredis.py	/^    def hkeys(self):$/;"	m	class:ThinHash
hmget	awscrawler/rediscluster/thinredis.py	/^    def hmget(self, *fields):$/;"	m	class:ThinHash
hmset	awscrawler/rediscluster/thinredis.py	/^    def hmset(self, *args):$/;"	m	class:ThinHash
hset	awscrawler/rediscluster/thinredis.py	/^    def hset(self, field, value):$/;"	m	class:ThinHash
inited	awscrawler/rediscluster/thinredis.py	/^    inited = False$/;"	v	class:CappedSortedSet
recount	awscrawler/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinHash
recount	awscrawler/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinSet
redis	awscrawler/rediscluster/thinredis.py	/^import redis$/;"	i
script	awscrawler/rediscluster/thinredis.py	/^    script = '\\n'.join([$/;"	v	class:CappedSortedSet
sha1	awscrawler/rediscluster/thinredis.py	/^    sha1 = hashlib.sha1(script).hexdigest()$/;"	v	class:CappedSortedSet
smembers	awscrawler/rediscluster/thinredis.py	/^    def smembers(self):$/;"	m	class:ThinSet
zadd	awscrawler/rediscluster/thinredis.py	/^    def zadd(self, member, score, **kwargs):$/;"	m	class:CappedSortedSet
zrange	awscrawler/rediscluster/thinredis.py	/^    def zrange(self, start, end, **kwargs):$/;"	m	class:CappedSortedSet
call_with_throttling	awscrawler/rediscluster/throttling.py	/^def call_with_throttling(func, args=(), kwargs={}, expected_processing_gap=0.1):$/;"	f
deque	awscrawler/rediscluster/throttling.py	/^from collections import deque$/;"	i
division	awscrawler/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
print_function	awscrawler/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
remove_outdated	awscrawler/rediscluster/throttling.py	/^    def remove_outdated():$/;"	f	function:call_with_throttling
smoothen_calling_interval	awscrawler/rediscluster/throttling.py	/^    def smoothen_calling_interval():$/;"	f	function:call_with_throttling
time	awscrawler/rediscluster/throttling.py	/^import time$/;"	i
wait_for_threshold	awscrawler/rediscluster/throttling.py	/^    def wait_for_threshold():$/;"	f	function:call_with_throttling
ENV	awscrawler/schedule.py	/^from settings import REGION_NAME, ENV$/;"	i
Ec2Manager	awscrawler/schedule.py	/^from awsapi.ec2manager import Ec2Manager$/;"	i
NoValidConnectionsError	awscrawler/schedule.py	/^from paramiko.ssh_exception import NoValidConnectionsError$/;"	i
REGION_NAME	awscrawler/schedule.py	/^from settings import REGION_NAME, ENV$/;"	i
Schedule	awscrawler/schedule.py	/^class Schedule(object):$/;"	c
__init__	awscrawler/schedule.py	/^    def __init__(self, machine_num, tag, cycle=1200, backoff_timeout=10, *args, **kwargs):$/;"	m	class:Schedule
_assign_cookies	awscrawler/schedule.py	/^    def _assign_cookies(self, cookies):$/;"	m	class:Schedule
ceil	awscrawler/schedule.py	/^from math import ceil$/;"	i
division	awscrawler/schedule.py	/^from __future__ import print_function, division$/;"	i
paramiko	awscrawler/schedule.py	/^import paramiko$/;"	i
print_function	awscrawler/schedule.py	/^from __future__ import print_function, division$/;"	i
remote_command	awscrawler/schedule.py	/^    def remote_command(self, ipaddr, command, repeat=20):$/;"	m	class:Schedule
run_command	awscrawler/schedule.py	/^    def run_command(self, one_id, base_cmd):$/;"	m	class:Schedule
run_forever	awscrawler/schedule.py	/^    def run_forever(self, *args, **kwargs):$/;"	m	class:Schedule
stop_all_instances	awscrawler/schedule.py	/^    def stop_all_instances(self, *_):$/;"	m	class:Schedule
time	awscrawler/schedule.py	/^import time$/;"	i
ENV	awscrawler/settings.py	/^    ENV = 'DEV'$/;"	v
ENV	awscrawler/settings.py	/^ENV = os.environ.get('ENV', 'DEV')$/;"	v
envs	awscrawler/settings.py	/^envs = {$/;"	v
os	awscrawler/settings.py	/^import os$/;"	i
Counter	awscrawler/tests/test_dongcaigonggao_url.py	/^from collections import Counter$/;"	i
GAP	awscrawler/tests/test_dongcaigonggao_url.py	/^GAP = 5$/;"	v
HEADERS	awscrawler/tests/test_dongcaigonggao_url.py	/^HEADERS = {$/;"	v
division	awscrawler/tests/test_dongcaigonggao_url.py	/^from __future__ import print_function, division$/;"	i
gcounter	awscrawler/tests/test_dongcaigonggao_url.py	/^gcounter = Counter()$/;"	v
get_gonggao	awscrawler/tests/test_dongcaigonggao_url.py	/^def get_gonggao(pageno):$/;"	f
html	awscrawler/tests/test_dongcaigonggao_url.py	/^import lxml.html$/;"	i
load_page_no	awscrawler/tests/test_dongcaigonggao_url.py	/^def load_page_no():$/;"	f
lxml	awscrawler/tests/test_dongcaigonggao_url.py	/^import lxml.html$/;"	i
make_session	awscrawler/tests/test_dongcaigonggao_url.py	/^def make_session():$/;"	f
os	awscrawler/tests/test_dongcaigonggao_url.py	/^import os$/;"	i
pageno	awscrawler/tests/test_dongcaigonggao_url.py	/^pageno = load_page_no()$/;"	v
print_function	awscrawler/tests/test_dongcaigonggao_url.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/tests/test_dongcaigonggao_url.py	/^import requests$/;"	i
time	awscrawler/tests/test_dongcaigonggao_url.py	/^import time$/;"	i
urlparse	awscrawler/tests/test_dongcaigonggao_url.py	/^import urlparse$/;"	i
write_page_no	awscrawler/tests/test_dongcaigonggao_url.py	/^def write_page_no(pageno):$/;"	f
Counter	awscrawler/tests/test_dongfangcaifu.py	/^from collections import Counter$/;"	i
HEADERS	awscrawler/tests/test_dongfangcaifu.py	/^HEADERS = {$/;"	v
division	awscrawler/tests/test_dongfangcaifu.py	/^from __future__ import print_function, division$/;"	i
func	awscrawler/tests/test_dongfangcaifu.py	/^def func():$/;"	f
gcounter	awscrawler/tests/test_dongfangcaifu.py	/^gcounter = Counter()$/;"	v
html	awscrawler/tests/test_dongfangcaifu.py	/^import lxml.html$/;"	i
lxml	awscrawler/tests/test_dongfangcaifu.py	/^import lxml.html$/;"	i
print_function	awscrawler/tests/test_dongfangcaifu.py	/^from __future__ import print_function, division$/;"	i
requests	awscrawler/tests/test_dongfangcaifu.py	/^import requests$/;"	i
time	awscrawler/tests/test_dongfangcaifu.py	/^import time$/;"	i
url	awscrawler/tests/test_dongfangcaifu.py	/^url = 'http:\/\/data.eastmoney.com\/notice\/20150509\/2Wvl2WNLCVR2KS.html'$/;"	v
Counter	awscrawler/tests/test_searchzhidao.py	/^from collections import Counter$/;"	i
GAP	awscrawler/tests/test_searchzhidao.py	/^GAP = 1$/;"	v
HEADERS	awscrawler/tests/test_searchzhidao.py	/^HEADERS = {$/;"	v
division	awscrawler/tests/test_searchzhidao.py	/^from __future__ import print_function, division$/;"	i
gcounter	awscrawler/tests/test_searchzhidao.py	/^gcounter = Counter()$/;"	v
html	awscrawler/tests/test_searchzhidao.py	/^import lxml.html$/;"	i
lxml	awscrawler/tests/test_searchzhidao.py	/^import lxml.html$/;"	i
os	awscrawler/tests/test_searchzhidao.py	/^import os$/;"	i
print_function	awscrawler/tests/test_searchzhidao.py	/^from __future__ import print_function, division$/;"	i
re	awscrawler/tests/test_searchzhidao.py	/^import re$/;"	i
requests	awscrawler/tests/test_searchzhidao.py	/^import requests$/;"	i
session	awscrawler/tests/test_searchzhidao.py	/^session = requests.Session()$/;"	v
test_searchzhidao	awscrawler/tests/test_searchzhidao.py	/^def test_searchzhidao():$/;"	f
time	awscrawler/tests/test_searchzhidao.py	/^import time$/;"	i
urlparse	awscrawler/tests/test_searchzhidao.py	/^import urlparse$/;"	i
AGENTS_ALL	awscrawler/tests/test_zhidao_crawler_limit.py	/^from fetch.agents import AGENTS_ALL$/;"	i
division	awscrawler/tests/test_zhidao_crawler_limit.py	/^from __future__ import print_function, division$/;"	i
get_cookie_template	awscrawler/tests/test_zhidao_crawler_limit.py	/^def get_cookie_template():$/;"	f
header	awscrawler/tests/test_zhidao_crawler_limit.py	/^header = {$/;"	v
json	awscrawler/tests/test_zhidao_crawler_limit.py	/^import json$/;"	i
print_function	awscrawler/tests/test_zhidao_crawler_limit.py	/^from __future__ import print_function, division$/;"	i
random	awscrawler/tests/test_zhidao_crawler_limit.py	/^import random$/;"	i
requests	awscrawler/tests/test_zhidao_crawler_limit.py	/^import requests$/;"	i
session	awscrawler/tests/test_zhidao_crawler_limit.py	/^session = requests.Session()$/;"	v
test_api	awscrawler/tests/test_zhidao_crawler_limit.py	/^def test_api():$/;"	f
test_question	awscrawler/tests/test_zhidao_crawler_limit.py	/^def test_question():$/;"	f
time	awscrawler/tests/test_zhidao_crawler_limit.py	/^import time$/;"	i
CACHE_SERVER	awscrawler/todo/search_zhidao.py	/^from settings import CACHE_SERVER$/;"	i
Cache	awscrawler/todo/search_zhidao.py	/^from downloader.cache import Cache$/;"	i
DownloadWrapper	awscrawler/todo/search_zhidao.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
THE_CONFIG	awscrawler/todo/search_zhidao.py	/^from invoker.search_zhidao import THE_CONFIG$/;"	i
base64	awscrawler/todo/search_zhidao.py	/^import base64$/;"	i
division	awscrawler/todo/search_zhidao.py	/^from __future__ import print_function, division$/;"	i
json	awscrawler/todo/search_zhidao.py	/^import json$/;"	i
os	awscrawler/todo/search_zhidao.py	/^import os$/;"	i
print_function	awscrawler/todo/search_zhidao.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/todo/search_zhidao.py	/^def process(url, batch_id, parameter, *args, **kwargs):$/;"	f
re	awscrawler/todo/search_zhidao.py	/^import re$/;"	i
requests	awscrawler/todo/search_zhidao.py	/^import requests$/;"	i
sys	awscrawler/todo/search_zhidao.py	/^import sys$/;"	i
time	awscrawler/todo/search_zhidao.py	/^import time$/;"	i
traceback	awscrawler/todo/search_zhidao.py	/^import traceback$/;"	i
BATCH_ID	awscrawler/todo/zhidao_check.py	/^from invoker.zhidao import BATCH_ID$/;"	i
OUTPUT_FILE	awscrawler/todo/zhidao_check.py	/^OUTPUT_FILE = 'OUTPUT'$/;"	v
base64	awscrawler/todo/zhidao_check.py	/^import base64$/;"	i
check_question	awscrawler/todo/zhidao_check.py	/^def check_question(question_raw):$/;"	f
check_url	awscrawler/todo/zhidao_check.py	/^def check_url(url):$/;"	f
json	awscrawler/todo/zhidao_check.py	/^import json$/;"	i
logging	awscrawler/todo/zhidao_check.py	/^import logging$/;"	i
os	awscrawler/todo/zhidao_check.py	/^import os$/;"	i
re	awscrawler/todo/zhidao_check.py	/^import re$/;"	i
requests	awscrawler/todo/zhidao_check.py	/^import requests$/;"	i
sys	awscrawler/todo/zhidao_check.py	/^import sys$/;"	i
time	awscrawler/todo/zhidao_check.py	/^import time$/;"	i
traceback	awscrawler/todo/zhidao_check.py	/^import traceback$/;"	i
CACHE_REDIS	awscrawler/worker.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
GetWorker	awscrawler/worker.py	/^class GetWorker(Worker):$/;"	c
QUEUE_REDIS	awscrawler/worker.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
RECORD_REDIS	awscrawler/worker.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Record	awscrawler/worker.py	/^from rediscluster.record import Record$/;"	i
RedisManager	awscrawler/worker.py	/^from rediscluster.redismanager import RedisManager$/;"	i
Worker	awscrawler/worker.py	/^class Worker(object):$/;"	c
__init__	awscrawler/worker.py	/^    def __init__(self):$/;"	m	class:Worker
__init__	awscrawler/worker.py	/^    def __init__(self, index):$/;"	m	class:GetWorker
argparse	awscrawler/worker.py	/^    import argparse$/;"	i
datetime	awscrawler/worker.py	/^from datetime import datetime$/;"	i
division	awscrawler/worker.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/worker.py	/^from crawlerlog.cachelog import get_logger$/;"	i
get_other_batch_process_time	awscrawler/worker.py	/^    def get_other_batch_process_time(self, other_batches):$/;"	m	class:GetWorker
main	awscrawler/worker.py	/^def main():$/;"	f
print_function	awscrawler/worker.py	/^from __future__ import print_function, division$/;"	i
run	awscrawler/worker.py	/^    def run(self, *args, **kwargs):$/;"	m	class:GetWorker
schedule	awscrawler/worker.py	/^    def schedule(self, *args, **kwargs):$/;"	m	class:GetWorker
time	awscrawler/worker.py	/^import time$/;"	i
update_process_time_of_this_batch	awscrawler/worker.py	/^    def update_process_time_of_this_batch(self, batch_id, start):$/;"	m	class:GetWorker
work	awscrawler/worker.py	/^    def work(self):$/;"	m	class:Worker
work	awscrawler/worker.py	/^    def work(self, batch_id, queue_dict, url_id, other_batch_process_time, *args, **kwargs):$/;"	m	class:GetWorker
CACHE_REDIS	awscrawler/worker_v1.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
GetWorker	awscrawler/worker_v1.py	/^class GetWorker(Worker):$/;"	c
QUEUE_REDIS	awscrawler/worker_v1.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
RECORD_REDIS	awscrawler/worker_v1.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Record	awscrawler/worker_v1.py	/^from rediscluster.record import Record$/;"	i
RedisManager	awscrawler/worker_v1.py	/^from rediscluster.redismanager import RedisManager$/;"	i
Worker	awscrawler/worker_v1.py	/^class Worker(object):$/;"	c
__init__	awscrawler/worker_v1.py	/^    def __init__(self):$/;"	m	class:Worker
__init__	awscrawler/worker_v1.py	/^    def __init__(self, index):$/;"	m	class:GetWorker
argparse	awscrawler/worker_v1.py	/^    import argparse$/;"	i
datetime	awscrawler/worker_v1.py	/^from datetime import datetime$/;"	i
division	awscrawler/worker_v1.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/worker_v1.py	/^from crawlerlog.cachelog import get_logger$/;"	i
main	awscrawler/worker_v1.py	/^def main():$/;"	f
print_function	awscrawler/worker_v1.py	/^from __future__ import print_function, division$/;"	i
run	awscrawler/worker_v1.py	/^    def run(self, *args, **kwargs):$/;"	m	class:GetWorker
schedule	awscrawler/worker_v1.py	/^    def schedule(self, *args, **kwargs):$/;"	m	class:GetWorker
time	awscrawler/worker_v1.py	/^import time$/;"	i
work	awscrawler/worker_v1.py	/^    def work(self):$/;"	m	class:Worker
work	awscrawler/worker_v1.py	/^    def work(self, batch_id, queue_dict, *args, **kwargs):$/;"	m	class:GetWorker
CACHE_SERVER	awscrawler/workers/agricul.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/agricul.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/agricul.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/agricul.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/agricul.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/agricul.py	/^SITE = 'http:\/\/agr.100ppi.com\/price\/'$/;"	v
datetime	awscrawler/workers/agricul.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/agricul.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/agricul.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/agricul.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/agricul.py	/^import json$/;"	i
print_function	awscrawler/workers/agricul.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/agricul.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/agricul.py	/^import re$/;"	i
safe_state	awscrawler/workers/agricul.py	/^    def safe_state(statement):$/;"	f	function:process
sys	awscrawler/workers/agricul.py	/^import sys$/;"	i
urllib	awscrawler/workers/agricul.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/agricul.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/agriculdaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/agriculdaily.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/agriculdaily.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/agriculdaily.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/agriculdaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/agriculdaily.py	/^SITE = 'http:\/\/agr.100ppi.com\/price\/'$/;"	v
datetime	awscrawler/workers/agriculdaily.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/agriculdaily.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/agriculdaily.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/agriculdaily.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/agriculdaily.py	/^import json$/;"	i
print_function	awscrawler/workers/agriculdaily.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/agriculdaily.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/agriculdaily.py	/^import re$/;"	i
safe_state	awscrawler/workers/agriculdaily.py	/^    def safe_state(statement):$/;"	f	function:process
sys	awscrawler/workers/agriculdaily.py	/^import sys$/;"	i
urllib	awscrawler/workers/agriculdaily.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/agriculdaily.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/chem.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/chem.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/chem.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/chem.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/chem.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/chem.py	/^SITE = 'http:\/\/china.chemnet.com'$/;"	v
datetime	awscrawler/workers/chem.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/chem.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/chem.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/chem.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/chem.py	/^import json$/;"	i
print_function	awscrawler/workers/chem.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/chem.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/chem.py	/^import re$/;"	i
safe_state	awscrawler/workers/chem.py	/^    def safe_state(statement):$/;"	f	function:process
sys	awscrawler/workers/chem.py	/^import sys$/;"	i
urllib	awscrawler/workers/chem.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/chem.py	/^import urlparse$/;"	i
xpath_string	awscrawler/workers/chem.py	/^    def xpath_string(n):$/;"	f	function:process
CACHE_SERVER	awscrawler/workers/chemppi.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/chemppi.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/chemppi.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/chemppi.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/chemppi.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/chemppi.py	/^SITE = 'http:\/\/chem.100ppi.com\/price\/'$/;"	v
datetime	awscrawler/workers/chemppi.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/chemppi.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/chemppi.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/chemppi.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/chemppi.py	/^import json$/;"	i
print_function	awscrawler/workers/chemppi.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/chemppi.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/chemppi.py	/^import re$/;"	i
safe_state	awscrawler/workers/chemppi.py	/^    def safe_state(statement):$/;"	f	function:process
sys	awscrawler/workers/chemppi.py	/^import sys$/;"	i
urllib	awscrawler/workers/chemppi.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/chemppi.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/chemppidaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/chemppidaily.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/chemppidaily.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/chemppidaily.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/chemppidaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/chemppidaily.py	/^SITE = 'http:\/\/chem.100ppi.com\/price\/'$/;"	v
datetime	awscrawler/workers/chemppidaily.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/chemppidaily.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/chemppidaily.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/chemppidaily.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/chemppidaily.py	/^import json$/;"	i
print_function	awscrawler/workers/chemppidaily.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/chemppidaily.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/chemppidaily.py	/^import re$/;"	i
safe_state	awscrawler/workers/chemppidaily.py	/^    def safe_state(statement):$/;"	f	function:process
sys	awscrawler/workers/chemppidaily.py	/^import sys$/;"	i
urllib	awscrawler/workers/chemppidaily.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/chemppidaily.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/cngrain.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/cngrain.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/cngrain.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/cngrain.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/cngrain.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/cngrain.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/cngrain.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/cngrain.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/cngrain.py	/^import lxml.html$/;"	i
json	awscrawler/workers/cngrain.py	/^import json$/;"	i
lxml	awscrawler/workers/cngrain.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/cngrain.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/cngrain.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/cngrain.py	/^import re$/;"	i
sys	awscrawler/workers/cngrain.py	/^import sys$/;"	i
time	awscrawler/workers/cngrain.py	/^import time$/;"	i
urllib	awscrawler/workers/cngrain.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/cngrain.py	/^import urlparse$/;"	i
CacheS3	awscrawler/workers/dongcaigonggao_content.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/dongcaigonggao_content.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/dongcaigonggao_content.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/dongcaigonggao_content.py	/^from settings import REGION_NAME$/;"	i
base64	awscrawler/workers/dongcaigonggao_content.py	/^import base64$/;"	i
datetime	awscrawler/workers/dongcaigonggao_content.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/dongcaigonggao_content.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/dongcaigonggao_content.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/dongcaigonggao_content.py	/^import lxml.html$/;"	i
json	awscrawler/workers/dongcaigonggao_content.py	/^import json$/;"	i
lxml	awscrawler/workers/dongcaigonggao_content.py	/^import lxml.html$/;"	i
os	awscrawler/workers/dongcaigonggao_content.py	/^import os$/;"	i
print_function	awscrawler/workers/dongcaigonggao_content.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/dongcaigonggao_content.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/dongcaigonggao_content.py	/^import re$/;"	i
requests	awscrawler/workers/dongcaigonggao_content.py	/^import requests$/;"	i
sys	awscrawler/workers/dongcaigonggao_content.py	/^import sys$/;"	i
time	awscrawler/workers/dongcaigonggao_content.py	/^import time$/;"	i
traceback	awscrawler/workers/dongcaigonggao_content.py	/^import traceback$/;"	i
DownloadWrapper	awscrawler/workers/dongcaigonggao_index0620.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/dongcaigonggao_index0620.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/dongcaigonggao_index0620.py	/^from settings import REGION_NAME$/;"	i
base64	awscrawler/workers/dongcaigonggao_index0620.py	/^import base64$/;"	i
datetime	awscrawler/workers/dongcaigonggao_index0620.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/dongcaigonggao_index0620.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/dongcaigonggao_index0620.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/dongcaigonggao_index0620.py	/^import lxml.html$/;"	i
json	awscrawler/workers/dongcaigonggao_index0620.py	/^import json$/;"	i
lxml	awscrawler/workers/dongcaigonggao_index0620.py	/^import lxml.html$/;"	i
os	awscrawler/workers/dongcaigonggao_index0620.py	/^import os$/;"	i
print_function	awscrawler/workers/dongcaigonggao_index0620.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/dongcaigonggao_index0620.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/dongcaigonggao_index0620.py	/^import re$/;"	i
requests	awscrawler/workers/dongcaigonggao_index0620.py	/^import requests$/;"	i
sys	awscrawler/workers/dongcaigonggao_index0620.py	/^import sys$/;"	i
time	awscrawler/workers/dongcaigonggao_index0620.py	/^import time$/;"	i
traceback	awscrawler/workers/dongcaigonggao_index0620.py	/^import traceback$/;"	i
urlparse	awscrawler/workers/dongcaigonggao_index0620.py	/^import urlparse$/;"	i
CacheS3	awscrawler/workers/fudankg.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/fudankg.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/fudankg.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/fudankg.py	/^from settings import REGION_NAME$/;"	i
SITE	awscrawler/workers/fudankg.py	/^SITE = 'https:\/\/crl.ptopenlab.com:8800'$/;"	v
datetime	awscrawler/workers/fudankg.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/fudankg.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/fudankg.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/fudankg.py	/^import json$/;"	i
print_function	awscrawler/workers/fudankg.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/fudankg.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/fudankg.py	/^import re$/;"	i
urllib	awscrawler/workers/fudankg.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/fudankg.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/fudanperiod.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/fudanperiod.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/fudanperiod.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/fudanperiod.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/fudanperiod.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/fudanperiod.py	/^SITE = 'https:\/\/crl.ptopenlab.com:8800'$/;"	v
datetime	awscrawler/workers/fudanperiod.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/fudanperiod.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/fudanperiod.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/fudanperiod.py	/^import json$/;"	i
print_function	awscrawler/workers/fudanperiod.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/fudanperiod.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/fudanperiod.py	/^import re$/;"	i
urllib	awscrawler/workers/fudanperiod.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/fudanperiod.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/kmzy.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/kmzy.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/kmzy.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/kmzy.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/kmzy.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/kmzy.py	/^SITE = 'http:\/\/www.kmzyw.com.cn\/'$/;"	v
datetime	awscrawler/workers/kmzy.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/kmzy.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/kmzy.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/kmzy.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/kmzy.py	/^import json$/;"	i
print_function	awscrawler/workers/kmzy.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/kmzy.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/kmzy.py	/^import re$/;"	i
sys	awscrawler/workers/kmzy.py	/^import sys$/;"	i
time	awscrawler/workers/kmzy.py	/^import time$/;"	i
timestamp2datetime	awscrawler/workers/kmzy.py	/^    def timestamp2datetime(timestamp):$/;"	f	function:process
urllib	awscrawler/workers/kmzy.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/kmzy.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/kmzydaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/kmzydaily.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/kmzydaily.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/kmzydaily.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/kmzydaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/kmzydaily.py	/^SITE = 'http:\/\/www.kmzyw.com.cn\/'$/;"	v
datetime	awscrawler/workers/kmzydaily.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/kmzydaily.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/kmzydaily.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/kmzydaily.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/kmzydaily.py	/^import json$/;"	i
print_function	awscrawler/workers/kmzydaily.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/kmzydaily.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/kmzydaily.py	/^import re$/;"	i
sys	awscrawler/workers/kmzydaily.py	/^import sys$/;"	i
time	awscrawler/workers/kmzydaily.py	/^import time$/;"	i
timestamp2datetime	awscrawler/workers/kmzydaily.py	/^    def timestamp2datetime(timestamp):$/;"	f	function:process
urllib	awscrawler/workers/kmzydaily.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/kmzydaily.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/prefetch.py	/^from settings import CACHE_SERVER$/;"	i
Cache	awscrawler/workers/prefetch.py	/^from downloader.cache import Cache$/;"	i
CacheS3	awscrawler/workers/prefetch.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/prefetch.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/prefetch.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
base64	awscrawler/workers/prefetch.py	/^import base64$/;"	i
division	awscrawler/workers/prefetch.py	/^from __future__ import print_function, division$/;"	i
json	awscrawler/workers/prefetch.py	/^import json$/;"	i
os	awscrawler/workers/prefetch.py	/^import os$/;"	i
print_function	awscrawler/workers/prefetch.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/prefetch.py	/^def process(url, batch_id, parameter, *args, **kwargs):$/;"	f
re	awscrawler/workers/prefetch.py	/^import re$/;"	i
requests	awscrawler/workers/prefetch.py	/^import requests$/;"	i
sys	awscrawler/workers/prefetch.py	/^import sys$/;"	i
time	awscrawler/workers/prefetch.py	/^import time$/;"	i
traceback	awscrawler/workers/prefetch.py	/^import traceback$/;"	i
CACHE_SERVER	awscrawler/workers/qichacha.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
Cache	awscrawler/workers/qichacha.py	/^from downloader.cache import Cache$/;"	i
CachePeriod	awscrawler/workers/qichacha.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/qichacha.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/qichacha.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
QiParser	awscrawler/workers/qichacha.py	/^from parsers.qiparser2 import QiParser$/;"	i
REGION_NAME	awscrawler/workers/qichacha.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/qichacha.py	/^SITE = 'http:\/\/www.qichacha.com'$/;"	v
datetime	awscrawler/workers/qichacha.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/qichacha.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/qichacha.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/qichacha.py	/^import lxml.html$/;"	i
json	awscrawler/workers/qichacha.py	/^import json$/;"	i
lxml	awscrawler/workers/qichacha.py	/^import lxml.html$/;"	i
parse_company_investment	awscrawler/workers/qichacha.py	/^    def parse_company_investment(tree):     # 解析对外投资页面，将子公司存入sub_companies字段下$/;"	f	function:process
print_function	awscrawler/workers/qichacha.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/qichacha.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/qichacha.py	/^import re$/;"	i
reformat	awscrawler/workers/qichacha.py	/^    def reformat(info):     # 将info按企查查页面顺序插入队列$/;"	f	function:process
requests	awscrawler/workers/qichacha.py	/^import requests$/;"	i
sys	awscrawler/workers/qichacha.py	/^import sys$/;"	i
urllib	awscrawler/workers/qichacha.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/qichacha.py	/^import urlparse$/;"	i
CacheS3	awscrawler/workers/searchzhidao.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/searchzhidao.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/searchzhidao.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/searchzhidao.py	/^from settings import REGION_NAME$/;"	i
SITE	awscrawler/workers/searchzhidao.py	/^SITE = 'http:\/\/zhidao.baidu.com'$/;"	v
datetime	awscrawler/workers/searchzhidao.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/searchzhidao.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/searchzhidao.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/searchzhidao.py	/^import json$/;"	i
parse_search_json_v0707	awscrawler/workers/searchzhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
print_function	awscrawler/workers/searchzhidao.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/searchzhidao.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/searchzhidao.py	/^import re$/;"	i
urllib	awscrawler/workers/searchzhidao.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/searchzhidao.py	/^import urlparse$/;"	i
CacheS3	awscrawler/workers/searchzhidao2.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/searchzhidao2.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/searchzhidao2.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/searchzhidao2.py	/^from settings import REGION_NAME$/;"	i
SITE	awscrawler/workers/searchzhidao2.py	/^SITE = 'http:\/\/zhidao.baidu.com'$/;"	v
datetime	awscrawler/workers/searchzhidao2.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/searchzhidao2.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/searchzhidao2.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/searchzhidao2.py	/^import json$/;"	i
parse_search_json_v0707	awscrawler/workers/searchzhidao2.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
print_function	awscrawler/workers/searchzhidao2.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/searchzhidao2.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/searchzhidao2.py	/^import re$/;"	i
urllib	awscrawler/workers/searchzhidao2.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/searchzhidao2.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/searchzhidaoperiod.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/searchzhidaoperiod.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/searchzhidaoperiod.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/searchzhidaoperiod.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/searchzhidaoperiod.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/searchzhidaoperiod.py	/^SITE = 'http:\/\/zhidao.baidu.com'$/;"	v
datetime	awscrawler/workers/searchzhidaoperiod.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/searchzhidaoperiod.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/searchzhidaoperiod.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/searchzhidaoperiod.py	/^import json$/;"	i
parse_search_json_v0707	awscrawler/workers/searchzhidaoperiod.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
print_function	awscrawler/workers/searchzhidaoperiod.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/searchzhidaoperiod.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/searchzhidaoperiod.py	/^import re$/;"	i
urllib	awscrawler/workers/searchzhidaoperiod.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/searchzhidaoperiod.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/shanghaigold.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/shanghaigold.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/shanghaigold.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/shanghaigold.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/shanghaigold.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/shanghaigold.py	/^SITE = 'http:\/\/www.sge.com.cn'$/;"	v
datetime	awscrawler/workers/shanghaigold.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/shanghaigold.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/shanghaigold.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/shanghaigold.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/shanghaigold.py	/^import json$/;"	i
print_function	awscrawler/workers/shanghaigold.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/shanghaigold.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/shanghaigold.py	/^import re$/;"	i
sys	awscrawler/workers/shanghaigold.py	/^import sys$/;"	i
urllib	awscrawler/workers/shanghaigold.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/shanghaigold.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/xiami.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/xiami.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/xiami.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/xiami.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/xiami.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/xiami.py	/^import datetime$/;"	i
get_content	awscrawler/workers/xiami.py	/^    def get_content(url):$/;"	f	function:process
get_logger	awscrawler/workers/xiami.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/xiami.py	/^import lxml.html$/;"	i
json	awscrawler/workers/xiami.py	/^import json$/;"	i
lxml	awscrawler/workers/xiami.py	/^import lxml.html$/;"	i
parse_album_detail	awscrawler/workers/xiami.py	/^def parse_album_detail(result, album_id, album_cache):$/;"	f
parse_song_detail	awscrawler/workers/xiami.py	/^def parse_song_detail(result, song_id):$/;"	f
parse_song_list	awscrawler/workers/xiami.py	/^def parse_song_list(artist_id):$/;"	f
process	awscrawler/workers/xiami.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/xiami.py	/^import re$/;"	i
requests	awscrawler/workers/xiami.py	/^import requests$/;"	i
sys	awscrawler/workers/xiami.py	/^import sys$/;"	i
time	awscrawler/workers/xiami.py	/^import time$/;"	i
tt	awscrawler/workers/xiami.py	/^    tt = CachePeriod('tett', CACHE_SERVER)$/;"	v
urllib	awscrawler/workers/xiami.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/xiami.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaojianju.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaojianju.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaojianju.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaojianju.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaojianju.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaojianju.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaojianju.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaojianju.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaojianju.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaojianju.py	/^import json$/;"	i
lxml	awscrawler/workers/yaojianju.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaojianju.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaojianju.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaojianju.py	/^import re$/;"	i
urllib	awscrawler/workers/yaojianju.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaojianju.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaojianjugmp.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaojianjugmp.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaojianjugmp.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaojianjugmp.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaojianjugmp.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaojianjugmp.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaojianjugmp.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaojianjugmp.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaojianjugmp.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaojianjugmp.py	/^import json$/;"	i
lxml	awscrawler/workers/yaojianjugmp.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaojianjugmp.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaojianjugmp.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaojianjugmp.py	/^import re$/;"	i
requests	awscrawler/workers/yaojianjugmp.py	/^            import requests$/;"	i
urllib	awscrawler/workers/yaojianjugmp.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaojianjugmp.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaojianjuoversea.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaojianjuoversea.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaojianjuoversea.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaojianjuoversea.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaojianjuoversea.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaojianjuoversea.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaojianjuoversea.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaojianjuoversea.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaojianjuoversea.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaojianjuoversea.py	/^import json$/;"	i
lxml	awscrawler/workers/yaojianjuoversea.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaojianjuoversea.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaojianjuoversea.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaojianjuoversea.py	/^import re$/;"	i
sys	awscrawler/workers/yaojianjuoversea.py	/^import sys$/;"	i
time	awscrawler/workers/yaojianjuoversea.py	/^import time$/;"	i
urllib	awscrawler/workers/yaojianjuoversea.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaojianjuoversea.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaotongnew.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaotongnew.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaotongnew.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaotongnew.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaotongnew.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaotongnew.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaotongnew.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaotongnew.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaotongnew.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaotongnew.py	/^import json$/;"	i
lxml	awscrawler/workers/yaotongnew.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaotongnew.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaotongnew.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaotongnew.py	/^import re$/;"	i
sys	awscrawler/workers/yaotongnew.py	/^import sys$/;"	i
time	awscrawler/workers/yaotongnew.py	/^import time$/;"	i
urllib	awscrawler/workers/yaotongnew.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaotongnew.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaotongnewdaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaotongnewdaily.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaotongnewdaily.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaotongnewdaily.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaotongnewdaily.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaotongnewdaily.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaotongnewdaily.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaotongnewdaily.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaotongnewdaily.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaotongnewdaily.py	/^import json$/;"	i
lxml	awscrawler/workers/yaotongnewdaily.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaotongnewdaily.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaotongnewdaily.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaotongnewdaily.py	/^import re$/;"	i
sys	awscrawler/workers/yaotongnewdaily.py	/^import sys$/;"	i
time	awscrawler/workers/yaotongnewdaily.py	/^import time$/;"	i
urllib	awscrawler/workers/yaotongnewdaily.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaotongnewdaily.py	/^import urlparse$/;"	i
CACHE_SERVER	awscrawler/workers/yaotongold.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/yaotongold.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/yaotongold.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaotongold.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaotongold.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
datetime	awscrawler/workers/yaotongold.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaotongold.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaotongold.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaotongold.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaotongold.py	/^import json$/;"	i
lxml	awscrawler/workers/yaotongold.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaotongold.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaotongold.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaotongold.py	/^import re$/;"	i
sys	awscrawler/workers/yaotongold.py	/^import sys$/;"	i
time	awscrawler/workers/yaotongold.py	/^import time$/;"	i
urllib	awscrawler/workers/yaotongold.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaotongold.py	/^import urlparse$/;"	i
CacheS3	awscrawler/workers/yaotongolddaily.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/yaotongolddaily.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/yaotongolddaily.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/yaotongolddaily.py	/^from settings import REGION_NAME$/;"	i
datetime	awscrawler/workers/yaotongolddaily.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/yaotongolddaily.py	/^from __future__ import print_function, division$/;"	i
get_logger	awscrawler/workers/yaotongolddaily.py	/^from crawlerlog.cachelog import get_logger$/;"	i
html	awscrawler/workers/yaotongolddaily.py	/^import lxml.html$/;"	i
json	awscrawler/workers/yaotongolddaily.py	/^import json$/;"	i
lxml	awscrawler/workers/yaotongolddaily.py	/^import lxml.html$/;"	i
print_function	awscrawler/workers/yaotongolddaily.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/yaotongolddaily.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/yaotongolddaily.py	/^import re$/;"	i
sys	awscrawler/workers/yaotongolddaily.py	/^import sys$/;"	i
time	awscrawler/workers/yaotongolddaily.py	/^import time$/;"	i
urllib	awscrawler/workers/yaotongolddaily.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/yaotongolddaily.py	/^import urlparse$/;"	i
BATCH_ID	awscrawler/workers/zhidao_answer.py	/^from invoker.zhidao_constant import BATCH_ID$/;"	i
CacheS3	awscrawler/workers/zhidao_answer.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/zhidao_answer.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
REGION_NAME	awscrawler/workers/zhidao_answer.py	/^from settings import REGION_NAME$/;"	i
base64	awscrawler/workers/zhidao_answer.py	/^import base64$/;"	i
division	awscrawler/workers/zhidao_answer.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	awscrawler/workers/zhidao_answer.py	/^from parsers.zhidao_parser import generate_answer_json$/;"	i
json	awscrawler/workers/zhidao_answer.py	/^import json$/;"	i
os	awscrawler/workers/zhidao_answer.py	/^import os$/;"	i
print_function	awscrawler/workers/zhidao_answer.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/zhidao_answer.py	/^def process(url, batch_id, parameter, *args, **kwargs):$/;"	f
re	awscrawler/workers/zhidao_answer.py	/^import re$/;"	i
requests	awscrawler/workers/zhidao_answer.py	/^import requests$/;"	i
sys	awscrawler/workers/zhidao_answer.py	/^import sys$/;"	i
time	awscrawler/workers/zhidao_answer.py	/^import time$/;"	i
traceback	awscrawler/workers/zhidao_answer.py	/^import traceback$/;"	i
BATCH_ID	awscrawler/workers/zhidao_question.py	/^from invoker.zhidao_constant import BATCH_ID$/;"	i
CacheS3	awscrawler/workers/zhidao_question.py	/^from downloader.caches3 import CacheS3$/;"	i
DownloadWrapper	awscrawler/workers/zhidao_question.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
REGION_NAME	awscrawler/workers/zhidao_question.py	/^from settings import REGION_NAME$/;"	i
base64	awscrawler/workers/zhidao_question.py	/^import base64$/;"	i
division	awscrawler/workers/zhidao_question.py	/^from __future__ import print_function, division$/;"	i
generate_question_json	awscrawler/workers/zhidao_question.py	/^from parsers.zhidao_parser import parse_q_time, parse_q_content, parse_answer_ids, generate_question_json$/;"	i
get_answer_url	awscrawler/workers/zhidao_question.py	/^def get_answer_url(q_id, r_id):$/;"	f
json	awscrawler/workers/zhidao_question.py	/^import json$/;"	i
parse_answer_ids	awscrawler/workers/zhidao_question.py	/^from parsers.zhidao_parser import parse_q_time, parse_q_content, parse_answer_ids, generate_question_json$/;"	i
parse_q_content	awscrawler/workers/zhidao_question.py	/^from parsers.zhidao_parser import parse_q_time, parse_q_content, parse_answer_ids, generate_question_json$/;"	i
parse_q_time	awscrawler/workers/zhidao_question.py	/^from parsers.zhidao_parser import parse_q_time, parse_q_content, parse_answer_ids, generate_question_json$/;"	i
print_function	awscrawler/workers/zhidao_question.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/zhidao_question.py	/^def process(url, batch_id, parameter, manager, *args, **kwargs):$/;"	f
re	awscrawler/workers/zhidao_question.py	/^import re$/;"	i
CACHE_SERVER	awscrawler/workers/zysj.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
CachePeriod	awscrawler/workers/zysj.py	/^from downloader.cacheperiod import CachePeriod$/;"	i
DownloadWrapper	awscrawler/workers/zysj.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	awscrawler/workers/zysj.py	/^from downloader.downloader_wrapper import Downloader$/;"	i
REGION_NAME	awscrawler/workers/zysj.py	/^from settings import REGION_NAME, CACHE_SERVER$/;"	i
SITE	awscrawler/workers/zysj.py	/^SITE = 'http:\/\/www.zysj.com.cn'$/;"	v
datetime	awscrawler/workers/zysj.py	/^from datetime import datetime$/;"	i
division	awscrawler/workers/zysj.py	/^from __future__ import print_function, division$/;"	i
etree	awscrawler/workers/zysj.py	/^from lxml import etree$/;"	i
get_logger	awscrawler/workers/zysj.py	/^from crawlerlog.cachelog import get_logger$/;"	i
json	awscrawler/workers/zysj.py	/^import json$/;"	i
print_function	awscrawler/workers/zysj.py	/^from __future__ import print_function, division$/;"	i
process	awscrawler/workers/zysj.py	/^def process(url, batch_id, parameter, manager, other_batch_process_time, *args, **kwargs):$/;"	f
re	awscrawler/workers/zysj.py	/^import re$/;"	i
sys	awscrawler/workers/zysj.py	/^import sys$/;"	i
urllib	awscrawler/workers/zysj.py	/^import urllib$/;"	i
urlparse	awscrawler/workers/zysj.py	/^import urlparse$/;"	i
BaseCache	crawlerservice/cache/basecache.py	/^class BaseCache(object):$/;"	c
CACHEPAGE	crawlerservice/cache/basecache.py	/^from settings import CACHEPAGE$/;"	i
__init__	crawlerservice/cache/basecache.py	/^    def __init__(self):$/;"	m	class:BaseCache
base64	crawlerservice/cache/basecache.py	/^import base64$/;"	i
db_get_all_cache	crawlerservice/cache/basecache.py	/^from .dbcache import db_get_cache, db_set_cache, db_get_all_cache$/;"	i
db_get_cache	crawlerservice/cache/basecache.py	/^from .dbcache import db_get_cache, db_set_cache, db_get_all_cache$/;"	i
db_set_cache	crawlerservice/cache/basecache.py	/^from .dbcache import db_get_cache, db_set_cache, db_get_all_cache$/;"	i
division	crawlerservice/cache/basecache.py	/^from __future__ import print_function, division$/;"	i
fs_get_cache	crawlerservice/cache/basecache.py	/^from .fscache import fs_get_cache, fs_set_cache$/;"	i
fs_set_cache	crawlerservice/cache/basecache.py	/^from .fscache import fs_get_cache, fs_set_cache$/;"	i
get_all_cache	crawlerservice/cache/basecache.py	/^    def get_all_cache(batch_id):$/;"	m	class:BaseCache
get_cache	crawlerservice/cache/basecache.py	/^    def get_cache(b64url, batch_id, exists=False): $/;"	m	class:BaseCache
hashlib	crawlerservice/cache/basecache.py	/^import hashlib$/;"	i
period_get_cache	crawlerservice/cache/basecache.py	/^from .periodcache import period_get_cache, period_set_cache$/;"	i
period_set_cache	crawlerservice/cache/basecache.py	/^from .periodcache import period_get_cache, period_set_cache$/;"	i
print_function	crawlerservice/cache/basecache.py	/^from __future__ import print_function, division$/;"	i
s3_get_cache	crawlerservice/cache/basecache.py	/^from .s3cache import s3_get_cache, s3_put_cache$/;"	i
s3_put_cache	crawlerservice/cache/basecache.py	/^from .s3cache import s3_get_cache, s3_put_cache$/;"	i
set_cache	crawlerservice/cache/basecache.py	/^    def set_cache(b64url, batch_id, groups, content, refresh):$/;"	m	class:BaseCache
ufile_get_cache	crawlerservice/cache/basecache.py	/^from .ufilecache import ufile_get_cache, ufile_set_cache$/;"	i
ufile_set_cache	crawlerservice/cache/basecache.py	/^from .ufilecache import ufile_get_cache, ufile_set_cache$/;"	i
accessed	crawlerservice/cache/crawlercache.sql	/^create table accessed ($/;"	t
accessed.accessed_batchid_urlhash_idx	crawlerservice/cache/crawlercache.sql	/^create index accessed_batchid_urlhash_idx on accessed (batch_id, url_hash); -- can be unique$/;"	i
accessed.accessed_url_idx	crawlerservice/cache/crawlercache.sql	/^create index accessed_url_idx on accessed (b64url);$/;"	i
accessed.b64url	crawlerservice/cache/crawlercache.sql	/^  b64url varchar(2048),$/;"	F
accessed.batch_id	crawlerservice/cache/crawlercache.sql	/^  batch_id varchar(64),$/;"	F
accessed.created_time	crawlerservice/cache/crawlercache.sql	/^  created_time timestamp default now(),$/;"	F
accessed.groups	crawlerservice/cache/crawlercache.sql	/^  groups varchar(64)[],$/;"	F
accessed.id	crawlerservice/cache/crawlercache.sql	/^  id bigserial primary key,$/;"	F
accessed.status	crawlerservice/cache/crawlercache.sql	/^  status smallint, -- 0 begin, 1 downloaded$/;"	F
accessed.updated_time	crawlerservice/cache/crawlercache.sql	/^  updated_time timestamp$/;"	F
accessed.url_hash	crawlerservice/cache/crawlercache.sql	/^  url_hash varchar(128),$/;"	F
cached	crawlerservice/cache/crawlercache.sql	/^create table cached ($/;"	t
cached.b64url	crawlerservice/cache/crawlercache.sql	/^  b64url varchar(2048),$/;"	F
cached.cached_url_hash_idx	crawlerservice/cache/crawlercache.sql	/^create index cached_url_hash_idx on cached (url_hash);$/;"	i
cached.cached_url_idx	crawlerservice/cache/crawlercache.sql	/^create index cached_url_idx on cached (b64url);$/;"	i
cached.content_hash	crawlerservice/cache/crawlercache.sql	/^  content_hash varchar(256)$/;"	F
cached.created_time	crawlerservice/cache/crawlercache.sql	/^  created_time timestamp default now(),$/;"	F
cached.id	crawlerservice/cache/crawlercache.sql	/^  id bigserial primary key,$/;"	F
cached.last_modify	crawlerservice/cache/crawlercache.sql	/^  last_modify timestamp,$/;"	F
cached.url_hash	crawlerservice/cache/crawlercache.sql	/^  url_hash varchar(128),$/;"	F
contents	crawlerservice/cache/crawlercache.sql	/^create table contents ($/;"	t
contents.cached_id	crawlerservice/cache/crawlercache.sql	/^  cached_id bigint references cached (id) not null,$/;"	F
contents.content	crawlerservice/cache/crawlercache.sql	/^  content text$/;"	F
contents.contents_cached_id_idx	crawlerservice/cache/crawlercache.sql	/^create index contents_cached_id_idx on contents (cached_id);$/;"	i
contents.id	crawlerservice/cache/crawlercache.sql	/^  id bigserial primary key,$/;"	F
base64	crawlerservice/cache/dbcache.py	/^import base64$/;"	i
db_get_all_cache	crawlerservice/cache/dbcache.py	/^def db_get_all_cache(batch_id):$/;"	f
db_get_cache	crawlerservice/cache/dbcache.py	/^def db_get_cache(url_hash):$/;"	f
db_set_cache	crawlerservice/cache/dbcache.py	/^def db_set_cache(b64url, url_hash, batch_id, groups, content, refresh):$/;"	f
dbwrapper	crawlerservice/cache/dbcache.py	/^from dbconnector import dbwrapper$/;"	i
division	crawlerservice/cache/dbcache.py	/^from __future__ import print_function, division$/;"	i
hashlib	crawlerservice/cache/dbcache.py	/^import hashlib$/;"	i
print_function	crawlerservice/cache/dbcache.py	/^from __future__ import print_function, division$/;"	i
NUM	crawlerservice/cache/entropy.py	/^NUM = 50000$/;"	v
alphanumber	crawlerservice/cache/entropy.py	/^alphanumber = 'ABCDEFGHIGKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'$/;"	v
bit_list	crawlerservice/cache/entropy.py	/^    bit_list = gen(hashlib.md5)$/;"	v
bit_list	crawlerservice/cache/entropy.py	/^    bit_list = gen(hashlib.sha1)$/;"	v
cal_entropy	crawlerservice/cache/entropy.py	/^def cal_entropy(bit_list):$/;"	f
defaultdict	crawlerservice/cache/entropy.py	/^from collections import defaultdict$/;"	i
division	crawlerservice/cache/entropy.py	/^from __future__ import print_function, division$/;"	i
gen	crawlerservice/cache/entropy.py	/^def gen(func):$/;"	f
hashlib	crawlerservice/cache/entropy.py	/^import hashlib$/;"	i
math	crawlerservice/cache/entropy.py	/^import math$/;"	i
print_function	crawlerservice/cache/entropy.py	/^from __future__ import print_function, division$/;"	i
random	crawlerservice/cache/entropy.py	/^import random$/;"	i
random_str	crawlerservice/cache/entropy.py	/^def random_str():$/;"	f
FSCACHEDIR	crawlerservice/cache/fscache.py	/^from settings import FSCACHEDIR$/;"	i
base64	crawlerservice/cache/fscache.py	/^import base64$/;"	i
cachelog	crawlerservice/cache/fscache.py	/^from crawlerlog import path, cachelog$/;"	i
datetime	crawlerservice/cache/fscache.py	/^from datetime import datetime$/;"	i
division	crawlerservice/cache/fscache.py	/^from __future__ import print_function, division$/;"	i
fs_get_cache	crawlerservice/cache/fscache.py	/^def fs_get_cache(b64url, url_hash, batch_id):$/;"	f
fs_set_cache	crawlerservice/cache/fscache.py	/^def fs_set_cache(b64url, url_hash, batch_id, groups, content, refresh=False):$/;"	f
hashlib	crawlerservice/cache/fscache.py	/^import hashlib$/;"	i
json	crawlerservice/cache/fscache.py	/^import json$/;"	i
os	crawlerservice/cache/fscache.py	/^import os$/;"	i
path	crawlerservice/cache/fscache.py	/^from crawlerlog import path, cachelog$/;"	i
print_function	crawlerservice/cache/fscache.py	/^from __future__ import print_function, division$/;"	i
HPCACHEDIR	crawlerservice/cache/periodcache.py	/^HPCACHEDIR = '\/data\/hproject\/'$/;"	v
base64	crawlerservice/cache/periodcache.py	/^import base64$/;"	i
cachelog	crawlerservice/cache/periodcache.py	/^from crawlerlog import path, cachelog$/;"	i
date	crawlerservice/cache/periodcache.py	/^from datetime import date$/;"	i
datetime	crawlerservice/cache/periodcache.py	/^from datetime import datetime$/;"	i
division	crawlerservice/cache/periodcache.py	/^from __future__ import print_function, division$/;"	i
hashlib	crawlerservice/cache/periodcache.py	/^import hashlib$/;"	i
json	crawlerservice/cache/periodcache.py	/^import json$/;"	i
os	crawlerservice/cache/periodcache.py	/^import os$/;"	i
path	crawlerservice/cache/periodcache.py	/^from crawlerlog import path, cachelog$/;"	i
period_get_cache	crawlerservice/cache/periodcache.py	/^def period_get_cache(url_hash, batch_id):$/;"	f
period_set_cache	crawlerservice/cache/periodcache.py	/^def period_set_cache(url_hash, batch_id, groups, content, refresh=False):$/;"	f
print_function	crawlerservice/cache/periodcache.py	/^from __future__ import print_function, division$/;"	i
access_key	crawlerservice/cache/qiniucache.py	/^from secret import access_key, secret_key$/;"	i
access_with_cache	crawlerservice/cache/qiniucache.py	/^def access_with_cache(qiniukey):$/;"	f
bucket_domain	crawlerservice/cache/qiniucache.py	/^bucket_domain = 'o6kz8oe5r.bkt.clouddn.com'$/;"	v
bucket_name	crawlerservice/cache/qiniucache.py	/^bucket_name = 'crawlercache'$/;"	v
dbwrapper	crawlerservice/cache/qiniucache.py	/^from dbconnector import dbwrapper$/;"	i
division	crawlerservice/cache/qiniucache.py	/^from __future__ import print_function, division$/;"	i
download	crawlerservice/cache/qiniucache.py	/^def download(qiniukey):$/;"	f
print_function	crawlerservice/cache/qiniucache.py	/^from __future__ import print_function, division$/;"	i
qiniu	crawlerservice/cache/qiniucache.py	/^import qiniu$/;"	i
requests	crawlerservice/cache/qiniucache.py	/^import requests$/;"	i
secret_key	crawlerservice/cache/qiniucache.py	/^from secret import access_key, secret_key$/;"	i
upload	crawlerservice/cache/qiniucache.py	/^def upload(source_url, content):$/;"	f
AWS_ACCESS_ID	crawlerservice/cache/s3cache.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	crawlerservice/cache/s3cache.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
FSCACHEDIR	crawlerservice/cache/s3cache.py	/^from settings import FSCACHEDIR$/;"	i
REGION_NAME	crawlerservice/cache/s3cache.py	/^from settings import REGION_NAME$/;"	i
S3	crawlerservice/cache/s3cache.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
base64	crawlerservice/cache/s3cache.py	/^import base64$/;"	i
boto3	crawlerservice/cache/s3cache.py	/^import boto3$/;"	i
botocore	crawlerservice/cache/s3cache.py	/^import botocore$/;"	i
bucket_contents	crawlerservice/cache/s3cache.py	/^def bucket_contents(bucketname):$/;"	f
cachelog	crawlerservice/cache/s3cache.py	/^from crawlerlog import cachelog$/;"	i
create_bucket	crawlerservice/cache/s3cache.py	/^def create_bucket(batch_key):$/;"	f
datetime	crawlerservice/cache/s3cache.py	/^from datetime import datetime$/;"	i
dbwrapper	crawlerservice/cache/s3cache.py	/^from dbconnector import dbwrapper$/;"	i
delete_object	crawlerservice/cache/s3cache.py	/^def delete_object(bucket, key):$/;"	f
division	crawlerservice/cache/s3cache.py	/^from __future__ import print_function, division$/;"	i
ensure_bucket	crawlerservice/cache/s3cache.py	/^def ensure_bucket(batch_key):$/;"	f
get_cache	crawlerservice/cache/s3cache.py	/^    def get_cache(batch_key, filename):$/;"	f	function:s3_get_cache
head_cache	crawlerservice/cache/s3cache.py	/^    def head_cache(batch_key, filename):$/;"	f	function:s3_get_cache
json	crawlerservice/cache/s3cache.py	/^import json$/;"	i
print_function	crawlerservice/cache/s3cache.py	/^from __future__ import print_function, division$/;"	i
put_cache	crawlerservice/cache/s3cache.py	/^    def put_cache(batch_key, filename, content):$/;"	f	function:s3_put_cache
s3_get_cache	crawlerservice/cache/s3cache.py	/^def s3_get_cache(batch_id, url_hash, exists=False):$/;"	f
s3_put_cache	crawlerservice/cache/s3cache.py	/^def s3_put_cache(b64url, url_hash, batch_id, groups, content, refresh=False):$/;"	f
string	crawlerservice/cache/s3cache.py	/^import string$/;"	i
Auth	crawlerservice/cache/ucloud/auth.py	/^class Auth(object):$/;"	c
__checkkey	crawlerservice/cache/ucloud/auth.py	/^    def __checkkey(public_key, private_key):$/;"	m	class:Auth	file:
__init__	crawlerservice/cache/ucloud/auth.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:Auth
_check_dict	crawlerservice/cache/ucloud/auth.py	/^from .util import standard_b64encode, _check_dict$/;"	i
_public_key	crawlerservice/cache/ucloud/auth.py	/^    def _public_key(self):$/;"	m	class:Auth
b	crawlerservice/cache/ucloud/auth.py	/^from .compact import b, s$/;"	i
bucket_signature	crawlerservice/cache/ucloud/auth.py	/^    def bucket_signature(self, query):$/;"	m	class:Auth
hashlib	crawlerservice/cache/ucloud/auth.py	/^import hashlib$/;"	i
hmac	crawlerservice/cache/ucloud/auth.py	/^import hmac$/;"	i
logger	crawlerservice/cache/ucloud/auth.py	/^from .logger import logger$/;"	i
reduce	crawlerservice/cache/ucloud/auth.py	/^from functools import reduce$/;"	i
s	crawlerservice/cache/ucloud/auth.py	/^from .compact import b, s$/;"	i
set_keys	crawlerservice/cache/ucloud/auth.py	/^    def set_keys(self, public_key, private_key):$/;"	m	class:Auth
standard_b64encode	crawlerservice/cache/ucloud/auth.py	/^from .util import standard_b64encode, _check_dict$/;"	i
ufile_authorization	crawlerservice/cache/ucloud/auth.py	/^    def ufile_authorization(self, data):$/;"	m	class:Auth
ufile_signature	crawlerservice/cache/ucloud/auth.py	/^    def ufile_signature(self, data):$/;"	m	class:Auth
BytesIO	crawlerservice/cache/ucloud/compact.py	/^    BytesIO = io.BytesIO$/;"	v
StringIO	crawlerservice/cache/ucloud/compact.py	/^    StringIO = io.StringIO$/;"	v
StringIO	crawlerservice/cache/ucloud/compact.py	/^    import StringIO$/;"	i
_ver	crawlerservice/cache/ucloud/compact.py	/^_ver = sys.version_info$/;"	v
b	crawlerservice/cache/ucloud/compact.py	/^    def b(data):$/;"	f
basestring	crawlerservice/cache/ucloud/compact.py	/^    basestring = (str, bytes)$/;"	v
basestring	crawlerservice/cache/ucloud/compact.py	/^    basestring = basestring  # noqa$/;"	v
builtin_str	crawlerservice/cache/ucloud/compact.py	/^    builtin_str = str$/;"	v
bytes	crawlerservice/cache/ucloud/compact.py	/^    bytes = bytes$/;"	v
bytes	crawlerservice/cache/ucloud/compact.py	/^    bytes = str$/;"	v
io	crawlerservice/cache/ucloud/compact.py	/^    import io$/;"	i
is_py2	crawlerservice/cache/ucloud/compact.py	/^is_py2 = (_ver[0] == 2)$/;"	v
is_py3	crawlerservice/cache/ucloud/compact.py	/^is_py3 = (_ver[0] == 3)$/;"	v
noqa	crawlerservice/cache/ucloud/compact.py	/^    from urllib.parse import urlparse  # noqa$/;"	i
noqa	crawlerservice/cache/ucloud/compact.py	/^    from urlparse import urlparse  # noqa$/;"	i
numeric_types	crawlerservice/cache/ucloud/compact.py	/^    numeric_types = (int, float)$/;"	v
numeric_types	crawlerservice/cache/ucloud/compact.py	/^    numeric_types = (int, long, float)  # noqa$/;"	v
s	crawlerservice/cache/ucloud/compact.py	/^    def s(data):$/;"	f
str	crawlerservice/cache/ucloud/compact.py	/^    str = str$/;"	v
str	crawlerservice/cache/ucloud/compact.py	/^    str = unicode  # noqa$/;"	v
sys	crawlerservice/cache/ucloud/compact.py	/^import sys$/;"	i
u	crawlerservice/cache/ucloud/compact.py	/^    def u(data):$/;"	f
urlparse	crawlerservice/cache/ucloud/compact.py	/^    from urllib.parse import urlparse  # noqa$/;"	i
urlparse	crawlerservice/cache/ucloud/compact.py	/^    from urlparse import urlparse  # noqa$/;"	i
LOG_FILE	crawlerservice/cache/ucloud/logger.py	/^LOG_FILE = 'ufile.log'$/;"	v
_ch	crawlerservice/cache/ucloud/logger.py	/^_ch = logging.StreamHandler()$/;"	v
_formatter	crawlerservice/cache/ucloud/logger.py	/^_formatter = logging.Formatter('[%(asctime)s, %(levelname)s]: %(filename)s-%(lineno)s: %(message)s')$/;"	v
logger	crawlerservice/cache/ucloud/logger.py	/^logger = logging.getLogger("UCLOUD")$/;"	v
logging	crawlerservice/cache/ucloud/logger.py	/^import logging$/;"	i
set_log_file	crawlerservice/cache/ucloud/logger.py	/^def set_log_file(localfile=None):$/;"	f
__version__	crawlerservice/cache/ucloud/ufile/__init__.py	/^__version__ = '2.0.0'$/;"	v
Auth	crawlerservice/cache/ucloud/ufile/baseufile.py	/^from ucloud.auth import Auth$/;"	i
BaseUFile	crawlerservice/cache/ucloud/ufile/baseufile.py	/^class BaseUFile(object):$/;"	c
__canonicalize_resource	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def __canonicalize_resource(self, bucket, key):$/;"	m	class:BaseUFile	file:
__canonicalize_ucloud_headers	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def __canonicalize_ucloud_headers(self, header):$/;"	m	class:BaseUFile	file:
__digest_authorization_data	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def __digest_authorization_data(self, method, bucket, key, header=None, mime_type=None):$/;"	m	class:BaseUFile	file:
__digest_signature_data	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def __digest_signature_data(self, bucket, key, method='get', header=None, mime_type=None):$/;"	m	class:BaseUFile	file:
__init__	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:BaseUFile
_check_dict	crawlerservice/cache/ucloud/ufile/baseufile.py	/^from ucloud.util import _check_dict$/;"	i
_public_key	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def _public_key(self):$/;"	m	class:BaseUFile
authorization	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def authorization(self, method, bucket, key, header=None, mime_type=None):$/;"	m	class:BaseUFile
set_keys	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def set_keys(self, public_key, private_key):$/;"	m	class:BaseUFile
signature	crawlerservice/cache/ucloud/ufile/baseufile.py	/^    def signature(self, bucket, key, method="get", header=None, mime_type=None):$/;"	m	class:BaseUFile
string	crawlerservice/cache/ucloud/ufile/baseufile.py	/^import string$/;"	i
Auth	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.auth import Auth$/;"	i
BucketManager	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^class BucketManager(object):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.ufile.httprequest import _bucket_request, ResponseInfo$/;"	i
UCLOUD_API_URL	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.ufile.config import UCLOUD_API_URL$/;"	i
__init__	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:BucketManager
_bucket_request	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.ufile.httprequest import _bucket_request, ResponseInfo$/;"	i
_check_dict	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.util import _check_dict$/;"	i
config	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.ufile import config$/;"	i
createbucket	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def createbucket(self, bucket, buckettype='private', domainlist=None, header=None):$/;"	m	class:BucketManager
deletebucket	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def deletebucket(self, bucket, header=None):$/;"	m	class:BucketManager
describebucket	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def describebucket(self, bucket=None, offset=0, limit=10, header=None):$/;"	m	class:BucketManager
getfilelist	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def getfilelist(self, bucket, offset=0, limit=20, header=None):$/;"	m	class:BucketManager
logger	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.logger import logger$/;"	i
s	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^from ucloud.compact import s$/;"	i
set_keys	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def set_keys(self, public_key, private_key):$/;"	m	class:BucketManager
updatebucket	crawlerservice/cache/ucloud/ufile/bucketmanager.py	/^    def updatebucket(self, bucket, buckettype, header=None):$/;"	m	class:BucketManager
BLOCKSIZE	crawlerservice/cache/ucloud/ufile/config.py	/^BLOCKSIZE = 1024 * 1024 * 4$/;"	v
UCLOUD_API_URL	crawlerservice/cache/ucloud/ufile/config.py	/^UCLOUD_API_URL = 'http:\/\/api.ucloud.cn'$/;"	v
UCLOUD_DOWNLOAD_SUFFIX	crawlerservice/cache/ucloud/ufile/config.py	/^UCLOUD_DOWNLOAD_SUFFIX = '.ufile.ucloud.cn'$/;"	v
UCLOUD_PROXY_SUFFIX	crawlerservice/cache/ucloud/ufile/config.py	/^UCLOUD_PROXY_SUFFIX = '.ufile.ucloud.cn'$/;"	v
USER_AGENT	crawlerservice/cache/ucloud/ufile/config.py	/^USER_AGENT = 'UCloud Python SDK {0} ({1} : Python\/{2})'.format(__version__, _sys_info, _python_ver)$/;"	v
__version__	crawlerservice/cache/ucloud/ufile/config.py	/^from . import __version__$/;"	i
_config	crawlerservice/cache/ucloud/ufile/config.py	/^_config = {$/;"	v
_python_ver	crawlerservice/cache/ucloud/ufile/config.py	/^_python_ver = platform.python_version()$/;"	v
_sys_info	crawlerservice/cache/ucloud/ufile/config.py	/^_sys_info = '{0}: {1}'.format(platform.system(), platform.machine())$/;"	v
get_default	crawlerservice/cache/ucloud/ufile/config.py	/^def get_default(key):$/;"	f
platform	crawlerservice/cache/ucloud/ufile/config.py	/^import platform$/;"	i
set_default	crawlerservice/cache/ucloud/ufile/config.py	/^def set_default(connection_timeout=None, expires=None, user_agent=None, uploadsuffix=None, downloadsuffix=None):$/;"	f
BaseUFile	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from .baseufile import BaseUFile$/;"	i
DeleteUFile	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^class DeleteUFile(BaseUFile):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from .httprequest import ResponseInfo, _delete_file$/;"	i
__init__	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:DeleteUFile
_check_dict	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from ucloud.util import _check_dict, ufile_put_url$/;"	i
_delete_file	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from .httprequest import ResponseInfo, _delete_file$/;"	i
config	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from ucloud.ufile import config$/;"	i
deletefile	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^    def deletefile(self, bucket, key, header=None):$/;"	m	class:DeleteUFile
logger	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from ucloud.logger import logger$/;"	i
ufile_put_url	crawlerservice/cache/ucloud/ufile/deleteufile.py	/^from ucloud.util import _check_dict, ufile_put_url$/;"	i
BaseUFile	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from .baseufile import BaseUFile$/;"	i
DownloadUFile	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^class DownloadUFile(BaseUFile):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from .httprequest import ResponseInfo, _download_file$/;"	i
__init__	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:DownloadUFile
_check_dict	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from ucloud.util import _check_dict$/;"	i
_download_file	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from .httprequest import ResponseInfo, _download_file$/;"	i
config	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from ucloud.ufile import config$/;"	i
download_file	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def download_file(self, bucket, key, localfile, isprivate=True, expires=config.get_default('expires'), content_range=None, header=None):$/;"	m	class:DownloadUFile
download_stream	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def download_stream(self, bucket, key, isprivate=True, expires=config.get_default('expires'), content_range=None, header=None):$/;"	m	class:DownloadUFile
logger	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from ucloud.logger import logger$/;"	i
os	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^import os$/;"	i
private_download_url	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def private_download_url(self, bucket, key, expires=config.get_default('expires'), header=None, internal=False):$/;"	m	class:DownloadUFile
private_head_url	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def private_head_url(self, bucket, key, expires=config.get_default('expires'), header=None):$/;"	m	class:DownloadUFile
public_download_url	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^    def public_download_url(self, bucket, key):$/;"	m	class:DownloadUFile
requests	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^        import requests$/;"	i
s	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^from ucloud.compact import s$/;"	i
time	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^import time$/;"	i
urllib	crawlerservice/cache/ucloud/ufile/downloadufile.py	/^import urllib$/;"	i
ResponseInfo	crawlerservice/cache/ucloud/ufile/httprequest.py	/^class ResponseInfo(object):$/;"	c
__init__	crawlerservice/cache/ucloud/ufile/httprequest.py	/^    def __init__(self, response, exception=None, content_consumed=False):$/;"	m	class:ResponseInfo
__repr__	crawlerservice/cache/ucloud/ufile/httprequest.py	/^    def __repr__(self):$/;"	m	class:ResponseInfo	file:
__return_wraper	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def __return_wraper(response, content_consumed=False):$/;"	f	file:
__str__	crawlerservice/cache/ucloud/ufile/httprequest.py	/^    def __str__(self):$/;"	m	class:ResponseInfo	file:
_bucket_request	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _bucket_request(url, param, header):$/;"	f
_delete_file	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _delete_file(url, header):$/;"	f
_download_file	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _download_file(url, header, localfile):$/;"	f
_finishsharding	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _finishsharding(url, param, header, data):$/;"	f
_initialsharding	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _initialsharding(url, header):$/;"	f
_post_file	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _post_file(url, header, data):$/;"	f
_put_file	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _put_file(url, header, uploadfile):$/;"	f
_put_stream	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _put_stream(url, header, data):$/;"	f
_shardingupload	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _shardingupload(url, data, header):$/;"	f
_uploadhit_file	crawlerservice/cache/ucloud/ufile/httprequest.py	/^def _uploadhit_file(url, header, params):$/;"	f
config	crawlerservice/cache/ucloud/ufile/httprequest.py	/^from ucloud.ufile import config$/;"	i
logger	crawlerservice/cache/ucloud/ufile/httprequest.py	/^from ucloud.logger import logger$/;"	i
need_retry	crawlerservice/cache/ucloud/ufile/httprequest.py	/^    def need_retry(self):$/;"	m	class:ResponseInfo
ok	crawlerservice/cache/ucloud/ufile/httprequest.py	/^    def ok(self):$/;"	m	class:ResponseInfo
re	crawlerservice/cache/ucloud/ufile/httprequest.py	/^import re$/;"	i
requests	crawlerservice/cache/ucloud/ufile/httprequest.py	/^import requests$/;"	i
CompleteMimeTypes	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^CompleteMimeTypes = {$/;"	v
Mimetype	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^class Mimetype(object):$/;"	c
__init__	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^    def __init__(self):$/;"	m	class:Mimetype
from_buffer	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^    def from_buffer(stream):$/;"	m	class:Mimetype
from_file	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^    def from_file(file):$/;"	m	class:Mimetype
mimetypes	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^import mimetypes$/;"	i
path	crawlerservice/cache/ucloud/ufile/magicwrapper.py	/^from os import path$/;"	i
BaseUFile	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .baseufile import BaseUFile$/;"	i
Mimetype	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .magicwrapper import Mimetype$/;"	i
MultipartUploadUFile	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^class MultipartUploadUFile(BaseUFile):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .httprequest import ResponseInfo, _initialsharding, _finishsharding, _shardingupload$/;"	i
__finishupload	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def __finishupload(self):$/;"	m	class:MultipartUploadUFile	file:
__init__	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:MultipartUploadUFile
__initialsharding	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def __initialsharding(self):$/;"	m	class:MultipartUploadUFile	file:
_check_dict	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.util import _check_dict, initialsharding_url, finishsharding_url, shardingupload_url, _file_iter$/;"	i
_file_iter	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.util import _check_dict, initialsharding_url, finishsharding_url, shardingupload_url, _file_iter$/;"	i
_finishsharding	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .httprequest import ResponseInfo, _initialsharding, _finishsharding, _shardingupload$/;"	i
_initialsharding	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .httprequest import ResponseInfo, _initialsharding, _finishsharding, _shardingupload$/;"	i
_shardingupload	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from .httprequest import ResponseInfo, _initialsharding, _finishsharding, _shardingupload$/;"	i
config	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.ufile import config$/;"	i
finishsharding_url	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.util import _check_dict, initialsharding_url, finishsharding_url, shardingupload_url, _file_iter$/;"	i
initialsharding_url	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.util import _check_dict, initialsharding_url, finishsharding_url, shardingupload_url, _file_iter$/;"	i
json	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^import json$/;"	i
logger	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.logger import logger$/;"	i
os	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^import os$/;"	i
resumeuploadfile	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def resumeuploadfile(self, retrycount=3, retryinterval=5, bucket=None, key=None, uploadid=None, blocksize=None, etaglist=None, localfile=None, pausepartnumber=None, mime_type=None, header=None):$/;"	m	class:MultipartUploadUFile
resumeuploadstream	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def resumeuploadstream(self, retrycount=3, retryinterval=5, bucket=None, key=None, uploadid=None, blocksize=None, etaglist=None, stream=None, pausepartnumber=None, mime_type=None, header=None):$/;"	m	class:MultipartUploadUFile
s	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.compact import s$/;"	i
shardingupload_url	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^from ucloud.util import _check_dict, initialsharding_url, finishsharding_url, shardingupload_url, _file_iter$/;"	i
time	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^import time$/;"	i
uploadfile	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def uploadfile(self, bucket, key, localfile, retrycount=3, retryinterval=5, header=None):$/;"	m	class:MultipartUploadUFile
uploadstream	crawlerservice/cache/ucloud/ufile/multipartuploadufile.py	/^    def uploadstream(self, bucket, key, stream, retrycount=3, retryinterval=5, mime_type=None, header=None):$/;"	m	class:MultipartUploadUFile
BaseUFile	crawlerservice/cache/ucloud/ufile/postufile.py	/^from .baseufile import BaseUFile$/;"	i
Mimetype	crawlerservice/cache/ucloud/ufile/postufile.py	/^from .magicwrapper import Mimetype$/;"	i
PostUFile	crawlerservice/cache/ucloud/ufile/postufile.py	/^class PostUFile(BaseUFile):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/postufile.py	/^from .httprequest import ResponseInfo, _post_file$/;"	i
__init__	crawlerservice/cache/ucloud/ufile/postufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:PostUFile
__make_boundary	crawlerservice/cache/ucloud/ufile/postufile.py	/^    def __make_boundary(self):$/;"	m	class:PostUFile	file:
__make_postbody	crawlerservice/cache/ucloud/ufile/postufile.py	/^    def __make_postbody(self, boundary, fields, stream, mime_type, localfile):$/;"	m	class:PostUFile	file:
_check_dict	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.util import _check_dict, ufile_post_url$/;"	i
_post_file	crawlerservice/cache/ucloud/ufile/postufile.py	/^from .httprequest import ResponseInfo, _post_file$/;"	i
b	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.compact import b, s, u$/;"	i
config	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.ufile import config$/;"	i
hashlib	crawlerservice/cache/ucloud/ufile/postufile.py	/^import hashlib$/;"	i
logger	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.logger import logger$/;"	i
os	crawlerservice/cache/ucloud/ufile/postufile.py	/^import os$/;"	i
postfile	crawlerservice/cache/ucloud/ufile/postufile.py	/^    def postfile(self, bucket, key, localfile, header=None):$/;"	m	class:PostUFile
s	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.compact import b, s, u$/;"	i
time	crawlerservice/cache/ucloud/ufile/postufile.py	/^import time$/;"	i
u	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.compact import b, s, u$/;"	i
ufile_post_url	crawlerservice/cache/ucloud/ufile/postufile.py	/^from ucloud.util import _check_dict, ufile_post_url$/;"	i
BaseUFile	crawlerservice/cache/ucloud/ufile/putufile.py	/^from .baseufile import BaseUFile$/;"	i
Mimetype	crawlerservice/cache/ucloud/ufile/putufile.py	/^from .magicwrapper import Mimetype$/;"	i
PutUFile	crawlerservice/cache/ucloud/ufile/putufile.py	/^class PutUFile(BaseUFile):$/;"	c
ResponseInfo	crawlerservice/cache/ucloud/ufile/putufile.py	/^from .httprequest import _put_stream, _put_file, ResponseInfo$/;"	i
__init__	crawlerservice/cache/ucloud/ufile/putufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:PutUFile
_check_dict	crawlerservice/cache/ucloud/ufile/putufile.py	/^from ucloud.util import _check_dict, ufile_put_url$/;"	i
_put_file	crawlerservice/cache/ucloud/ufile/putufile.py	/^from .httprequest import _put_stream, _put_file, ResponseInfo$/;"	i
_put_stream	crawlerservice/cache/ucloud/ufile/putufile.py	/^from .httprequest import _put_stream, _put_file, ResponseInfo$/;"	i
config	crawlerservice/cache/ucloud/ufile/putufile.py	/^from ucloud.ufile import config$/;"	i
json	crawlerservice/cache/ucloud/ufile/putufile.py	/^import json$/;"	i
logger	crawlerservice/cache/ucloud/ufile/putufile.py	/^from ucloud.logger import logger$/;"	i
os	crawlerservice/cache/ucloud/ufile/putufile.py	/^import os$/;"	i
putfile	crawlerservice/cache/ucloud/ufile/putufile.py	/^    def putfile(self, bucket, key, localfile, header=None):$/;"	m	class:PutUFile
putstream	crawlerservice/cache/ucloud/ufile/putufile.py	/^    def putstream(self, bucket, key, stream, mime_type=None, header=None):$/;"	m	class:PutUFile
s	crawlerservice/cache/ucloud/ufile/putufile.py	/^from ucloud.compact import s$/;"	i
ufile_put_url	crawlerservice/cache/ucloud/ufile/putufile.py	/^from ucloud.util import _check_dict, ufile_put_url$/;"	i
BLOCKSIZE	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.ufile.config import BLOCKSIZE$/;"	i
BaseUFile	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from .baseufile import BaseUFile$/;"	i
Mimetype	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from .magicwrapper import Mimetype$/;"	i
ResponseInfo	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from .httprequest import ResponseInfo, _uploadhit_file$/;"	i
UploadHitUFile	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^class UploadHitUFile(BaseUFile):$/;"	c
__init__	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^    def __init__(self, public_key, private_key):$/;"	m	class:UploadHitUFile
_check_dict	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.util import file_etag, _check_dict, ufile_uploadhit_url$/;"	i
_uploadhit_file	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from .httprequest import ResponseInfo, _uploadhit_file$/;"	i
config	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.ufile import config$/;"	i
file_etag	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.util import file_etag, _check_dict, ufile_uploadhit_url$/;"	i
logger	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.logger import logger$/;"	i
os	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^import os$/;"	i
s	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.compact import s$/;"	i
ufile_uploadhit_url	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^from ucloud.util import file_etag, _check_dict, ufile_uploadhit_url$/;"	i
uploadhit	crawlerservice/cache/ucloud/ufile/uploadhitufile.py	/^    def uploadhit(self, bucket, key, localfile, header=None):$/;"	m	class:UploadHitUFile
_check_dict	crawlerservice/cache/ucloud/util.py	/^def _check_dict(data):$/;"	f
_file_iter	crawlerservice/cache/ucloud/util.py	/^def _file_iter(input_stream, size):$/;"	f
base64	crawlerservice/cache/ucloud/util.py	/^import base64$/;"	i
config	crawlerservice/cache/ucloud/util.py	/^from ucloud.ufile import config$/;"	i
file_etag	crawlerservice/cache/ucloud/util.py	/^def file_etag(localfile, size):$/;"	f
finishsharding_url	crawlerservice/cache/ucloud/util.py	/^def finishsharding_url(bucket, key):$/;"	f
hashlib	crawlerservice/cache/ucloud/util.py	/^import hashlib$/;"	i
initialsharding_url	crawlerservice/cache/ucloud/util.py	/^def initialsharding_url(bucket, key):$/;"	f
os	crawlerservice/cache/ucloud/util.py	/^import os$/;"	i
shardingupload_url	crawlerservice/cache/ucloud/util.py	/^def shardingupload_url(bucket, key, uploadid, part_number):$/;"	f
standard_b64decode	crawlerservice/cache/ucloud/util.py	/^def standard_b64decode(data):$/;"	f
standard_b64encode	crawlerservice/cache/ucloud/util.py	/^def standard_b64encode(data):$/;"	f
struct	crawlerservice/cache/ucloud/util.py	/^import struct$/;"	i
ufile_post_url	crawlerservice/cache/ucloud/util.py	/^def ufile_post_url(bucket):$/;"	f
ufile_put_url	crawlerservice/cache/ucloud/util.py	/^def ufile_put_url(bucket, key):$/;"	f
ufile_uploadhit_url	crawlerservice/cache/ucloud/util.py	/^def ufile_uploadhit_url(bucket):$/;"	f
urlsafe_b64decode	crawlerservice/cache/ucloud/util.py	/^def urlsafe_b64decode(data):$/;"	f
urlsafe_b64encode	crawlerservice/cache/ucloud/util.py	/^def urlsafe_b64encode(data):$/;"	f
FSCACHEDIR	crawlerservice/cache/ufilecache.py	/^from settings import FSCACHEDIR$/;"	i
StringIO	crawlerservice/cache/ufilecache.py	/^from cStringIO import StringIO$/;"	i
base64	crawlerservice/cache/ufilecache.py	/^import base64$/;"	i
bucketmanager	crawlerservice/cache/ufilecache.py	/^from ucloud.ufile import bucketmanager$/;"	i
cachelog	crawlerservice/cache/ufilecache.py	/^from crawlerlog import cachelog$/;"	i
datetime	crawlerservice/cache/ufilecache.py	/^from datetime import datetime$/;"	i
dbwrapper	crawlerservice/cache/ufilecache.py	/^from dbconnector import dbwrapper$/;"	i
division	crawlerservice/cache/ufilecache.py	/^from __future__ import print_function, division$/;"	i
downloadufile	crawlerservice/cache/ufilecache.py	/^from ucloud.ufile import putufile, downloadufile$/;"	i
ensure_bucket	crawlerservice/cache/ufilecache.py	/^def ensure_bucket(batch_key):$/;"	f
hashlib	crawlerservice/cache/ufilecache.py	/^import hashlib$/;"	i
json	crawlerservice/cache/ufilecache.py	/^import json$/;"	i
print_function	crawlerservice/cache/ufilecache.py	/^from __future__ import print_function, division$/;"	i
private_key	crawlerservice/cache/ufilecache.py	/^from secret import public_key, private_key$/;"	i
public_key	crawlerservice/cache/ufilecache.py	/^from secret import public_key, private_key$/;"	i
putufile	crawlerservice/cache/ufilecache.py	/^from ucloud.ufile import putufile, downloadufile$/;"	i
requests	crawlerservice/cache/ufilecache.py	/^import requests$/;"	i
string	crawlerservice/cache/ufilecache.py	/^import string$/;"	i
ufile_get_cache	crawlerservice/cache/ufilecache.py	/^def ufile_get_cache(batch_id, url_hash):$/;"	f
ufile_set_cache	crawlerservice/cache/ufilecache.py	/^def ufile_set_cache(b64url, url_hash, batch_id, groups, content, refresh=False):$/;"	f
division	crawlerservice/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
filename_in_logger_out	crawlerservice/crawlerlog/cachelog.py	/^    def filename_in_logger_out(the_batch_id, cachedir):$/;"	f	function:get_logger
get_logger	crawlerservice/crawlerlog/cachelog.py	/^def get_logger(batch_id, today_str, cachedir='.'):$/;"	f
ip	crawlerservice/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
log	crawlerservice/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
logging	crawlerservice/crawlerlog/cachelog.py	/^import logging$/;"	i
os	crawlerservice/crawlerlog/cachelog.py	/^import os$/;"	i
path	crawlerservice/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
print_function	crawlerservice/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
division	crawlerservice/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
get_local_ip_address	crawlerservice/crawlerlog/ip.py	/^def get_local_ip_address():$/;"	f
print_function	crawlerservice/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
socket	crawlerservice/crawlerlog/ip.py	/^import socket$/;"	i
handlers	crawlerservice/crawlerlog/log.py	/^    import logging.handlers$/;"	i
init	crawlerservice/crawlerlog/log.py	/^def init(log_name, log_file, level=logging.DEBUG, size=1024*1024, count=10):$/;"	f
log_print	crawlerservice/crawlerlog/log.py	/^def log_print(msg, logger=None, level=logging.ERROR):$/;"	f
log_traceback	crawlerservice/crawlerlog/log.py	/^def log_traceback(logger=None, msg=None):$/;"	f
logging	crawlerservice/crawlerlog/log.py	/^    import logging.handlers$/;"	i
logging	crawlerservice/crawlerlog/log.py	/^import logging$/;"	i
sys	crawlerservice/crawlerlog/log.py	/^    import sys, traceback$/;"	i
traceback	crawlerservice/crawlerlog/log.py	/^    import sys, traceback$/;"	i
division	crawlerservice/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
makedir	crawlerservice/crawlerlog/path.py	/^def makedir(absdir):$/;"	f
os	crawlerservice/crawlerlog/path.py	/^import os$/;"	i
print_function	crawlerservice/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
PGWrapper	crawlerservice/dbconnector.py	/^from pgwrapper import PGWrapper$/;"	i
dbwrapper	crawlerservice/dbconnector.py	/^dbwrapper = PGWrapper(dbname=DBNAME,$/;"	v
division	crawlerservice/dbconnector.py	/^from __future__ import print_function, division$/;"	i
host	crawlerservice/dbconnector.py	/^                      host=DBHOST,$/;"	v
password	crawlerservice/dbconnector.py	/^                      password=DBPASS,$/;"	v
port	crawlerservice/dbconnector.py	/^                      port=DBPORT)$/;"	v
print_function	crawlerservice/dbconnector.py	/^from __future__ import print_function, division$/;"	i
user	crawlerservice/dbconnector.py	/^                      user=DBUSER,$/;"	v
division	crawlerservice/exception.py	/^from __future__ import print_function, division$/;"	i
exception	crawlerservice/exception.py	/^def exception(func):$/;"	f
exe_function	crawlerservice/exception.py	/^    def exe_function(self, *args, **kwargs):$/;"	f	function:exception
print_function	crawlerservice/exception.py	/^from __future__ import print_function, division$/;"	i
DBPASS	crawlerservice/fabfile.py	/^from settings import DBPASS$/;"	i
DEPLOY_ENV	crawlerservice/fabfile.py	/^DEPLOY_ENV = 'HCRAWLER'$/;"	v
PG_VERSION	crawlerservice/fabfile.py	/^    PG_VERSION = 'jessie-pgdg'$/;"	v
PG_VERSION	crawlerservice/fabfile.py	/^    PG_VERSION = 'trusty-pgdg'$/;"	v
_aws	crawlerservice/fabfile.py	/^def _aws():$/;"	f
_build_pg	crawlerservice/fabfile.py	/^def _build_pg():$/;"	f
build_env	crawlerservice/fabfile.py	/^def build_env():$/;"	f
deploy	crawlerservice/fabfile.py	/^def deploy():$/;"	f
division	crawlerservice/fabfile.py	/^from __future__ import print_function, division$/;"	i
hostos	crawlerservice/fabfile.py	/^hostos = 'debian'$/;"	v
kill	crawlerservice/fabfile.py	/^def kill():$/;"	f
print_function	crawlerservice/fabfile.py	/^from __future__ import print_function, division$/;"	i
runapp	crawlerservice/fabfile.py	/^def runapp():$/;"	f
upload	crawlerservice/fabfile.py	/^def upload():$/;"	f
AGENTS	crawlerservice/fetch/agents.py	/^AGENTS=["Mozilla\/5.0 (X11; Linux x86_64; rv:27.0) Gecko\/20100101 Firefox\/27.0"]$/;"	v
AGENTS_ALL	crawlerservice/fetch/agents.py	/^AGENTS_ALL = [$/;"	v
AGENT_GOOGLE_IMAGE	crawlerservice/fetch/agents.py	/^AGENT_GOOGLE_IMAGE=["Googlebot-Image\/1.0"]$/;"	v
CACHE_SERVER	crawlerservice/fetch/cache.py	/^from settings import CACHE_SERVER$/;"	i
Cache	crawlerservice/fetch/cache.py	/^class Cache(object):$/;"	c
__init__	crawlerservice/fetch/cache.py	/^    def __init__(self, batch_id, server=None):$/;"	m	class:Cache
base64	crawlerservice/fetch/cache.py	/^import base64$/;"	i
division	crawlerservice/fetch/cache.py	/^from __future__ import print_function, division$/;"	i
get	crawlerservice/fetch/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	crawlerservice/fetch/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	crawlerservice/fetch/cache.py	/^from __future__ import print_function, division$/;"	i
requests	crawlerservice/fetch/cache.py	/^import requests$/;"	i
urlparse	crawlerservice/fetch/cache.py	/^import urlparse$/;"	i
Cache	crawlerservice/fetch/downloader.py	/^from cache import Cache$/;"	i
Downloader	crawlerservice/fetch/downloader.py	/^class Downloader(object):$/;"	c
Proxy	crawlerservice/fetch/downloader.py	/^from proxy import Proxy$/;"	i
__init__	crawlerservice/fetch/downloader.py	/^    def __init__(self, request=False, gap=0, batch_id='', groups=None, refresh=False):$/;"	m	class:Downloader
_get_sleep_period	crawlerservice/fetch/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
choice_agent	crawlerservice/fetch/downloader.py	/^from header import choice_agent, choice_proxy, common_header$/;"	i
choice_proxy	crawlerservice/fetch/downloader.py	/^from header import choice_agent, choice_proxy, common_header$/;"	i
close	crawlerservice/fetch/downloader.py	/^    def close(self):$/;"	m	class:Downloader
common_header	crawlerservice/fetch/downloader.py	/^from header import choice_agent, choice_proxy, common_header$/;"	i
division	crawlerservice/fetch/downloader.py	/^from __future__ import print_function, division$/;"	i
log_traceback	crawlerservice/fetch/downloader.py	/^from crawlerlog.log import log_traceback$/;"	i
login	crawlerservice/fetch/downloader.py	/^    def login(self):$/;"	m	class:Downloader
pick_cookie_agent_proxy	crawlerservice/fetch/downloader.py	/^    def pick_cookie_agent_proxy(self, url):$/;"	m	class:Downloader
print_function	crawlerservice/fetch/downloader.py	/^from __future__ import print_function, division$/;"	i
request_download	crawlerservice/fetch/downloader.py	/^    def request_download(self, url, method='get', encode='utf-8', redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	crawlerservice/fetch/downloader.py	/^import requests$/;"	i
requests_with_cache	crawlerservice/fetch/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	crawlerservice/fetch/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	crawlerservice/fetch/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
sys	crawlerservice/fetch/downloader.py	/^import sys$/;"	i
time	crawlerservice/fetch/downloader.py	/^import time$/;"	i
update_header	crawlerservice/fetch/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
AGENTS_ALL	crawlerservice/fetch/header.py	/^from agents import AGENTS_ALL$/;"	i
Proxy	crawlerservice/fetch/header.py	/^from proxy import Proxy$/;"	i
choice_agent	crawlerservice/fetch/header.py	/^def choice_agent():$/;"	f
choice_proxy	crawlerservice/fetch/header.py	/^def choice_proxy(url, gap=0):$/;"	f
common_header	crawlerservice/fetch/header.py	/^common_header = {$/;"	v
division	crawlerservice/fetch/header.py	/^from __future__ import print_function, division$/;"	i
print_function	crawlerservice/fetch/header.py	/^from __future__ import print_function, division$/;"	i
random	crawlerservice/fetch/header.py	/^import random$/;"	i
time	crawlerservice/fetch/header.py	/^import time$/;"	i
PROXY_SERVER	crawlerservice/fetch/proxy.py	/^from settings import PROXY_SERVER$/;"	i
Proxy	crawlerservice/fetch/proxy.py	/^class Proxy(object):$/;"	c
__init__	crawlerservice/fetch/proxy.py	/^    def __init__(self, server=None):$/;"	m	class:Proxy
base64	crawlerservice/fetch/proxy.py	/^import base64$/;"	i
division	crawlerservice/fetch/proxy.py	/^from __future__ import print_function, division$/;"	i
get	crawlerservice/fetch/proxy.py	/^    def get(self, url, max_last_time):$/;"	m	class:Proxy
instance	crawlerservice/fetch/proxy.py	/^    def instance(cls, server=None):$/;"	m	class:Proxy
post	crawlerservice/fetch/proxy.py	/^    def post(self, url, proxy):$/;"	m	class:Proxy
print_function	crawlerservice/fetch/proxy.py	/^from __future__ import print_function, division$/;"	i
requests	crawlerservice/fetch/proxy.py	/^import requests$/;"	i
urlparse	crawlerservice/fetch/proxy.py	/^import urlparse$/;"	i
BaseCache	crawlerservice/handler.py	/^from cache.basecache import BaseCache$/;"	i
CacheHandler	crawlerservice/handler.py	/^class CacheHandler(tornado.web.RequestHandler):$/;"	c
Downloader	crawlerservice/handler.py	/^from fetch.downloader import Downloader$/;"	i
FetchHandler	crawlerservice/handler.py	/^class FetchHandler(tornado.web.RequestHandler):$/;"	c
MissingParameter	crawlerservice/handler.py	/^class MissingParameter(Exception): pass$/;"	c
ProxyDataStructureHandler	crawlerservice/handler.py	/^class ProxyDataStructureHandler(tornado.web.RequestHandler):$/;"	c
ProxyHandler	crawlerservice/handler.py	/^class ProxyHandler(tornado.web.RequestHandler):$/;"	c
ProxyPool	crawlerservice/handler.py	/^from proxy.proxypool import ProxyPool$/;"	i
base64	crawlerservice/handler.py	/^import base64$/;"	i
division	crawlerservice/handler.py	/^from __future__ import print_function, division$/;"	i
exception	crawlerservice/handler.py	/^import exception$/;"	i
get	crawlerservice/handler.py	/^    def get(self):$/;"	m	class:ProxyDataStructureHandler
get	crawlerservice/handler.py	/^    def get(self, b64url, batch_id):$/;"	m	class:CacheHandler
get	crawlerservice/handler.py	/^    def get(self, b64url, max_last_time):$/;"	m	class:ProxyHandler
get	crawlerservice/handler.py	/^    def get(self, method, b64url):$/;"	m	class:FetchHandler
json	crawlerservice/handler.py	/^import json$/;"	i
post	crawlerservice/handler.py	/^    def post(self, b64url, batch_id):$/;"	m	class:CacheHandler
post	crawlerservice/handler.py	/^    def post(self, b64url, useless):$/;"	m	class:ProxyHandler
print_function	crawlerservice/handler.py	/^from __future__ import print_function, division$/;"	i
tornado	crawlerservice/handler.py	/^import tornado.web$/;"	i
web	crawlerservice/handler.py	/^import tornado.web$/;"	i
CONCURRENT_NUM	crawlerservice/main.py	/^from settings import CONCURRENT_NUM$/;"	i
Future	crawlerservice/main.py	/^from tornado.concurrent import Future$/;"	i
define	crawlerservice/main.py	/^from tornado.options import define, options$/;"	i
deque	crawlerservice/main.py	/^from collections import deque$/;"	i
division	crawlerservice/main.py	/^from __future__ import print_function, division$/;"	i
gen	crawlerservice/main.py	/^from tornado import gen$/;"	i
http_server	crawlerservice/main.py	/^    http_server = tornado.httpserver.HTTPServer(urls, xheaders=True)$/;"	v
httpserver	crawlerservice/main.py	/^import tornado.httpserver$/;"	i
ioloop	crawlerservice/main.py	/^import tornado.ioloop$/;"	i
options	crawlerservice/main.py	/^from tornado.options import define, options$/;"	i
prepare_checkproxy	crawlerservice/main.py	/^def prepare_checkproxy():$/;"	f
print_function	crawlerservice/main.py	/^from __future__ import print_function, division$/;"	i
simulator	crawlerservice/main.py	/^    def simulator(futures):$/;"	f	function:prepare_checkproxy
tornado	crawlerservice/main.py	/^import tornado.httpserver$/;"	i
tornado	crawlerservice/main.py	/^import tornado.ioloop$/;"	i
urls	crawlerservice/main.py	/^from router import urls$/;"	i
CurlAsyncHTTPClient	crawlerservice/phantomjs/phantomfetcher.py	/^from tornado.curl_httpclient import CurlAsyncHTTPClient$/;"	i
PhantomFetcher	crawlerservice/phantomjs/phantomfetcher.py	/^class PhantomFetcher(object):$/;"	c
__init__	crawlerservice/phantomjs/phantomfetcher.py	/^    def __init__(self,$/;"	m	class:PhantomFetcher
copy	crawlerservice/phantomjs/phantomfetcher.py	/^import copy$/;"	i
default_options	crawlerservice/phantomjs/phantomfetcher.py	/^    default_options = {$/;"	v	class:PhantomFetcher
division	crawlerservice/phantomjs/phantomfetcher.py	/^from __future__ import print_function, division$/;"	i
fetch	crawlerservice/phantomjs/phantomfetcher.py	/^    def fetch(self, url, **kwargs):$/;"	m	class:PhantomFetcher
fetcher	crawlerservice/phantomjs/phantomfetcher.py	/^    fetcher = PhantomFetcher('http:\/\/localhost:8001', async=False)$/;"	v	class:PhantomFetcher
handle_error	crawlerservice/phantomjs/phantomfetcher.py	/^        def handle_error(error):$/;"	f	function:PhantomFetcher.fetch
handle_response	crawlerservice/phantomjs/phantomfetcher.py	/^        def handle_response(response):$/;"	f	function:PhantomFetcher.fetch
httpclient	crawlerservice/phantomjs/phantomfetcher.py	/^import tornado.httpclient$/;"	i
ioloop	crawlerservice/phantomjs/phantomfetcher.py	/^import tornado.ioloop$/;"	i
json	crawlerservice/phantomjs/phantomfetcher.py	/^import json$/;"	i
parse_option	crawlerservice/phantomjs/phantomfetcher.py	/^    def parse_option(self, url, method='GET', **kwargs):$/;"	m	class:PhantomFetcher
print_function	crawlerservice/phantomjs/phantomfetcher.py	/^from __future__ import print_function, division$/;"	i
res	crawlerservice/phantomjs/phantomfetcher.py	/^    res = fetcher.fetch(url)$/;"	v	class:PhantomFetcher
time	crawlerservice/phantomjs/phantomfetcher.py	/^import time$/;"	i
tornado	crawlerservice/phantomjs/phantomfetcher.py	/^import tornado.httpclient$/;"	i
tornado	crawlerservice/phantomjs/phantomfetcher.py	/^import tornado.ioloop$/;"	i
url	crawlerservice/phantomjs/phantomfetcher.py	/^    url = url.format( urllib.quote('三加二十') )$/;"	v	class:PhantomFetcher
urllib	crawlerservice/phantomjs/phantomfetcher.py	/^    import urllib$/;"	i
console.debug	crawlerservice/phantomjs/phantomjs_fetcher.js	/^  console.debug = function(){};$/;"	f
port	crawlerservice/phantomjs/phantomjs_fetcher.js	/^var port, server, service,$/;"	v
GetWorker	crawlerservice/prefetch/worker.py	/^class GetWorker(Worker):$/;"	c
HashQueue	crawlerservice/prefetch/worker.py	/^from rediscluster.queues import HashQueue$/;"	i
Record	crawlerservice/prefetch/worker.py	/^from rediscluster.record import Record$/;"	i
RedisManager	crawlerservice/prefetch/worker.py	/^from rediscluster.redismanager import RedisManager$/;"	i
ThinHash	crawlerservice/prefetch/worker.py	/^from rediscluster.thinredis import ThinHash$/;"	i
Worker	crawlerservice/prefetch/worker.py	/^class Worker(object):$/;"	c
__init__	crawlerservice/prefetch/worker.py	/^    def __init__(self):$/;"	m	class:Worker
__init__	crawlerservice/prefetch/worker.py	/^    def __init__(self, index):$/;"	m	class:GetWorker
argparse	crawlerservice/prefetch/worker.py	/^    import argparse$/;"	i
division	crawlerservice/prefetch/worker.py	/^from __future__ import print_function, division$/;"	i
gevent	crawlerservice/prefetch/worker.py	/^import gevent$/;"	i
main	crawlerservice/prefetch/worker.py	/^def main():$/;"	f
monkey	crawlerservice/prefetch/worker.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
patch_all	crawlerservice/prefetch/worker.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
print_function	crawlerservice/prefetch/worker.py	/^from __future__ import print_function, division$/;"	i
run	crawlerservice/prefetch/worker.py	/^    def run(self, *args, **kwargs):$/;"	m	class:GetWorker
schedule	crawlerservice/prefetch/worker.py	/^    def schedule(self, *args, **kwargs):$/;"	m	class:GetWorker
time	crawlerservice/prefetch/worker.py	/^import time$/;"	i
work	crawlerservice/prefetch/worker.py	/^    def work(self):$/;"	m	class:Worker
work	crawlerservice/prefetch/worker.py	/^    def work(self, batch_id, queue_dict, *args, **kwargs):$/;"	m	class:GetWorker
BATCH_ID	crawlerservice/prefetch/workers/zhidao_answer.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
Cache	crawlerservice/prefetch/workers/zhidao_answer.py	/^from downloader.cache import Cache$/;"	i
HEADER	crawlerservice/prefetch/workers/zhidao_answer.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
base64	crawlerservice/prefetch/workers/zhidao_answer.py	/^import base64$/;"	i
division	crawlerservice/prefetch/workers/zhidao_answer.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	crawlerservice/prefetch/workers/zhidao_answer.py	/^def generate_answer_json(ans_content):$/;"	f
get_answer_url	crawlerservice/prefetch/workers/zhidao_answer.py	/^from zhidao_tools import get_zhidao_content, get_answer_url$/;"	i
get_zhidao_content	crawlerservice/prefetch/workers/zhidao_answer.py	/^from zhidao_tools import get_zhidao_content, get_answer_url$/;"	i
json	crawlerservice/prefetch/workers/zhidao_answer.py	/^import json$/;"	i
os	crawlerservice/prefetch/workers/zhidao_answer.py	/^import os$/;"	i
print_function	crawlerservice/prefetch/workers/zhidao_answer.py	/^from __future__ import print_function, division$/;"	i
process	crawlerservice/prefetch/workers/zhidao_answer.py	/^def process(url, parameter, *args, **kwargs):$/;"	f
re	crawlerservice/prefetch/workers/zhidao_answer.py	/^import re$/;"	i
requests	crawlerservice/prefetch/workers/zhidao_answer.py	/^import requests$/;"	i
sys	crawlerservice/prefetch/workers/zhidao_answer.py	/^import sys$/;"	i
time	crawlerservice/prefetch/workers/zhidao_answer.py	/^import time$/;"	i
traceback	crawlerservice/prefetch/workers/zhidao_answer.py	/^import traceback$/;"	i
BATCH_ID	crawlerservice/prefetch/workers/zhidao_check.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
HEADER	crawlerservice/prefetch/workers/zhidao_check.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
OUTPUT_FILE	crawlerservice/prefetch/workers/zhidao_check.py	/^OUTPUT_FILE = 'OUTPUT'$/;"	v
base64	crawlerservice/prefetch/workers/zhidao_check.py	/^import base64$/;"	i
check_question	crawlerservice/prefetch/workers/zhidao_check.py	/^def check_question(question_raw):$/;"	f
check_url	crawlerservice/prefetch/workers/zhidao_check.py	/^def check_url(url):$/;"	f
get_zhidao_content	crawlerservice/prefetch/workers/zhidao_check.py	/^from zhidao_tools import get_zhidao_content$/;"	i
json	crawlerservice/prefetch/workers/zhidao_check.py	/^import json$/;"	i
logging	crawlerservice/prefetch/workers/zhidao_check.py	/^import logging$/;"	i
os	crawlerservice/prefetch/workers/zhidao_check.py	/^import os$/;"	i
re	crawlerservice/prefetch/workers/zhidao_check.py	/^import re$/;"	i
requests	crawlerservice/prefetch/workers/zhidao_check.py	/^import requests$/;"	i
sys	crawlerservice/prefetch/workers/zhidao_check.py	/^import sys$/;"	i
time	crawlerservice/prefetch/workers/zhidao_check.py	/^import time$/;"	i
traceback	crawlerservice/prefetch/workers/zhidao_check.py	/^import traceback$/;"	i
BATCH_ID	crawlerservice/prefetch/workers/zhidao_question.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
Cache	crawlerservice/prefetch/workers/zhidao_question.py	/^from downloader.cache import Cache$/;"	i
HEADER	crawlerservice/prefetch/workers/zhidao_question.py	/^from invoker.zhidao import BATCH_ID, HEADER$/;"	i
base64	crawlerservice/prefetch/workers/zhidao_question.py	/^import base64$/;"	i
division	crawlerservice/prefetch/workers/zhidao_question.py	/^from __future__ import print_function, division$/;"	i
generate_question_json	crawlerservice/prefetch/workers/zhidao_question.py	/^def generate_question_json(content, answer_ids):$/;"	f
get_answer_url	crawlerservice/prefetch/workers/zhidao_question.py	/^from zhidao_tools import get_zhidao_content, get_answer_url$/;"	i
get_zhidao_content	crawlerservice/prefetch/workers/zhidao_question.py	/^from zhidao_tools import get_zhidao_content, get_answer_url$/;"	i
json	crawlerservice/prefetch/workers/zhidao_question.py	/^import json$/;"	i
os	crawlerservice/prefetch/workers/zhidao_question.py	/^import os$/;"	i
parse_answer_ids	crawlerservice/prefetch/workers/zhidao_question.py	/^def parse_answer_ids(content):$/;"	f
parse_q_content	crawlerservice/prefetch/workers/zhidao_question.py	/^def parse_q_content(content):$/;"	f
parse_q_id	crawlerservice/prefetch/workers/zhidao_question.py	/^def parse_q_id(content):$/;"	f
parse_q_time	crawlerservice/prefetch/workers/zhidao_question.py	/^def parse_q_time(content):$/;"	f
parse_title	crawlerservice/prefetch/workers/zhidao_question.py	/^def parse_title(content):$/;"	f
print_function	crawlerservice/prefetch/workers/zhidao_question.py	/^from __future__ import print_function, division$/;"	i
process	crawlerservice/prefetch/workers/zhidao_question.py	/^def process(url, parameter, manager, *args, **kwargs):$/;"	f
re	crawlerservice/prefetch/workers/zhidao_question.py	/^import re$/;"	i
requests	crawlerservice/prefetch/workers/zhidao_question.py	/^import requests$/;"	i
sys	crawlerservice/prefetch/workers/zhidao_question.py	/^import sys$/;"	i
time	crawlerservice/prefetch/workers/zhidao_question.py	/^import time$/;"	i
traceback	crawlerservice/prefetch/workers/zhidao_question.py	/^import traceback$/;"	i
BATCH_ID	crawlerservice/prefetch/workers/zhidao_tools.py	/^from invoker.zhidao import BATCH_ID$/;"	i
DATA_PATH	crawlerservice/prefetch/workers/zhidao_tools.py	/^DATA_PATH = os.path.abspath(os.path.dirname($/;"	v
Downloader	crawlerservice/prefetch/workers/zhidao_tools.py	/^from downloader.downloader import Downloader$/;"	i
VERSION	crawlerservice/prefetch/workers/zhidao_tools.py	/^VERSION = "201606"$/;"	v
division	crawlerservice/prefetch/workers/zhidao_tools.py	/^from __future__ import print_function, division$/;"	i
get_answer_url	crawlerservice/prefetch/workers/zhidao_tools.py	/^def get_answer_url(q_id, r_id):$/;"	f
get_zhidao_content	crawlerservice/prefetch/workers/zhidao_tools.py	/^def get_zhidao_content(url, method, gap, header, batch_id):$/;"	f
json	crawlerservice/prefetch/workers/zhidao_tools.py	/^import json$/;"	i
os	crawlerservice/prefetch/workers/zhidao_tools.py	/^import os$/;"	i
print_function	crawlerservice/prefetch/workers/zhidao_tools.py	/^from __future__ import print_function, division$/;"	i
question_template	crawlerservice/prefetch/workers/zhidao_tools.py	/^question_template = 'http:\/\/zhidao.baidu.com\/question\/{}.html'$/;"	v
requests	crawlerservice/prefetch/workers/zhidao_tools.py	/^import requests$/;"	i
sys	crawlerservice/prefetch/workers/zhidao_tools.py	/^import sys$/;"	i
PrefetchHandler	crawlerservice/prefetch_handler.py	/^class PrefetchHandler(tornado.web.RequestHandler):$/;"	c
division	crawlerservice/prefetch_handler.py	/^from __future__ import print_function, division$/;"	i
hashlib	crawlerservice/prefetch_handler.py	/^import hashlib$/;"	i
json	crawlerservice/prefetch_handler.py	/^import json$/;"	i
post	crawlerservice/prefetch_handler.py	/^    def post(self, batch_id, method):$/;"	m	class:PrefetchHandler
print_function	crawlerservice/prefetch_handler.py	/^from __future__ import print_function, division$/;"	i
tornado	crawlerservice/prefetch_handler.py	/^import tornado.web$/;"	i
web	crawlerservice/prefetch_handler.py	/^import tornado.web$/;"	i
AsyncHTTPClient	crawlerservice/proxy/extractproxies.py	/^from tornado.curl_httpclient import CurlAsyncHTTPClient as AsyncHTTPClient, CurlError$/;"	i
CONCURRENT_NUM	crawlerservice/proxy/extractproxies.py	/^from settings import CONCURRENT_NUM$/;"	i
CurlError	crawlerservice/proxy/extractproxies.py	/^from tornado.curl_httpclient import CurlAsyncHTTPClient as AsyncHTTPClient, CurlError$/;"	i
DAY_LIMIATION	crawlerservice/proxy/extractproxies.py	/^DAY_LIMIATION = 600000$/;"	v
ExtractProxies	crawlerservice/proxy/extractproxies.py	/^class ExtractProxies(object):$/;"	c
ONCE_LIMIATION	crawlerservice/proxy/extractproxies.py	/^ONCE_LIMIATION = 3000$/;"	v
Semaphore	crawlerservice/proxy/extractproxies.py	/^from tornado.locks import Semaphore$/;"	i
__init__	crawlerservice/proxy/extractproxies.py	/^    def __init__(self):$/;"	m	class:ExtractProxies
async_http	crawlerservice/proxy/extractproxies.py	/^    def async_http(self, proxy, idx, requests_proxies):$/;"	m	class:ExtractProxies
check_proxies_connectivity	crawlerservice/proxy/extractproxies.py	/^    def check_proxies_connectivity(self, proxies):$/;"	m	class:ExtractProxies
division	crawlerservice/proxy/extractproxies.py	/^from __future__ import print_function, division$/;"	i
extract_proxies	crawlerservice/proxy/extractproxies.py	/^def extract_proxies():$/;"	f
extract_proxies_async	crawlerservice/proxy/extractproxies.py	/^def extract_proxies_async(requests_proxies):$/;"	f
gen	crawlerservice/proxy/extractproxies.py	/^from tornado import gen$/;"	i
get_proxies	crawlerservice/proxy/extractproxies.py	/^    def get_proxies(self):$/;"	m	class:ExtractProxies
handle_request	crawlerservice/proxy/extractproxies.py	/^        def handle_request(response):$/;"	f	function:ExtractProxies.async_http
httpclient	crawlerservice/proxy/extractproxies.py	/^from tornado import httpclient$/;"	i
instance	crawlerservice/proxy/extractproxies.py	/^    def instance(cls):$/;"	m	class:ExtractProxies
parse_proxies	crawlerservice/proxy/extractproxies.py	/^    def parse_proxies(self, item):$/;"	m	class:ExtractProxies
parse_proxies_async	crawlerservice/proxy/extractproxies.py	/^    def parse_proxies_async(self, item):$/;"	m	class:ExtractProxies
prepare_curl_type	crawlerservice/proxy/extractproxies.py	/^        def prepare_curl_type(curl):$/;"	f	function:ExtractProxies.async_http
print_function	crawlerservice/proxy/extractproxies.py	/^from __future__ import print_function, division$/;"	i
pycurl	crawlerservice/proxy/extractproxies.py	/^import pycurl$/;"	i
requests	crawlerservice/proxy/extractproxies.py	/^import requests$/;"	i
time	crawlerservice/proxy/extractproxies.py	/^import time$/;"	i
worker	crawlerservice/proxy/extractproxies.py	/^    def worker(instance, idx, item, requests_proxies):$/;"	f	function:extract_proxies_async
FREE_PROXIES	crawlerservice/proxy/proxies.py	/^FREE_PROXIES = [$/;"	v
MIMVIP_PROXIES	crawlerservice/proxy/proxies.py	/^MIMVIP_PROXIES = [$/;"	v
PROXIES	crawlerservice/proxy/proxies.py	/^PROXIES = parse_proxies()$/;"	v
division	crawlerservice/proxy/proxies.py	/^from __future__ import print_function, division$/;"	i
print_function	crawlerservice/proxy/proxies.py	/^from __future__ import print_function, division$/;"	i
FSCACHEDIR	crawlerservice/proxy/proxypool.py	/^from settings import FSCACHEDIR$/;"	i
ProxyPool	crawlerservice/proxy/proxypool.py	/^class ProxyPool(object):$/;"	c
__init__	crawlerservice/proxy/proxypool.py	/^    def __init__(self):$/;"	m	class:ProxyPool
_count_rule	crawlerservice/proxy/proxypool.py	/^    def _count_rule(self, method, count):$/;"	m	class:ProxyPool
defaultdict	crawlerservice/proxy/proxypool.py	/^from collections import defaultdict$/;"	i
division	crawlerservice/proxy/proxypool.py	/^from __future__ import print_function, division$/;"	i
extract_proxies	crawlerservice/proxy/proxypool.py	/^from extractproxies import extract_proxies, extract_proxies_async$/;"	i
extract_proxies_async	crawlerservice/proxy/proxypool.py	/^from extractproxies import extract_proxies, extract_proxies_async$/;"	i
extract_proxies_task	crawlerservice/proxy/proxypool.py	/^    def extract_proxies_task(self):$/;"	m	class:ProxyPool
extract_proxies_task_async	crawlerservice/proxy/proxypool.py	/^    def extract_proxies_task_async(self, debug=False):$/;"	m	class:ProxyPool
gen	crawlerservice/proxy/proxypool.py	/^import tornado.gen$/;"	i
get	crawlerservice/proxy/proxypool.py	/^    def get(self, url, max_last_time):$/;"	m	class:ProxyPool
get_data_structure	crawlerservice/proxy/proxypool.py	/^    def get_data_structure(self):$/;"	m	class:ProxyPool
heapq	crawlerservice/proxy/proxypool.py	/^from Queue import heapq$/;"	i
instance	crawlerservice/proxy/proxypool.py	/^    def instance(cls):$/;"	m	class:ProxyPool
json	crawlerservice/proxy/proxypool.py	/^import json$/;"	i
os	crawlerservice/proxy/proxypool.py	/^import os$/;"	i
print_function	crawlerservice/proxy/proxypool.py	/^from __future__ import print_function, division$/;"	i
set_host_interval	crawlerservice/proxy/proxypool.py	/^    def set_host_interval(self, host, interval):$/;"	m	class:ProxyPool
set_proxy_status	crawlerservice/proxy/proxypool.py	/^    def set_proxy_status(self, url, proxy, status):$/;"	m	class:ProxyPool
time	crawlerservice/proxy/proxypool.py	/^import time$/;"	i
tornado	crawlerservice/proxy/proxypool.py	/^import tornado.gen$/;"	i
urlparse	crawlerservice/proxy/proxypool.py	/^import urlparse$/;"	i
HashQueue	crawlerservice/rediscluster/queues.py	/^class HashQueue(object):$/;"	c
Queue	crawlerservice/rediscluster/queues.py	/^class Queue(object):$/;"	c
Record	crawlerservice/rediscluster/queues.py	/^from record import Record$/;"	i
RedisPool	crawlerservice/rediscluster/queues.py	/^from redispool import RedisPool$/;"	i
__init__	crawlerservice/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:HashQueue
__init__	crawlerservice/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:Queue
background_cleaning	crawlerservice/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:HashQueue
background_cleaning	crawlerservice/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:Queue
clean_task	crawlerservice/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:HashQueue
clean_task	crawlerservice/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:Queue
clear	crawlerservice/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:HashQueue
clear	crawlerservice/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:Queue
datetime	crawlerservice/rediscluster/queues.py	/^from datetime import datetime$/;"	i
delete	crawlerservice/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:HashQueue
delete	crawlerservice/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:Queue
flush	crawlerservice/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:HashQueue
flush	crawlerservice/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:Queue
get	crawlerservice/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:HashQueue
get	crawlerservice/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:Queue
get_background_cleaning_status	crawlerservice/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:HashQueue
get_background_cleaning_status	crawlerservice/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:Queue
get_failed_fields	crawlerservice/rediscluster/queues.py	/^    def get_failed_fields(self):$/;"	m	class:Queue
get_failed_times	crawlerservice/rediscluster/queues.py	/^    def get_failed_times(self, field):$/;"	m	class:Queue
poll	crawlerservice/rediscluster/queues.py	/^def poll(queues, timeout=None):$/;"	f
put	crawlerservice/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:HashQueue
put	crawlerservice/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:Queue
put_init	crawlerservice/rediscluster/queues.py	/^    def put_init(self, *items):$/;"	m	class:HashQueue
qsize	crawlerservice/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:HashQueue
qsize	crawlerservice/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:Queue
set_failed_times_to_url	crawlerservice/rediscluster/queues.py	/^    def set_failed_times_to_url(self, field, url):$/;"	m	class:Queue
task_done	crawlerservice/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:HashQueue
task_done	crawlerservice/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:Queue
task_start	crawlerservice/rediscluster/queues.py	/^    def task_start(self, result):$/;"	m	class:Queue
task_start	crawlerservice/rediscluster/queues.py	/^    def task_start(self, result, count):$/;"	m	class:HashQueue
task_start_batch	crawlerservice/rediscluster/queues.py	/^    def task_start_batch(self, results):$/;"	m	class:Queue
time	crawlerservice/rediscluster/queues.py	/^import time$/;"	i
Record	crawlerservice/rediscluster/record.py	/^class Record(object):$/;"	c
RedisPool	crawlerservice/rediscluster/record.py	/^from redispool import RedisPool$/;"	i
ResponseError	crawlerservice/rediscluster/record.py	/^from redis import ResponseError$/;"	i
__init__	crawlerservice/rediscluster/record.py	/^    def __init__(self):$/;"	m	class:Record
add_exception	crawlerservice/rediscluster/record.py	/^    def add_exception(self, batch_id, url, error):$/;"	m	class:Record
begin	crawlerservice/rediscluster/record.py	/^    def begin(self, batch_id, parameter, total, priority):$/;"	m	class:Record
connect	crawlerservice/rediscluster/record.py	/^    def connect(self):$/;"	m	class:Record
datetime	crawlerservice/rediscluster/record.py	/^from datetime import datetime$/;"	i
division	crawlerservice/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
get_parameter	crawlerservice/rediscluster/record.py	/^    def get_parameter(self, batch_id):$/;"	m	class:Record
get_priority	crawlerservice/rediscluster/record.py	/^    def get_priority(self, batch_id):$/;"	m	class:Record
get_total_number	crawlerservice/rediscluster/record.py	/^    def get_total_number(self, batch_id):$/;"	m	class:Record
get_unfinished_batch	crawlerservice/rediscluster/record.py	/^    def get_unfinished_batch(self):$/;"	m	class:Record
if_not_finish_set	crawlerservice/rediscluster/record.py	/^    def if_not_finish_set(self, batch_id):$/;"	m	class:Record
increase_failed	crawlerservice/rediscluster/record.py	/^    def increase_failed(self, batch_id, count=1):$/;"	m	class:Record
increase_success	crawlerservice/rediscluster/record.py	/^    def increase_success(self, batch_id, count=1):$/;"	m	class:Record
instance	crawlerservice/rediscluster/record.py	/^    def instance(cls):$/;"	m	class:Record
is_finished	crawlerservice/rediscluster/record.py	/^    def is_finished(self, batch_id):$/;"	m	class:Record
print_function	crawlerservice/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
Queue	crawlerservice/rediscluster/redismanager.py	/^from rediscluster.queues import Queue$/;"	i
Record	crawlerservice/rediscluster/redismanager.py	/^from rediscluster.record import Record$/;"	i
RedisManager	crawlerservice/rediscluster/redismanager.py	/^class RedisManager(object):$/;"	c
RedisPool	crawlerservice/rediscluster/redismanager.py	/^from rediscluster.redispool import RedisPool$/;"	i
ThinHash	crawlerservice/rediscluster/redismanager.py	/^from rediscluster.thinredis import ThinHash$/;"	i
__check_empty_queue	crawlerservice/rediscluster/redismanager.py	/^    def __check_empty_queue(self, queue):$/;"	m	class:RedisManager	file:
__init__	crawlerservice/rediscluster/redismanager.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisManager
delete_queue	crawlerservice/rediscluster/redismanager.py	/^    def delete_queue(self, batch_id):$/;"	m	class:RedisManager
division	crawlerservice/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
get_distributed_queue	crawlerservice/rediscluster/redismanager.py	/^    def get_distributed_queue(self, batch_id):$/;"	m	class:RedisManager
get_queue_with_priority	crawlerservice/rediscluster/redismanager.py	/^    def get_queue_with_priority(self):$/;"	m	class:RedisManager
get_status	crawlerservice/rediscluster/redismanager.py	/^    def get_status(self, batch_id):$/;"	m	class:RedisManager
hashlib	crawlerservice/rediscluster/redismanager.py	/^import hashlib$/;"	i
init_distributed_queue	crawlerservice/rediscluster/redismanager.py	/^    def init_distributed_queue(self,$/;"	m	class:RedisManager
itemgetter	crawlerservice/rediscluster/redismanager.py	/^from operator import itemgetter$/;"	i
print_function	crawlerservice/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
put_url_enqueue	crawlerservice/rediscluster/redismanager.py	/^    def put_url_enqueue(self, batch_id, url):$/;"	m	class:RedisManager
put_urls_enqueue	crawlerservice/rediscluster/redismanager.py	/^    def put_urls_enqueue(self, batch_id, urls):$/;"	m	class:RedisManager
set_distributed_queue	crawlerservice/rediscluster/redismanager.py	/^    def set_distributed_queue(self, batch_id, queue, thinhash, priority, refresh=True):$/;"	m	class:RedisManager
worker_init_distributed_queue	crawlerservice/rediscluster/redismanager.py	/^    def worker_init_distributed_queue(self, batch_id, total_count):$/;"	m	class:RedisManager
CACHE_REDIS	crawlerservice/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
QUEUE_REDIS	crawlerservice/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Queue	crawlerservice/rediscluster/redismonitor.py	/^from rediscluster.queues import Queue$/;"	i
RECORD_REDIS	crawlerservice/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Record	crawlerservice/rediscluster/redismonitor.py	/^from rediscluster.record import Record$/;"	i
RedisPool	crawlerservice/rediscluster/redismonitor.py	/^from rediscluster.redispool import RedisPool$/;"	i
argparse	crawlerservice/rediscluster/redismonitor.py	/^    import argparse$/;"	i
division	crawlerservice/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
get_status	crawlerservice/rediscluster/redismonitor.py	/^def get_status(batch_id):$/;"	f
init	crawlerservice/rediscluster/redismonitor.py	/^def init():$/;"	f
interval	crawlerservice/rediscluster/redismonitor.py	/^def interval(val, func, arg):$/;"	f
main	crawlerservice/rediscluster/redismonitor.py	/^def main():$/;"	f
os	crawlerservice/rediscluster/redismonitor.py	/^import os$/;"	i
parse_args	crawlerservice/rediscluster/redismonitor.py	/^def parse_args():$/;"	f
print_function	crawlerservice/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
sys	crawlerservice/rediscluster/redismonitor.py	/^import sys$/;"	i
time	crawlerservice/rediscluster/redismonitor.py	/^import time$/;"	i
RedisPool	crawlerservice/rediscluster/redispool.py	/^class RedisPool(object):$/;"	c
__init__	crawlerservice/rediscluster/redispool.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisPool
contextlib	crawlerservice/rediscluster/redispool.py	/^import contextlib$/;"	i
division	crawlerservice/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
instance	crawlerservice/rediscluster/redispool.py	/^    def instance(cls, *args):$/;"	m	class:RedisPool
print_function	crawlerservice/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
re	crawlerservice/rediscluster/redispool.py	/^import re$/;"	i
redis	crawlerservice/rediscluster/redispool.py	/^import redis$/;"	i
HashRing	crawlerservice/rediscluster/shardredis.py	/^from hash_ring import HashRing$/;"	i
Redis	crawlerservice/rediscluster/shardredis.py	/^from redis import Redis$/;"	i
ShardRedis	crawlerservice/rediscluster/shardredis.py	/^class ShardRedis(object):$/;"	c
__getattribute__	crawlerservice/rediscluster/shardredis.py	/^    def __getattribute__(self, name):$/;"	m	class:ShardRedis	file:
__init__	crawlerservice/rediscluster/shardredis.py	/^    def __init__(self, conns, pipelines=None):$/;"	m	class:ShardRedis
cache	crawlerservice/rediscluster/shardredis.py	/^    cache = {}$/;"	v	class:ShardRedis
cmd_hashes	crawlerservice/rediscluster/shardredis.py	/^cmd_hashes = {'hdel', 'hincrby', 'hmget', 'hvals', 'hexists', 'hincrbyfloat', 'hmset', 'hget',$/;"	v
cmd_keys	crawlerservice/rediscluster/shardredis.py	/^cmd_keys = {'delete', 'keys', 'pexpire', 'renamenx', 'dump', 'migrate', 'pexpireat', $/;"	v
cmd_lists	crawlerservice/rediscluster/shardredis.py	/^cmd_lists = {'blpop', 'llen', 'lrem', 'rpush', 'brpop', 'lpop', 'lset', 'rpushx', 'brpoplpush',$/;"	v
cmd_mods	crawlerservice/rediscluster/shardredis.py	/^cmd_mods = cmd_hashes | cmd_lists | cmd_sets | cmd_zsets | cmd_strings | cmd_supports$/;"	v
cmd_sets	crawlerservice/rediscluster/shardredis.py	/^cmd_sets = {'sadd', 'sinter', 'smove', 'sunion', 'scard', 'sinterstore', 'spop', 'sunionstore',$/;"	v
cmd_strings	crawlerservice/rediscluster/shardredis.py	/^cmd_strings = {'append', 'getbit', 'mget', 'setex', 'bitcount', 'getrange', 'mset', 'setnx',$/;"	v
cmd_supports	crawlerservice/rediscluster/shardredis.py	/^cmd_supports = {'delete', 'type'}$/;"	v
cmd_zsets	crawlerservice/rediscluster/shardredis.py	/^cmd_zsets = {'zadd', 'zinterstore', 'zrem', 'zrevrangebyscore', 'zcard', 'zrange', 'zremrangebyrank',$/;"	v
func	crawlerservice/rediscluster/shardredis.py	/^                def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__.func
func	crawlerservice/rediscluster/shardredis.py	/^            def func():$/;"	f	function:ShardRedis.__getattribute__
func	crawlerservice/rediscluster/shardredis.py	/^            def func(*args, **kwargs): $/;"	f	function:ShardRedis.__getattribute__
func	crawlerservice/rediscluster/shardredis.py	/^            def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__
get_redis	crawlerservice/rediscluster/shardredis.py	/^    def get_redis(self, skey):$/;"	m	class:ShardRedis
getconn	crawlerservice/rediscluster/shardredis.py	/^    def getconn(self, index):$/;"	m	class:ShardRedis
conn	crawlerservice/rediscluster/test_hscan.py	/^conn = redis.StrictRedis()$/;"	v
division	crawlerservice/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
get	crawlerservice/rediscluster/test_hscan.py	/^def get():$/;"	f
key	crawlerservice/rediscluster/test_hscan.py	/^key = 'test'$/;"	v
print_function	crawlerservice/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
redis	crawlerservice/rediscluster/test_hscan.py	/^import redis$/;"	i
CappedSortedSet	crawlerservice/rediscluster/thinredis.py	/^class CappedSortedSet(object):$/;"	c
RedisPool	crawlerservice/rediscluster/thinredis.py	/^from redispool import RedisPool$/;"	i
ShardRedis	crawlerservice/rediscluster/thinredis.py	/^from shardredis import ShardRedis$/;"	i
ThinHash	crawlerservice/rediscluster/thinredis.py	/^class ThinHash(object):$/;"	c
ThinSet	crawlerservice/rediscluster/thinredis.py	/^class ThinSet(object):$/;"	c
__init__	crawlerservice/rediscluster/thinredis.py	/^    def __init__(self, key, cap, conn, **kwargs):$/;"	m	class:CappedSortedSet
__init__	crawlerservice/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinHash
__init__	crawlerservice/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinSet
_get_bucket	crawlerservice/rediscluster/thinredis.py	/^    def _get_bucket(self, field):$/;"	m	class:ThinHash
_get_bucket	crawlerservice/rediscluster/thinredis.py	/^    def _get_bucket(self, item):$/;"	m	class:ThinSet
add	crawlerservice/rediscluster/thinredis.py	/^    def add(self, *items):$/;"	m	class:ThinSet
contains	crawlerservice/rediscluster/thinredis.py	/^    def contains(self, *items):$/;"	m	class:ThinSet
count	crawlerservice/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinHash
count	crawlerservice/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinSet
delete	crawlerservice/rediscluster/thinredis.py	/^    def delete(self):$/;"	m	class:ThinHash
delete	crawlerservice/rediscluster/thinredis.py	/^    def delete(self, *items):$/;"	m	class:ThinSet
hashlib	crawlerservice/rediscluster/thinredis.py	/^import hashlib$/;"	i
hdel	crawlerservice/rediscluster/thinredis.py	/^    def hdel(self, field):$/;"	m	class:ThinHash
hget	crawlerservice/rediscluster/thinredis.py	/^    def hget(self, field):$/;"	m	class:ThinHash
hgetall	crawlerservice/rediscluster/thinredis.py	/^    def hgetall(self):$/;"	m	class:ThinHash
hkeys	crawlerservice/rediscluster/thinredis.py	/^    def hkeys(self):$/;"	m	class:ThinHash
hmget	crawlerservice/rediscluster/thinredis.py	/^    def hmget(self, *fields):$/;"	m	class:ThinHash
hmset	crawlerservice/rediscluster/thinredis.py	/^    def hmset(self, *args):$/;"	m	class:ThinHash
hset	crawlerservice/rediscluster/thinredis.py	/^    def hset(self, field, value):$/;"	m	class:ThinHash
inited	crawlerservice/rediscluster/thinredis.py	/^    inited = False$/;"	v	class:CappedSortedSet
recount	crawlerservice/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinHash
recount	crawlerservice/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinSet
redis	crawlerservice/rediscluster/thinredis.py	/^import redis$/;"	i
script	crawlerservice/rediscluster/thinredis.py	/^    script = '\\n'.join([$/;"	v	class:CappedSortedSet
sha1	crawlerservice/rediscluster/thinredis.py	/^    sha1 = hashlib.sha1(script).hexdigest()$/;"	v	class:CappedSortedSet
smembers	crawlerservice/rediscluster/thinredis.py	/^    def smembers(self):$/;"	m	class:ThinSet
zadd	crawlerservice/rediscluster/thinredis.py	/^    def zadd(self, member, score, **kwargs):$/;"	m	class:CappedSortedSet
zrange	crawlerservice/rediscluster/thinredis.py	/^    def zrange(self, start, end, **kwargs):$/;"	m	class:CappedSortedSet
call_with_throttling	crawlerservice/rediscluster/throttling.py	/^def call_with_throttling(func, args=(), kwargs={}, expected_processing_gap=0.1):$/;"	f
deque	crawlerservice/rediscluster/throttling.py	/^from collections import deque$/;"	i
division	crawlerservice/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
print_function	crawlerservice/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
remove_outdated	crawlerservice/rediscluster/throttling.py	/^    def remove_outdated():$/;"	f	function:call_with_throttling
smoothen_calling_interval	crawlerservice/rediscluster/throttling.py	/^    def smoothen_calling_interval():$/;"	f	function:call_with_throttling
time	crawlerservice/rediscluster/throttling.py	/^import time$/;"	i
wait_for_threshold	crawlerservice/rediscluster/throttling.py	/^    def wait_for_threshold():$/;"	f	function:call_with_throttling
division	crawlerservice/router.py	/^from __future__ import print_function, division$/;"	i
print_function	crawlerservice/router.py	/^from __future__ import print_function, division$/;"	i
settings	crawlerservice/router.py	/^settings = {$/;"	v
tornado	crawlerservice/router.py	/^import tornado.web$/;"	i
urls	crawlerservice/router.py	/^urls = tornado.web.Application([$/;"	v
web	crawlerservice/router.py	/^import tornado.web$/;"	i
ENV	crawlerservice/settings.py	/^    ENV = 'DEV'$/;"	v
ENV	crawlerservice/settings.py	/^ENV = os.environ.get('ENV', 'DEV')$/;"	v
envs	crawlerservice/settings.py	/^envs = {$/;"	v
os	crawlerservice/settings.py	/^import os$/;"	i
AWS_ACCESS_ID	haizhicommon/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
REGION_NAME	haizhicommon/awsapi/download_s3bucket.py	/^REGION_NAME = 'ap-northeast-1'$/;"	v
S3	haizhicommon/awsapi/download_s3bucket.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
boto3	haizhicommon/awsapi/download_s3bucket.py	/^import boto3$/;"	i
bucketname	haizhicommon/awsapi/download_s3bucket.py	/^    bucketname = 'fudankg-json'$/;"	v
compare_time	haizhicommon/awsapi/download_s3bucket.py	/^    compare_time = datetime(2016,7,1,2,0,0,).strftime('%Y%m%d%H%M%S') $/;"	v
count_bucket	haizhicommon/awsapi/download_s3bucket.py	/^def count_bucket(bucketname):$/;"	f
datetime	haizhicommon/awsapi/download_s3bucket.py	/^from datetime import datetime$/;"	i
delete_bucket	haizhicommon/awsapi/download_s3bucket.py	/^def delete_bucket(bucketname):$/;"	f
division	haizhicommon/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
down_fudankg	haizhicommon/awsapi/download_s3bucket.py	/^def down_fudankg(bucketname):$/;"	f
empty_bucket	haizhicommon/awsapi/download_s3bucket.py	/^def empty_bucket(bucketname, compare_time=None):$/;"	f
os	haizhicommon/awsapi/download_s3bucket.py	/^import os$/;"	i
print_function	haizhicommon/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
save_to_local	haizhicommon/awsapi/download_s3bucket.py	/^def save_to_local(bucketname):$/;"	f
AWS_ACCESS_ID	haizhicommon/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
Ec2Manager	haizhicommon/awsapi/ec2manager.py	/^class Ec2Manager(object):$/;"	c
__init__	haizhicommon/awsapi/ec2manager.py	/^    def __init__(self, region_name, tag='crawler', amiid=None):$/;"	m	class:Ec2Manager
boto3	haizhicommon/awsapi/ec2manager.py	/^import boto3$/;"	i
config	haizhicommon/awsapi/ec2manager.py	/^    config = {$/;"	v	class:Ec2Manager
create_instances	haizhicommon/awsapi/ec2manager.py	/^    def create_instances(self, MachineNum=1):$/;"	m	class:Ec2Manager
deque	haizhicommon/awsapi/ec2manager.py	/^from collections import deque$/;"	i
division	haizhicommon/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
get_ids_in_status	haizhicommon/awsapi/ec2manager.py	/^    def get_ids_in_status(self, status):$/;"	m	class:Ec2Manager
get_idx_by_id	haizhicommon/awsapi/ec2manager.py	/^    def get_idx_by_id(self, one_id):$/;"	m	class:Ec2Manager
get_ipaddr	haizhicommon/awsapi/ec2manager.py	/^    def get_ipaddr(self, one_id):$/;"	m	class:Ec2Manager
get_keypair	haizhicommon/awsapi/ec2manager.py	/^    def get_keypair(self):$/;"	m	class:Ec2Manager
print_function	haizhicommon/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
start	haizhicommon/awsapi/ec2manager.py	/^    def start(self, ids):$/;"	m	class:Ec2Manager
stop	haizhicommon/awsapi/ec2manager.py	/^    def stop(self, ids):$/;"	m	class:Ec2Manager
stop_and_start	haizhicommon/awsapi/ec2manager.py	/^    def stop_and_start(self, group_num):$/;"	m	class:Ec2Manager
stop_one_and_restart	haizhicommon/awsapi/ec2manager.py	/^    def stop_one_and_restart(self):$/;"	m	class:Ec2Manager
terminate	haizhicommon/awsapi/ec2manager.py	/^    def terminate(self, ids):$/;"	m	class:Ec2Manager
time	haizhicommon/awsapi/ec2manager.py	/^import time$/;"	i
AWS_ACCESS_ID	haizhicommon/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
S3Object	haizhicommon/awsapi/s3object.py	/^class S3Object(object):$/;"	c
__init__	haizhicommon/awsapi/s3object.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:S3Object
boto3	haizhicommon/awsapi/s3object.py	/^import boto3$/;"	i
botocore	haizhicommon/awsapi/s3object.py	/^import botocore$/;"	i
create_bucket	haizhicommon/awsapi/s3object.py	/^    def create_bucket(self):$/;"	m	class:S3Object
division	haizhicommon/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
get_cache	haizhicommon/awsapi/s3object.py	/^    def get_cache(self, filename):$/;"	m	class:S3Object
hashlib	haizhicommon/awsapi/s3object.py	/^import hashlib$/;"	i
head_cache	haizhicommon/awsapi/s3object.py	/^    def head_cache(self, filename):$/;"	m	class:S3Object
print_function	haizhicommon/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
put_cache	haizhicommon/awsapi/s3object.py	/^    def put_cache(self, filename, content):$/;"	m	class:S3Object
division	haizhicommon/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
filename_in_logger_out	haizhicommon/crawlerlog/cachelog.py	/^    def filename_in_logger_out(the_batch_id, cachedir):$/;"	f	function:get_logger
get_logger	haizhicommon/crawlerlog/cachelog.py	/^def get_logger(batch_id, today_str, cachedir='.'):$/;"	f
ip	haizhicommon/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
log	haizhicommon/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
logging	haizhicommon/crawlerlog/cachelog.py	/^import logging$/;"	i
os	haizhicommon/crawlerlog/cachelog.py	/^import os$/;"	i
path	haizhicommon/crawlerlog/cachelog.py	/^from crawlerlog import log, ip, path$/;"	i
print_function	haizhicommon/crawlerlog/cachelog.py	/^from __future__ import print_function, division$/;"	i
division	haizhicommon/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
get_local_ip_address	haizhicommon/crawlerlog/ip.py	/^def get_local_ip_address():$/;"	f
print_function	haizhicommon/crawlerlog/ip.py	/^from __future__ import print_function, division$/;"	i
socket	haizhicommon/crawlerlog/ip.py	/^import socket$/;"	i
handlers	haizhicommon/crawlerlog/log.py	/^    import logging.handlers$/;"	i
init	haizhicommon/crawlerlog/log.py	/^def init(log_name, log_file, level=logging.DEBUG, size=1024*1024, count=10):$/;"	f
log_print	haizhicommon/crawlerlog/log.py	/^def log_print(msg, logger=None, level=logging.ERROR):$/;"	f
log_traceback	haizhicommon/crawlerlog/log.py	/^def log_traceback(logger=None, msg=None):$/;"	f
logging	haizhicommon/crawlerlog/log.py	/^    import logging.handlers$/;"	i
logging	haizhicommon/crawlerlog/log.py	/^import logging$/;"	i
sys	haizhicommon/crawlerlog/log.py	/^    import sys, traceback$/;"	i
traceback	haizhicommon/crawlerlog/log.py	/^    import sys, traceback$/;"	i
division	haizhicommon/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
makedir	haizhicommon/crawlerlog/path.py	/^def makedir(absdir):$/;"	f
os	haizhicommon/crawlerlog/path.py	/^import os$/;"	i
print_function	haizhicommon/crawlerlog/path.py	/^from __future__ import print_function, division$/;"	i
Cache	haizhicommon/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	haizhicommon/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	haizhicommon/downloader/cache.py	/^import base64$/;"	i
division	haizhicommon/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	haizhicommon/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	haizhicommon/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	haizhicommon/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	haizhicommon/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	haizhicommon/downloader/cache.py	/^import requests$/;"	i
urlparse	haizhicommon/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	haizhicommon/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	haizhicommon/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	haizhicommon/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	haizhicommon/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	haizhicommon/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	haizhicommon/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	haizhicommon/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	haizhicommon/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	haizhicommon/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	haizhicommon/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	haizhicommon/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	haizhicommon/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	haizhicommon/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	haizhicommon/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	haizhicommon/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	haizhicommon/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	haizhicommon/downloader/caches3.py	/^import hashlib$/;"	i
post	haizhicommon/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	haizhicommon/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	haizhicommon/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	haizhicommon/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	haizhicommon/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	haizhicommon/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	haizhicommon/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	haizhicommon/downloader/downloader.py	/^            import chardet$/;"	i
close	haizhicommon/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	haizhicommon/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	haizhicommon/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	haizhicommon/downloader/downloader.py	/^import os$/;"	i
print_function	haizhicommon/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	haizhicommon/downloader/downloader.py	/^import re$/;"	i
request_download	haizhicommon/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	haizhicommon/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	haizhicommon/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	haizhicommon/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	haizhicommon/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	haizhicommon/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	haizhicommon/downloader/downloader.py	/^import sys$/;"	i
time	haizhicommon/downloader/downloader.py	/^import time$/;"	i
update_header	haizhicommon/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	haizhicommon/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	haizhicommon/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	haizhicommon/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	haizhicommon/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	haizhicommon/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	haizhicommon/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	haizhicommon/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	haizhicommon/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	haizhicommon/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	haizhicommon/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	haizhicommon/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	haizhicommon/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	haizhicommon/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	haizhicommon/downloader/test_cacheperiod.py	/^import json$/;"	i
main	haizhicommon/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	haizhicommon/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	haizhicommon/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	haizhicommon/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	haizhicommon/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	haizhicommon/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	haizhicommon/downloader/test_download.py	/^    import chardet$/;"	i
codecs	haizhicommon/downloader/test_download.py	/^import codecs$/;"	i
collections	haizhicommon/downloader/test_download.py	/^import collections$/;"	i
datetime	haizhicommon/downloader/test_download.py	/^import datetime$/;"	i
json	haizhicommon/downloader/test_download.py	/^import json$/;"	i
main	haizhicommon/downloader/test_download.py	/^def main():$/;"	f
os	haizhicommon/downloader/test_download.py	/^import os$/;"	i
re	haizhicommon/downloader/test_download.py	/^import re$/;"	i
requests	haizhicommon/downloader/test_download.py	/^    import requests$/;"	i
sys	haizhicommon/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	haizhicommon/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	haizhicommon/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	haizhicommon/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	haizhicommon/downloader/test_download.py	/^import time$/;"	i
urllib	haizhicommon/downloader/test_download.py	/^import urllib$/;"	i
INDEX_OPTION_DELETE	haizhicommon/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	haizhicommon/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	haizhicommon/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	haizhicommon/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	haizhicommon/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	haizhicommon/es/es_api.py	/^import codecs$/;"	i
collections	haizhicommon/es/es_api.py	/^import collections$/;"	i
es_api_post	haizhicommon/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	haizhicommon/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	haizhicommon/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	haizhicommon/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	haizhicommon/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	haizhicommon/es/es_api.py	/^import hashlib$/;"	i
json	haizhicommon/es/es_api.py	/^import json$/;"	i
os	haizhicommon/es/es_api.py	/^import os$/;"	i
os	haizhicommon/es/es_api.py	/^import os.path$/;"	i
path	haizhicommon/es/es_api.py	/^import os.path$/;"	i
requests	haizhicommon/es/es_api.py	/^import requests$/;"	i
run_batch	haizhicommon/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	haizhicommon/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	haizhicommon/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	haizhicommon/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	haizhicommon/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	haizhicommon/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	haizhicommon/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	haizhicommon/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	haizhicommon/es/es_api.py	/^import sys$/;"	i
test	haizhicommon/es/es_api.py	/^def test():$/;"	f
test_echo	haizhicommon/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	haizhicommon/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	haizhicommon/es/es_api.py	/^import urllib$/;"	i
InstanceMgr	haizhicommon/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	haizhicommon/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	haizhicommon/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	haizhicommon/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	haizhicommon/hzlib/api_aws.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/api_aws.py	/^import collections$/;"	i
config	haizhicommon/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	haizhicommon/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	haizhicommon/hzlib/api_aws.py	/^import datetime$/;"	i
filename	haizhicommon/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	haizhicommon/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	haizhicommon/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	haizhicommon/hzlib/api_aws.py	/^import hashlib$/;"	i
json	haizhicommon/hzlib/api_aws.py	/^import json$/;"	i
list	haizhicommon/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	haizhicommon/hzlib/api_aws.py	/^import logging$/;"	i
main	haizhicommon/hzlib/api_aws.py	/^def main(config):$/;"	f
os	haizhicommon/hzlib/api_aws.py	/^import os$/;"	i
paramiko	haizhicommon/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	haizhicommon/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	haizhicommon/hzlib/api_aws.py	/^import re$/;"	i
run	haizhicommon/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	haizhicommon/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	haizhicommon/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	haizhicommon/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	haizhicommon/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	haizhicommon/hzlib/api_aws.py	/^import sys$/;"	i
terminate	haizhicommon/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	haizhicommon/hzlib/api_aws.py	/^import time$/;"	i
upload	haizhicommon/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	haizhicommon/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	haizhicommon/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	haizhicommon/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	haizhicommon/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	haizhicommon/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	haizhicommon/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	haizhicommon/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	haizhicommon/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	haizhicommon/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	haizhicommon/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	haizhicommon/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	haizhicommon/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	haizhicommon/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	haizhicommon/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	haizhicommon/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	haizhicommon/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	haizhicommon/hzlib/api_classify.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/api_classify.py	/^import collections$/;"	i
corpora	haizhicommon/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	haizhicommon/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	haizhicommon/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	haizhicommon/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	haizhicommon/hzlib/api_classify.py	/^import gensim$/;"	i
glob	haizhicommon/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	haizhicommon/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	haizhicommon/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	haizhicommon/hzlib/api_classify.py	/^import jieba$/;"	i
json	haizhicommon/hzlib/api_classify.py	/^import json$/;"	i
metrics	haizhicommon/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	haizhicommon/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	haizhicommon/hzlib/api_classify.py	/^import os$/;"	i
pprint	haizhicommon/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	haizhicommon/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	haizhicommon/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	haizhicommon/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	haizhicommon/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	haizhicommon/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	haizhicommon/hzlib/api_classify.py	/^import sys$/;"	i
train	haizhicommon/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	haizhicommon/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	haizhicommon/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	haizhicommon/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	haizhicommon/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	haizhicommon/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	haizhicommon/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	haizhicommon/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	haizhicommon/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	haizhicommon/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	haizhicommon/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	haizhicommon/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	haizhicommon/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	haizhicommon/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	haizhicommon/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	haizhicommon/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	haizhicommon/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	haizhicommon/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	haizhicommon/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	haizhicommon/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	haizhicommon/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	haizhicommon/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	haizhicommon/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	haizhicommon/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	haizhicommon/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	haizhicommon/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	haizhicommon/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	haizhicommon/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	haizhicommon/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	haizhicommon/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	haizhicommon/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	haizhicommon/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	haizhicommon/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	haizhicommon/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	haizhicommon/hzlib/api_zhidao.py	/^import random$/;"	i
re	haizhicommon/hzlib/api_zhidao.py	/^import re$/;"	i
requests	haizhicommon/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	haizhicommon/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	haizhicommon/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	haizhicommon/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	haizhicommon/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	haizhicommon/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	haizhicommon/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	haizhicommon/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	haizhicommon/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	haizhicommon/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	haizhicommon/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	haizhicommon/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	haizhicommon/hzlib/api_zhidao.py	/^import sys$/;"	i
time	haizhicommon/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	haizhicommon/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	haizhicommon/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	haizhicommon/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	haizhicommon/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	haizhicommon/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	haizhicommon/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	haizhicommon/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	haizhicommon/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	haizhicommon/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	haizhicommon/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	haizhicommon/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	haizhicommon/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	haizhicommon/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	haizhicommon/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	haizhicommon/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	haizhicommon/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	haizhicommon/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	haizhicommon/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	haizhicommon/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	haizhicommon/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	haizhicommon/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	haizhicommon/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	haizhicommon/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	haizhicommon/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	haizhicommon/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	haizhicommon/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	haizhicommon/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	haizhicommon/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	haizhicommon/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	haizhicommon/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	haizhicommon/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	haizhicommon/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	haizhicommon/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	haizhicommon/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	haizhicommon/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	haizhicommon/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	haizhicommon/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	haizhicommon/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	haizhicommon/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	haizhicommon/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	haizhicommon/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	haizhicommon/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	haizhicommon/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	haizhicommon/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	haizhicommon/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	haizhicommon/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	haizhicommon/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	haizhicommon/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	haizhicommon/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	haizhicommon/hzlib/eval_classify.py	/^import json$/;"	i
libdata	haizhicommon/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	haizhicommon/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	haizhicommon/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	haizhicommon/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	haizhicommon/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	haizhicommon/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	haizhicommon/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	haizhicommon/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	haizhicommon/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	haizhicommon/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	haizhicommon/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	haizhicommon/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	haizhicommon/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	haizhicommon/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	haizhicommon/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	haizhicommon/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	haizhicommon/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	haizhicommon/hzlib/libclassify.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/libclassify.py	/^import collections$/;"	i
corpora	haizhicommon/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	haizhicommon/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	haizhicommon/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	haizhicommon/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	haizhicommon/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	haizhicommon/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	haizhicommon/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	haizhicommon/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	haizhicommon/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	haizhicommon/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	haizhicommon/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	haizhicommon/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	haizhicommon/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	haizhicommon/hzlib/libclassify.py	/^import jieba$/;"	i
json	haizhicommon/hzlib/libclassify.py	/^import json$/;"	i
libfile	haizhicommon/hzlib/libclassify.py	/^    import libfile$/;"	i
main	haizhicommon/hzlib/libclassify.py	/^def main():$/;"	f
metrics	haizhicommon/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	haizhicommon/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	haizhicommon/hzlib/libclassify.py	/^import os$/;"	i
pickle	haizhicommon/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	haizhicommon/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	haizhicommon/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	haizhicommon/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	haizhicommon/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	haizhicommon/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	haizhicommon/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	haizhicommon/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	haizhicommon/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	haizhicommon/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	haizhicommon/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	haizhicommon/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	haizhicommon/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	haizhicommon/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	haizhicommon/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	haizhicommon/hzlib/libdata.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/libdata.py	/^import collections$/;"	i
datetime	haizhicommon/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	haizhicommon/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	haizhicommon/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	haizhicommon/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	haizhicommon/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	haizhicommon/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	haizhicommon/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	haizhicommon/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	haizhicommon/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	haizhicommon/hzlib/libdata.py	/^import os$/;"	i
print_json	haizhicommon/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	haizhicommon/hzlib/libdata.py	/^import random$/;"	i
re	haizhicommon/hzlib/libdata.py	/^import re$/;"	i
requests	haizhicommon/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	haizhicommon/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	haizhicommon/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	haizhicommon/hzlib/libdata.py	/^import sys$/;"	i
time	haizhicommon/hzlib/libdata.py	/^import time$/;"	i
codecs	haizhicommon/hzlib/libfile.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	haizhicommon/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	haizhicommon/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	haizhicommon/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	haizhicommon/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	haizhicommon/hzlib/libfile.py	/^import glob$/;"	i
hashlib	haizhicommon/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	haizhicommon/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	haizhicommon/hzlib/libfile.py	/^import json$/;"	i
json2file	haizhicommon/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	haizhicommon/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	haizhicommon/hzlib/libfile.py	/^import os$/;"	i
re	haizhicommon/hzlib/libfile.py	/^import re$/;"	i
readExcel	haizhicommon/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	haizhicommon/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	haizhicommon/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	haizhicommon/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	haizhicommon/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	haizhicommon/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	haizhicommon/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	haizhicommon/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	haizhicommon/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	haizhicommon/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	haizhicommon/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	haizhicommon/hzlib/libnlp.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	haizhicommon/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	haizhicommon/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	haizhicommon/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	haizhicommon/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	haizhicommon/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	haizhicommon/hzlib/libnlp.py	/^        import jieba$/;"	i
json	haizhicommon/hzlib/libnlp.py	/^import json$/;"	i
libfile	haizhicommon/hzlib/libnlp.py	/^import libfile$/;"	i
os	haizhicommon/hzlib/libnlp.py	/^import os$/;"	i
re	haizhicommon/hzlib/libnlp.py	/^import re$/;"	i
sys	haizhicommon/hzlib/libnlp.py	/^import sys$/;"	i
time	haizhicommon/hzlib/libnlp.py	/^import time$/;"	i
codecs	haizhicommon/hzlib/libregex.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/libregex.py	/^import collections$/;"	i
datetime	haizhicommon/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	haizhicommon/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	haizhicommon/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	haizhicommon/hzlib/libregex.py	/^import json$/;"	i
libfile	haizhicommon/hzlib/libregex.py	/^    import libfile$/;"	i
main	haizhicommon/hzlib/libregex.py	/^def main():$/;"	f
os	haizhicommon/hzlib/libregex.py	/^import os$/;"	i
re	haizhicommon/hzlib/libregex.py	/^import re$/;"	i
sys	haizhicommon/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	haizhicommon/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	haizhicommon/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	haizhicommon/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	haizhicommon/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	haizhicommon/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	haizhicommon/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	haizhicommon/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	haizhicommon/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	haizhicommon/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	haizhicommon/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	haizhicommon/hzlib/task_api_classify.py	/^def main():$/;"	f
os	haizhicommon/hzlib/task_api_classify.py	/^import os$/;"	i
re	haizhicommon/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	haizhicommon/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	haizhicommon/hzlib/task_api_classify.py	/^import sys$/;"	i
time	haizhicommon/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	haizhicommon/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	haizhicommon/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	haizhicommon/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	haizhicommon/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	haizhicommon/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	haizhicommon/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	haizhicommon/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	haizhicommon/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	haizhicommon/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	haizhicommon/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	haizhicommon/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	haizhicommon/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	haizhicommon/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	haizhicommon/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	haizhicommon/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	haizhicommon/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	haizhicommon/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	haizhicommon/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	haizhicommon/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	haizhicommon/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	haizhicommon/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	haizhicommon/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	haizhicommon/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	haizhicommon/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	haizhicommon/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	haizhicommon/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	haizhicommon/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	haizhicommon/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	haizhicommon/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	haizhicommon/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	haizhicommon/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	haizhicommon/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	haizhicommon/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	haizhicommon/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	haizhicommon/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	haizhicommon/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	haizhicommon/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	haizhicommon/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	haizhicommon/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	haizhicommon/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	haizhicommon/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	haizhicommon/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	haizhicommon/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	haizhicommon/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	haizhicommon/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	haizhicommon/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	haizhicommon/hzlib/test_libdata.py	/^import json$/;"	i
libdata	haizhicommon/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	haizhicommon/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	haizhicommon/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	haizhicommon/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	haizhicommon/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	haizhicommon/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	haizhicommon/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	haizhicommon/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	haizhicommon/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	haizhicommon/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	haizhicommon/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	haizhicommon/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	haizhicommon/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	haizhicommon/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	haizhicommon/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	haizhicommon/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	haizhicommon/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	haizhicommon/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	haizhicommon/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	haizhicommon/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	haizhicommon/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	haizhicommon/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	haizhicommon/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	haizhicommon/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	haizhicommon/hzlib/tests/test_api.py	/^import json$/;"	i
os	haizhicommon/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	haizhicommon/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	haizhicommon/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	haizhicommon/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	haizhicommon/hzlib/tests/test_api.py	/^def test_search():$/;"	f
Downloader	haizhicommon/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	haizhicommon/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	haizhicommon/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	haizhicommon/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	haizhicommon/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	haizhicommon/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	haizhicommon/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	haizhicommon/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	haizhicommon/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	haizhicommon/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	haizhicommon/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	haizhicommon/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	haizhicommon/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	haizhicommon/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	haizhicommon/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	haizhicommon/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	haizhicommon/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	haizhicommon/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	haizhicommon/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	haizhicommon/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	haizhicommon/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	haizhicommon/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	haizhicommon/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	haizhicommon/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	haizhicommon/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	haizhicommon/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	haizhicommon/parsers/qichacha2.py	/^import re$/;"	i
traceback	haizhicommon/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	haizhicommon/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	haizhicommon/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	haizhicommon/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	haizhicommon/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	haizhicommon/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	haizhicommon/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	haizhicommon/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	haizhicommon/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	haizhicommon/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	haizhicommon/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	haizhicommon/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	haizhicommon/parsers/qiparser2.py	/^import re$/;"	i
string	haizhicommon/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	haizhicommon/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	haizhicommon/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	haizhicommon/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	haizhicommon/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	haizhicommon/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	haizhicommon/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	haizhicommon/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	haizhicommon/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	haizhicommon/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	haizhicommon/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	haizhicommon/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	haizhicommon/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	haizhicommon/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	haizhicommon/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	haizhicommon/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	haizhicommon/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	haizhicommon/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	haizhicommon/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	haizhicommon/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	haizhicommon/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	haizhicommon/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
HashQueue	haizhicommon/rediscluster/queues.py	/^class HashQueue(object):$/;"	c
Queue	haizhicommon/rediscluster/queues.py	/^class Queue(object):$/;"	c
Record	haizhicommon/rediscluster/queues.py	/^from record import Record$/;"	i
RedisPool	haizhicommon/rediscluster/queues.py	/^from redispool import RedisPool$/;"	i
__init__	haizhicommon/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:HashQueue
__init__	haizhicommon/rediscluster/queues.py	/^    def __init__(self, key, priority=1, timeout=180, failure_times=3):$/;"	m	class:Queue
background_cleaning	haizhicommon/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:HashQueue
background_cleaning	haizhicommon/rediscluster/queues.py	/^    def background_cleaning(self):$/;"	m	class:Queue
clean_task	haizhicommon/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:HashQueue
clean_task	haizhicommon/rediscluster/queues.py	/^    def clean_task(self):$/;"	m	class:Queue
clear	haizhicommon/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:HashQueue
clear	haizhicommon/rediscluster/queues.py	/^    def clear(self):$/;"	m	class:Queue
datetime	haizhicommon/rediscluster/queues.py	/^from datetime import datetime$/;"	i
delete	haizhicommon/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:HashQueue
delete	haizhicommon/rediscluster/queues.py	/^    def delete(self, *items):$/;"	m	class:Queue
flush	haizhicommon/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:HashQueue
flush	haizhicommon/rediscluster/queues.py	/^    def flush(self):$/;"	m	class:Queue
get	haizhicommon/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:HashQueue
get	haizhicommon/rediscluster/queues.py	/^    def get(self, block=True, timeout=None, interval=0.1):$/;"	m	class:Queue
get_background_cleaning_status	haizhicommon/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:HashQueue
get_background_cleaning_status	haizhicommon/rediscluster/queues.py	/^    def get_background_cleaning_status(self):$/;"	m	class:Queue
get_failed_fields	haizhicommon/rediscluster/queues.py	/^    def get_failed_fields(self):$/;"	m	class:Queue
get_failed_times	haizhicommon/rediscluster/queues.py	/^    def get_failed_times(self, field):$/;"	m	class:Queue
poll	haizhicommon/rediscluster/queues.py	/^def poll(queues, timeout=None):$/;"	f
put	haizhicommon/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:HashQueue
put	haizhicommon/rediscluster/queues.py	/^    def put(self, *items):$/;"	m	class:Queue
put_init	haizhicommon/rediscluster/queues.py	/^    def put_init(self, *items):$/;"	m	class:HashQueue
qsize	haizhicommon/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:HashQueue
qsize	haizhicommon/rediscluster/queues.py	/^    def qsize(self):$/;"	m	class:Queue
set_failed_times_to_url	haizhicommon/rediscluster/queues.py	/^    def set_failed_times_to_url(self, field, url):$/;"	m	class:Queue
task_done	haizhicommon/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:HashQueue
task_done	haizhicommon/rediscluster/queues.py	/^    def task_done(self, result):$/;"	m	class:Queue
task_start	haizhicommon/rediscluster/queues.py	/^    def task_start(self, result):$/;"	m	class:Queue
task_start	haizhicommon/rediscluster/queues.py	/^    def task_start(self, result, count):$/;"	m	class:HashQueue
task_start_batch	haizhicommon/rediscluster/queues.py	/^    def task_start_batch(self, results):$/;"	m	class:Queue
time	haizhicommon/rediscluster/queues.py	/^import time$/;"	i
Record	haizhicommon/rediscluster/record.py	/^class Record(object):$/;"	c
RedisPool	haizhicommon/rediscluster/record.py	/^from redispool import RedisPool$/;"	i
ResponseError	haizhicommon/rediscluster/record.py	/^from redis import ResponseError$/;"	i
__init__	haizhicommon/rediscluster/record.py	/^    def __init__(self):$/;"	m	class:Record
add_exception	haizhicommon/rediscluster/record.py	/^    def add_exception(self, batch_id, url, error):$/;"	m	class:Record
begin	haizhicommon/rediscluster/record.py	/^    def begin(self, batch_id, parameter, total, priority):$/;"	m	class:Record
connect	haizhicommon/rediscluster/record.py	/^    def connect(self):$/;"	m	class:Record
datetime	haizhicommon/rediscluster/record.py	/^from datetime import datetime$/;"	i
division	haizhicommon/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
get_parameter	haizhicommon/rediscluster/record.py	/^    def get_parameter(self, batch_id):$/;"	m	class:Record
get_priority	haizhicommon/rediscluster/record.py	/^    def get_priority(self, batch_id):$/;"	m	class:Record
get_total_number	haizhicommon/rediscluster/record.py	/^    def get_total_number(self, batch_id):$/;"	m	class:Record
get_unfinished_batch	haizhicommon/rediscluster/record.py	/^    def get_unfinished_batch(self):$/;"	m	class:Record
if_not_finish_set	haizhicommon/rediscluster/record.py	/^    def if_not_finish_set(self, batch_id):$/;"	m	class:Record
increase_failed	haizhicommon/rediscluster/record.py	/^    def increase_failed(self, batch_id, count=1):$/;"	m	class:Record
increase_success	haizhicommon/rediscluster/record.py	/^    def increase_success(self, batch_id, count=1):$/;"	m	class:Record
instance	haizhicommon/rediscluster/record.py	/^    def instance(cls):$/;"	m	class:Record
is_finished	haizhicommon/rediscluster/record.py	/^    def is_finished(self, batch_id):$/;"	m	class:Record
print_function	haizhicommon/rediscluster/record.py	/^from __future__ import print_function, division$/;"	i
Queue	haizhicommon/rediscluster/redismanager.py	/^from rediscluster.queues import Queue$/;"	i
Record	haizhicommon/rediscluster/redismanager.py	/^from rediscluster.record import Record$/;"	i
RedisManager	haizhicommon/rediscluster/redismanager.py	/^class RedisManager(object):$/;"	c
RedisPool	haizhicommon/rediscluster/redismanager.py	/^from rediscluster.redispool import RedisPool$/;"	i
ThinHash	haizhicommon/rediscluster/redismanager.py	/^from rediscluster.thinredis import ThinHash$/;"	i
__check_empty_queue	haizhicommon/rediscluster/redismanager.py	/^    def __check_empty_queue(self, queue):$/;"	m	class:RedisManager	file:
__init__	haizhicommon/rediscluster/redismanager.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisManager
delete_queue	haizhicommon/rediscluster/redismanager.py	/^    def delete_queue(self, batch_id):$/;"	m	class:RedisManager
division	haizhicommon/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
get_distributed_queue	haizhicommon/rediscluster/redismanager.py	/^    def get_distributed_queue(self, batch_id):$/;"	m	class:RedisManager
get_queue_with_priority	haizhicommon/rediscluster/redismanager.py	/^    def get_queue_with_priority(self):$/;"	m	class:RedisManager
get_status	haizhicommon/rediscluster/redismanager.py	/^    def get_status(self, batch_id):$/;"	m	class:RedisManager
hashlib	haizhicommon/rediscluster/redismanager.py	/^import hashlib$/;"	i
init_distributed_queue	haizhicommon/rediscluster/redismanager.py	/^    def init_distributed_queue(self,$/;"	m	class:RedisManager
itemgetter	haizhicommon/rediscluster/redismanager.py	/^from operator import itemgetter$/;"	i
print_function	haizhicommon/rediscluster/redismanager.py	/^from __future__ import print_function, division$/;"	i
put_url_enqueue	haizhicommon/rediscluster/redismanager.py	/^    def put_url_enqueue(self, batch_id, url):$/;"	m	class:RedisManager
put_urls_enqueue	haizhicommon/rediscluster/redismanager.py	/^    def put_urls_enqueue(self, batch_id, urls):$/;"	m	class:RedisManager
set_distributed_queue	haizhicommon/rediscluster/redismanager.py	/^    def set_distributed_queue(self, batch_id, queue, thinhash, priority, refresh=True):$/;"	m	class:RedisManager
worker_init_distributed_queue	haizhicommon/rediscluster/redismanager.py	/^    def worker_init_distributed_queue(self, batch_id, total_count):$/;"	m	class:RedisManager
CACHE_REDIS	haizhicommon/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
QUEUE_REDIS	haizhicommon/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Queue	haizhicommon/rediscluster/redismonitor.py	/^from rediscluster.queues import Queue$/;"	i
RECORD_REDIS	haizhicommon/rediscluster/redismonitor.py	/^from settings import RECORD_REDIS, QUEUE_REDIS, CACHE_REDIS$/;"	i
Record	haizhicommon/rediscluster/redismonitor.py	/^from rediscluster.record import Record$/;"	i
RedisPool	haizhicommon/rediscluster/redismonitor.py	/^from rediscluster.redispool import RedisPool$/;"	i
argparse	haizhicommon/rediscluster/redismonitor.py	/^    import argparse$/;"	i
division	haizhicommon/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
get_status	haizhicommon/rediscluster/redismonitor.py	/^def get_status(batch_id):$/;"	f
init	haizhicommon/rediscluster/redismonitor.py	/^def init():$/;"	f
interval	haizhicommon/rediscluster/redismonitor.py	/^def interval(val, func, arg):$/;"	f
main	haizhicommon/rediscluster/redismonitor.py	/^def main():$/;"	f
os	haizhicommon/rediscluster/redismonitor.py	/^import os$/;"	i
parse_args	haizhicommon/rediscluster/redismonitor.py	/^def parse_args():$/;"	f
print_function	haizhicommon/rediscluster/redismonitor.py	/^from __future__ import print_function, division$/;"	i
sys	haizhicommon/rediscluster/redismonitor.py	/^import sys$/;"	i
time	haizhicommon/rediscluster/redismonitor.py	/^import time$/;"	i
RedisPool	haizhicommon/rediscluster/redispool.py	/^class RedisPool(object):$/;"	c
__init__	haizhicommon/rediscluster/redispool.py	/^    def __init__(self, record_redis, queue_redis, cache_redis, poolsize=5):$/;"	m	class:RedisPool
contextlib	haizhicommon/rediscluster/redispool.py	/^import contextlib$/;"	i
division	haizhicommon/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
instance	haizhicommon/rediscluster/redispool.py	/^    def instance(cls, *args):$/;"	m	class:RedisPool
print_function	haizhicommon/rediscluster/redispool.py	/^from __future__ import print_function, division$/;"	i
re	haizhicommon/rediscluster/redispool.py	/^import re$/;"	i
redis	haizhicommon/rediscluster/redispool.py	/^import redis$/;"	i
HashRing	haizhicommon/rediscluster/shardredis.py	/^from hash_ring import HashRing$/;"	i
Redis	haizhicommon/rediscluster/shardredis.py	/^from redis import Redis$/;"	i
ShardRedis	haizhicommon/rediscluster/shardredis.py	/^class ShardRedis(object):$/;"	c
__getattribute__	haizhicommon/rediscluster/shardredis.py	/^    def __getattribute__(self, name):$/;"	m	class:ShardRedis	file:
__init__	haizhicommon/rediscluster/shardredis.py	/^    def __init__(self, conns, pipelines=None):$/;"	m	class:ShardRedis
cache	haizhicommon/rediscluster/shardredis.py	/^    cache = {}$/;"	v	class:ShardRedis
cmd_hashes	haizhicommon/rediscluster/shardredis.py	/^cmd_hashes = {'hdel', 'hincrby', 'hmget', 'hvals', 'hexists', 'hincrbyfloat', 'hmset', 'hget',$/;"	v
cmd_keys	haizhicommon/rediscluster/shardredis.py	/^cmd_keys = {'delete', 'keys', 'pexpire', 'renamenx', 'dump', 'migrate', 'pexpireat', $/;"	v
cmd_lists	haizhicommon/rediscluster/shardredis.py	/^cmd_lists = {'blpop', 'llen', 'lrem', 'rpush', 'brpop', 'lpop', 'lset', 'rpushx', 'brpoplpush',$/;"	v
cmd_mods	haizhicommon/rediscluster/shardredis.py	/^cmd_mods = cmd_hashes | cmd_lists | cmd_sets | cmd_zsets | cmd_strings | cmd_supports$/;"	v
cmd_sets	haizhicommon/rediscluster/shardredis.py	/^cmd_sets = {'sadd', 'sinter', 'smove', 'sunion', 'scard', 'sinterstore', 'spop', 'sunionstore',$/;"	v
cmd_strings	haizhicommon/rediscluster/shardredis.py	/^cmd_strings = {'append', 'getbit', 'mget', 'setex', 'bitcount', 'getrange', 'mset', 'setnx',$/;"	v
cmd_supports	haizhicommon/rediscluster/shardredis.py	/^cmd_supports = {'delete', 'type'}$/;"	v
cmd_zsets	haizhicommon/rediscluster/shardredis.py	/^cmd_zsets = {'zadd', 'zinterstore', 'zrem', 'zrevrangebyscore', 'zcard', 'zrange', 'zremrangebyrank',$/;"	v
func	haizhicommon/rediscluster/shardredis.py	/^                def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__.func
func	haizhicommon/rediscluster/shardredis.py	/^            def func():$/;"	f	function:ShardRedis.__getattribute__
func	haizhicommon/rediscluster/shardredis.py	/^            def func(*args, **kwargs): $/;"	f	function:ShardRedis.__getattribute__
func	haizhicommon/rediscluster/shardredis.py	/^            def func(*args, **kwargs):$/;"	f	function:ShardRedis.__getattribute__
get_redis	haizhicommon/rediscluster/shardredis.py	/^    def get_redis(self, skey):$/;"	m	class:ShardRedis
getconn	haizhicommon/rediscluster/shardredis.py	/^    def getconn(self, index):$/;"	m	class:ShardRedis
conn	haizhicommon/rediscluster/test_hscan.py	/^conn = redis.StrictRedis()$/;"	v
division	haizhicommon/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
get	haizhicommon/rediscluster/test_hscan.py	/^def get():$/;"	f
key	haizhicommon/rediscluster/test_hscan.py	/^key = 'test'$/;"	v
print_function	haizhicommon/rediscluster/test_hscan.py	/^from __future__ import print_function, division$/;"	i
redis	haizhicommon/rediscluster/test_hscan.py	/^import redis$/;"	i
CappedSortedSet	haizhicommon/rediscluster/thinredis.py	/^class CappedSortedSet(object):$/;"	c
RedisPool	haizhicommon/rediscluster/thinredis.py	/^from redispool import RedisPool$/;"	i
ShardRedis	haizhicommon/rediscluster/thinredis.py	/^from shardredis import ShardRedis$/;"	i
ThinHash	haizhicommon/rediscluster/thinredis.py	/^class ThinHash(object):$/;"	c
ThinSet	haizhicommon/rediscluster/thinredis.py	/^class ThinSet(object):$/;"	c
__init__	haizhicommon/rediscluster/thinredis.py	/^    def __init__(self, key, cap, conn, **kwargs):$/;"	m	class:CappedSortedSet
__init__	haizhicommon/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinHash
__init__	haizhicommon/rediscluster/thinredis.py	/^    def __init__(self, key, totalcount, connection=None):$/;"	m	class:ThinSet
_get_bucket	haizhicommon/rediscluster/thinredis.py	/^    def _get_bucket(self, field):$/;"	m	class:ThinHash
_get_bucket	haizhicommon/rediscluster/thinredis.py	/^    def _get_bucket(self, item):$/;"	m	class:ThinSet
add	haizhicommon/rediscluster/thinredis.py	/^    def add(self, *items):$/;"	m	class:ThinSet
contains	haizhicommon/rediscluster/thinredis.py	/^    def contains(self, *items):$/;"	m	class:ThinSet
count	haizhicommon/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinHash
count	haizhicommon/rediscluster/thinredis.py	/^    def count(self):$/;"	m	class:ThinSet
delete	haizhicommon/rediscluster/thinredis.py	/^    def delete(self):$/;"	m	class:ThinHash
delete	haizhicommon/rediscluster/thinredis.py	/^    def delete(self, *items):$/;"	m	class:ThinSet
hashlib	haizhicommon/rediscluster/thinredis.py	/^import hashlib$/;"	i
hdel	haizhicommon/rediscluster/thinredis.py	/^    def hdel(self, field):$/;"	m	class:ThinHash
hget	haizhicommon/rediscluster/thinredis.py	/^    def hget(self, field):$/;"	m	class:ThinHash
hgetall	haizhicommon/rediscluster/thinredis.py	/^    def hgetall(self):$/;"	m	class:ThinHash
hkeys	haizhicommon/rediscluster/thinredis.py	/^    def hkeys(self):$/;"	m	class:ThinHash
hmget	haizhicommon/rediscluster/thinredis.py	/^    def hmget(self, *fields):$/;"	m	class:ThinHash
hmset	haizhicommon/rediscluster/thinredis.py	/^    def hmset(self, *args):$/;"	m	class:ThinHash
hset	haizhicommon/rediscluster/thinredis.py	/^    def hset(self, field, value):$/;"	m	class:ThinHash
inited	haizhicommon/rediscluster/thinredis.py	/^    inited = False$/;"	v	class:CappedSortedSet
recount	haizhicommon/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinHash
recount	haizhicommon/rediscluster/thinredis.py	/^    def recount(self):$/;"	m	class:ThinSet
redis	haizhicommon/rediscluster/thinredis.py	/^import redis$/;"	i
script	haizhicommon/rediscluster/thinredis.py	/^    script = '\\n'.join([$/;"	v	class:CappedSortedSet
sha1	haizhicommon/rediscluster/thinredis.py	/^    sha1 = hashlib.sha1(script).hexdigest()$/;"	v	class:CappedSortedSet
smembers	haizhicommon/rediscluster/thinredis.py	/^    def smembers(self):$/;"	m	class:ThinSet
zadd	haizhicommon/rediscluster/thinredis.py	/^    def zadd(self, member, score, **kwargs):$/;"	m	class:CappedSortedSet
zrange	haizhicommon/rediscluster/thinredis.py	/^    def zrange(self, start, end, **kwargs):$/;"	m	class:CappedSortedSet
call_with_throttling	haizhicommon/rediscluster/throttling.py	/^def call_with_throttling(func, args=(), kwargs={}, expected_processing_gap=0.1):$/;"	f
deque	haizhicommon/rediscluster/throttling.py	/^from collections import deque$/;"	i
division	haizhicommon/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
print_function	haizhicommon/rediscluster/throttling.py	/^from __future__ import print_function, division$/;"	i
remove_outdated	haizhicommon/rediscluster/throttling.py	/^    def remove_outdated():$/;"	f	function:call_with_throttling
smoothen_calling_interval	haizhicommon/rediscluster/throttling.py	/^    def smoothen_calling_interval():$/;"	f	function:call_with_throttling
time	haizhicommon/rediscluster/throttling.py	/^import time$/;"	i
wait_for_threshold	haizhicommon/rediscluster/throttling.py	/^    def wait_for_threshold():$/;"	f	function:call_with_throttling
AWS_ACCESS_ID	haizhicommon/reducer/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/reducer/awsapi/download_s3bucket.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
REGION_NAME	haizhicommon/reducer/awsapi/download_s3bucket.py	/^REGION_NAME = 'ap-northeast-1'$/;"	v
S3	haizhicommon/reducer/awsapi/download_s3bucket.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
boto3	haizhicommon/reducer/awsapi/download_s3bucket.py	/^import boto3$/;"	i
bucketname	haizhicommon/reducer/awsapi/download_s3bucket.py	/^    bucketname = 'fudankg-json'$/;"	v
compare_time	haizhicommon/reducer/awsapi/download_s3bucket.py	/^    compare_time = datetime(2016,7,1,2,0,0,).strftime('%Y%m%d%H%M%S') $/;"	v
count_bucket	haizhicommon/reducer/awsapi/download_s3bucket.py	/^def count_bucket(bucketname):$/;"	f
datetime	haizhicommon/reducer/awsapi/download_s3bucket.py	/^from datetime import datetime$/;"	i
delete_bucket	haizhicommon/reducer/awsapi/download_s3bucket.py	/^def delete_bucket(bucketname):$/;"	f
division	haizhicommon/reducer/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
down_fudankg	haizhicommon/reducer/awsapi/download_s3bucket.py	/^def down_fudankg(bucketname):$/;"	f
empty_bucket	haizhicommon/reducer/awsapi/download_s3bucket.py	/^def empty_bucket(bucketname, compare_time=None):$/;"	f
os	haizhicommon/reducer/awsapi/download_s3bucket.py	/^import os$/;"	i
print_function	haizhicommon/reducer/awsapi/download_s3bucket.py	/^from __future__ import print_function, division$/;"	i
save_to_local	haizhicommon/reducer/awsapi/download_s3bucket.py	/^def save_to_local(bucketname):$/;"	f
AWS_ACCESS_ID	haizhicommon/reducer/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/reducer/awsapi/ec2manager.py	/^from secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
Ec2Manager	haizhicommon/reducer/awsapi/ec2manager.py	/^class Ec2Manager(object):$/;"	c
__init__	haizhicommon/reducer/awsapi/ec2manager.py	/^    def __init__(self, region_name, tag='crawler', amiid=None):$/;"	m	class:Ec2Manager
boto3	haizhicommon/reducer/awsapi/ec2manager.py	/^import boto3$/;"	i
config	haizhicommon/reducer/awsapi/ec2manager.py	/^    config = {$/;"	v	class:Ec2Manager
create_instances	haizhicommon/reducer/awsapi/ec2manager.py	/^    def create_instances(self, MachineNum=1):$/;"	m	class:Ec2Manager
deque	haizhicommon/reducer/awsapi/ec2manager.py	/^from collections import deque$/;"	i
division	haizhicommon/reducer/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
get_ids_in_status	haizhicommon/reducer/awsapi/ec2manager.py	/^    def get_ids_in_status(self, status):$/;"	m	class:Ec2Manager
get_idx_by_id	haizhicommon/reducer/awsapi/ec2manager.py	/^    def get_idx_by_id(self, one_id):$/;"	m	class:Ec2Manager
get_ipaddr	haizhicommon/reducer/awsapi/ec2manager.py	/^    def get_ipaddr(self, one_id):$/;"	m	class:Ec2Manager
get_keypair	haizhicommon/reducer/awsapi/ec2manager.py	/^    def get_keypair(self):$/;"	m	class:Ec2Manager
print_function	haizhicommon/reducer/awsapi/ec2manager.py	/^from __future__ import print_function, division$/;"	i
start	haizhicommon/reducer/awsapi/ec2manager.py	/^    def start(self, ids):$/;"	m	class:Ec2Manager
stop	haizhicommon/reducer/awsapi/ec2manager.py	/^    def stop(self, ids):$/;"	m	class:Ec2Manager
stop_and_start	haizhicommon/reducer/awsapi/ec2manager.py	/^    def stop_and_start(self, group_num):$/;"	m	class:Ec2Manager
stop_one_and_restart	haizhicommon/reducer/awsapi/ec2manager.py	/^    def stop_one_and_restart(self):$/;"	m	class:Ec2Manager
terminate	haizhicommon/reducer/awsapi/ec2manager.py	/^    def terminate(self, ids):$/;"	m	class:Ec2Manager
time	haizhicommon/reducer/awsapi/ec2manager.py	/^import time$/;"	i
AWS_ACCESS_ID	haizhicommon/reducer/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/reducer/awsapi/s3object.py	/^from .secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
S3Object	haizhicommon/reducer/awsapi/s3object.py	/^class S3Object(object):$/;"	c
__init__	haizhicommon/reducer/awsapi/s3object.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:S3Object
boto3	haizhicommon/reducer/awsapi/s3object.py	/^import boto3$/;"	i
botocore	haizhicommon/reducer/awsapi/s3object.py	/^import botocore$/;"	i
create_bucket	haizhicommon/reducer/awsapi/s3object.py	/^    def create_bucket(self):$/;"	m	class:S3Object
division	haizhicommon/reducer/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
get_cache	haizhicommon/reducer/awsapi/s3object.py	/^    def get_cache(self, filename):$/;"	m	class:S3Object
hashlib	haizhicommon/reducer/awsapi/s3object.py	/^import hashlib$/;"	i
head_cache	haizhicommon/reducer/awsapi/s3object.py	/^    def head_cache(self, filename):$/;"	m	class:S3Object
print_function	haizhicommon/reducer/awsapi/s3object.py	/^from __future__ import print_function, division$/;"	i
put_cache	haizhicommon/reducer/awsapi/s3object.py	/^    def put_cache(self, filename, content):$/;"	m	class:S3Object
AWS_ACCESS_ID	haizhicommon/reducer/chem_program.py	/^from awsapi.secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/reducer/chem_program.py	/^from awsapi.secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
BUCKET	haizhicommon/reducer/chem_program.py	/^BUCKET = 'chem-json'$/;"	v
HOMEDIR	haizhicommon/reducer/chem_program.py	/^HOMEDIR = '\/home\/admin\/'$/;"	v
REGION_NAME	haizhicommon/reducer/chem_program.py	/^REGION_NAME = 'ap-northeast-1'$/;"	v
S3	haizhicommon/reducer/chem_program.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
boto3	haizhicommon/reducer/chem_program.py	/^import boto3$/;"	i
division	haizhicommon/reducer/chem_program.py	/^from __future__ import print_function, division$/;"	i
fake_save_bucket	haizhicommon/reducer/chem_program.py	/^def fake_save_bucket(bucketname, savepath):$/;"	f
hashlib	haizhicommon/reducer/chem_program.py	/^    import hashlib$/;"	i
os	haizhicommon/reducer/chem_program.py	/^    import os$/;"	i
print_function	haizhicommon/reducer/chem_program.py	/^from __future__ import print_function, division$/;"	i
save_bucket	haizhicommon/reducer/chem_program.py	/^def save_bucket(bucketname, savepath):$/;"	f
Controller	haizhicommon/reducer/controller.py	/^class Controller(object):$/;"	c
Ec2Manager	haizhicommon/reducer/controller.py	/^from awsapi.ec2manager import Ec2Manager$/;"	i
NoValidConnectionsError	haizhicommon/reducer/controller.py	/^from paramiko.ssh_exception import NoValidConnectionsError$/;"	i
__init__	haizhicommon/reducer/controller.py	/^    def __init__(self, batch_id, machine_num, region_name='ap-northeast-1', amiid=''):$/;"	m	class:Controller
argparse	haizhicommon/reducer/controller.py	/^    import argparse$/;"	i
base64	haizhicommon/reducer/controller.py	/^        import base64$/;"	i
division	haizhicommon/reducer/controller.py	/^from __future__ import print_function, division$/;"	i
dryrun	haizhicommon/reducer/controller.py	/^    def dryrun(cls, fname, total):$/;"	m	class:Controller
main	haizhicommon/reducer/controller.py	/^def main():$/;"	f
marshal	haizhicommon/reducer/controller.py	/^        import marshal$/;"	i
os	haizhicommon/reducer/controller.py	/^import os$/;"	i
paramiko	haizhicommon/reducer/controller.py	/^import paramiko$/;"	i
parse_arg	haizhicommon/reducer/controller.py	/^def parse_arg():$/;"	f
print_function	haizhicommon/reducer/controller.py	/^from __future__ import print_function, division$/;"	i
remote_command	haizhicommon/reducer/controller.py	/^    def remote_command(self, ipaddr, command, repeat=11):$/;"	m	class:Controller
run	haizhicommon/reducer/controller.py	/^    def run(self, fname):$/;"	m	class:Controller
run_command	haizhicommon/reducer/controller.py	/^    def run_command(self, one_id, base_cmd):$/;"	m	class:Controller
start_instances	haizhicommon/reducer/controller.py	/^    def start_instances(self):$/;"	m	class:Controller
stop_all_instances	haizhicommon/reducer/controller.py	/^    def stop_all_instances(self, *_):$/;"	m	class:Controller
time	haizhicommon/reducer/controller.py	/^import time$/;"	i
zlib	haizhicommon/reducer/controller.py	/^        import zlib$/;"	i
DEPLOY_ENV	haizhicommon/reducer/fabfile.py	/^DEPLOY_ENV = 'PRODUCTION'$/;"	v
deploy_run	haizhicommon/reducer/fabfile.py	/^def deploy_run():$/;"	f
deploy_worker	haizhicommon/reducer/fabfile.py	/^def deploy_worker():$/;"	f
division	haizhicommon/reducer/fabfile.py	/^from __future__ import print_function, division$/;"	i
print_function	haizhicommon/reducer/fabfile.py	/^from __future__ import print_function, division$/;"	i
runapp	haizhicommon/reducer/fabfile.py	/^def runapp(flag_run=True, param=None):$/;"	f
upload	haizhicommon/reducer/fabfile.py	/^def upload():$/;"	f
AWS_ACCESS_ID	haizhicommon/reducer/program.py	/^from awsapi.secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
AWS_SECRET_KEY	haizhicommon/reducer/program.py	/^from awsapi.secret import AWS_ACCESS_ID, AWS_SECRET_KEY$/;"	i
BUCKET	haizhicommon/reducer/program.py	/^BUCKET = 'searchzhidao2-json'$/;"	v
HOMEDIR	haizhicommon/reducer/program.py	/^HOMEDIR = '\/home\/admin\/'$/;"	v
REGION_NAME	haizhicommon/reducer/program.py	/^REGION_NAME = 'ap-northeast-1'$/;"	v
S3	haizhicommon/reducer/program.py	/^S3 = boto3.resource('s3', region_name=REGION_NAME, aws_access_key_id=AWS_ACCESS_ID, aws_secret_access_key=AWS_SECRET_KEY)$/;"	v
boto3	haizhicommon/reducer/program.py	/^import boto3$/;"	i
division	haizhicommon/reducer/program.py	/^from __future__ import print_function, division$/;"	i
fake_save_bucket	haizhicommon/reducer/program.py	/^def fake_save_bucket(bucketname, savepath):$/;"	f
hashlib	haizhicommon/reducer/program.py	/^    import hashlib$/;"	i
os	haizhicommon/reducer/program.py	/^    import os$/;"	i
print_function	haizhicommon/reducer/program.py	/^from __future__ import print_function, division$/;"	i
save_bucket	haizhicommon/reducer/program.py	/^def save_bucket(bucketname, savepath):$/;"	f
action	haizhicommon/reducer/reducer.py	/^def action(cmd, index, machine_num):$/;"	f
argparse	haizhicommon/reducer/reducer.py	/^    import argparse$/;"	i
base64	haizhicommon/reducer/reducer.py	/^import base64$/;"	i
division	haizhicommon/reducer/reducer.py	/^from __future__ import print_function, division$/;"	i
main	haizhicommon/reducer/reducer.py	/^def main():$/;"	f
marshal	haizhicommon/reducer/reducer.py	/^import marshal$/;"	i
os	haizhicommon/reducer/reducer.py	/^import os$/;"	i
parse_arg	haizhicommon/reducer/reducer.py	/^def parse_arg():$/;"	f
print_function	haizhicommon/reducer/reducer.py	/^from __future__ import print_function, division$/;"	i
sys	haizhicommon/reducer/reducer.py	/^import sys$/;"	i
zlib	haizhicommon/reducer/reducer.py	/^import zlib$/;"	i
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
file_name	projects/baiduzhidao/baidu_offline_parse.py	/^file_name = 'result\/zhidao0614'$/;"	v
json	projects/baiduzhidao/baidu_offline_parse.py	/^import json$/;"	i
os	projects/baiduzhidao/baidu_offline_parse.py	/^import os$/;"	i
pa	projects/baiduzhidao/baidu_offline_parse.py	/^pa = os.path.abspath(os.path.dirname(__file__))$/;"	v
parse	projects/baiduzhidao/baidu_offline_parse.py	/^def parse(response):$/;"	f
parse_best	projects/baiduzhidao/baidu_offline_parse.py	/^def parse_best(response):$/;"	f
parse_q_id	projects/baiduzhidao/baidu_offline_parse.py	/^def parse_q_id(content):$/;"	f
parse_quality	projects/baiduzhidao/baidu_offline_parse.py	/^def parse_quality(response):$/;"	f
parse_recommend	projects/baiduzhidao/baidu_offline_parse.py	/^def parse_recommend(response):$/;"	f
re	projects/baiduzhidao/baidu_offline_parse.py	/^import re$/;"	i
replace_count	projects/baiduzhidao/baidu_offline_parse.py	/^replace_count=0$/;"	v
scrapy	projects/baiduzhidao/baidu_offline_parse.py	/^import scrapy$/;"	i
sys	projects/baiduzhidao/baidu_offline_parse.py	/^import sys$/;"	i
time	projects/baiduzhidao/baidu_offline_parse.py	/^import time$/;"	i
traverseDirByListdir	projects/baiduzhidao/baidu_offline_parse.py	/^def traverseDirByListdir(path):$/;"	f
Downloader	projects/baiduzhidao/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	projects/baiduzhidao/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/baiduzhidao/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	projects/baiduzhidao/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/baiduzhidao/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/baiduzhidao/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/baiduzhidao/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/baiduzhidao/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/baiduzhidao/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	projects/baiduzhidao/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/baiduzhidao/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	projects/baiduzhidao/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	projects/baiduzhidao/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/baiduzhidao/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/baiduzhidao/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	projects/baiduzhidao/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	projects/baiduzhidao/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	projects/baiduzhidao/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/baiduzhidao/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	projects/baiduzhidao/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/baiduzhidao/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	projects/baiduzhidao/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/baiduzhidao/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/baiduzhidao/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	projects/baiduzhidao/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	projects/baiduzhidao/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	projects/baiduzhidao/parsers/qichacha2.py	/^import re$/;"	i
traceback	projects/baiduzhidao/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	projects/baiduzhidao/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	projects/baiduzhidao/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	projects/baiduzhidao/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/baiduzhidao/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	projects/baiduzhidao/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	projects/baiduzhidao/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	projects/baiduzhidao/parsers/qiparser2.py	/^import re$/;"	i
string	projects/baiduzhidao/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	projects/baiduzhidao/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	projects/baiduzhidao/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	projects/baiduzhidao/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	projects/baiduzhidao/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	projects/baiduzhidao/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	projects/baiduzhidao/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	projects/baiduzhidao/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	projects/baiduzhidao/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	projects/baiduzhidao/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	projects/baiduzhidao/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	projects/baiduzhidao/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	projects/baiduzhidao/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	projects/baiduzhidao/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
check_id	projects/baiduzhidao/read_xlsx.py	/^def check_id(one_id):$/;"	f
division	projects/baiduzhidao/read_xlsx.py	/^from __future__ import print_function, division$/;"	i
fname	projects/baiduzhidao/read_xlsx.py	/^fname = '百科服务对百度知道的测试用例.xlsx'$/;"	v
print_function	projects/baiduzhidao/read_xlsx.py	/^from __future__ import print_function, division$/;"	i
re	projects/baiduzhidao/read_xlsx.py	/^import re$/;"	i
read	projects/baiduzhidao/read_xlsx.py	/^def read(fname):$/;"	f
ret	projects/baiduzhidao/read_xlsx.py	/^ret = read(fname)$/;"	v
statistics	projects/baiduzhidao/read_xlsx.py	/^def statistics(result):$/;"	f
xlrd	projects/baiduzhidao/read_xlsx.py	/^import xlrd$/;"	i
BATCH_ID_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^BATCH_ID_FILE = DATA_PATH + "\/batch_id_record.txt"$/;"	v
DATA_PATH	projects/baiduzhidao/task_baiduzhidao.py	/^DATA_PATH = os.path.abspath(os.path.dirname(__file__)).replace("\/projects\/", "\/local\/") $/;"	v
FAIL_IDS_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^FAIL_IDS_FILE = DATA_PATH + "\/fail_ids.txt"$/;"	v
LINK_RAW_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^LINK_RAW_FILE = DATA_PATH + "\/link_question_all.txt"$/;"	v
LOG_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^LOG_FILE = DATA_PATH + "\/log"$/;"	v
OUTPUT_ES_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^OUTPUT_ES_FILE = DATA_PATH + "\/baiduzhidao.{}.esdata".format(VERSION)$/;"	v
SUCCESS_IDS_FILE	projects/baiduzhidao/task_baiduzhidao.py	/^SUCCESS_IDS_FILE = DATA_PATH + "\/success_ids.txt"$/;"	v
VERSION	projects/baiduzhidao/task_baiduzhidao.py	/^VERSION = "201605"$/;"	v
base64	projects/baiduzhidao/task_baiduzhidao.py	/^import base64$/;"	i
chardet	projects/baiduzhidao/task_baiduzhidao.py	/^import chardet$/;"	i
collections	projects/baiduzhidao/task_baiduzhidao.py	/^import collections$/;"	i
counter	projects/baiduzhidao/task_baiduzhidao.py	/^counter = collections.Counter()$/;"	v
crawl_url	projects/baiduzhidao/task_baiduzhidao.py	/^def crawl_url(url):$/;"	f
get_answer	projects/baiduzhidao/task_baiduzhidao.py	/^def get_answer(q_id, answer_id):$/;"	f
get_batch_id	projects/baiduzhidao/task_baiduzhidao.py	/^def get_batch_id():$/;"	f
json	projects/baiduzhidao/task_baiduzhidao.py	/^import json$/;"	i
logging	projects/baiduzhidao/task_baiduzhidao.py	/^import logging$/;"	i
os	projects/baiduzhidao/task_baiduzhidao.py	/^import os$/;"	i
parse	projects/baiduzhidao/task_baiduzhidao.py	/^def parse(content, q_id):$/;"	f
parse_answer_ids	projects/baiduzhidao/task_baiduzhidao.py	/^def parse_answer_ids(content):$/;"	f
parse_q_content	projects/baiduzhidao/task_baiduzhidao.py	/^def parse_q_content(content):$/;"	f
parse_q_time	projects/baiduzhidao/task_baiduzhidao.py	/^def parse_q_time(content):$/;"	f
parse_title	projects/baiduzhidao/task_baiduzhidao.py	/^def parse_title(content):$/;"	f
parse_username	projects/baiduzhidao/task_baiduzhidao.py	/^def parse_username(content):$/;"	f
re	projects/baiduzhidao/task_baiduzhidao.py	/^import re$/;"	i
read_success_ids	projects/baiduzhidao/task_baiduzhidao.py	/^def read_success_ids():$/;"	f
read_urls	projects/baiduzhidao/task_baiduzhidao.py	/^def read_urls():$/;"	f
requests	projects/baiduzhidao/task_baiduzhidao.py	/^import requests$/;"	i
run	projects/baiduzhidao/task_baiduzhidao.py	/^def run():$/;"	f
sys	projects/baiduzhidao/task_baiduzhidao.py	/^import sys$/;"	i
time	projects/baiduzhidao/task_baiduzhidao.py	/^import time$/;"	i
traceback	projects/baiduzhidao/task_baiduzhidao.py	/^import traceback$/;"	i
write_es	projects/baiduzhidao/task_baiduzhidao.py	/^def write_es(items):$/;"	f
write_fail_ids	projects/baiduzhidao/task_baiduzhidao.py	/^def write_fail_ids(fail_ids):$/;"	f
write_success_ids	projects/baiduzhidao/task_baiduzhidao.py	/^def write_success_ids(success_ids):$/;"	f
DIR	projects/baikekg/add_zgdbk_aliases.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
add_fudan_alias	projects/baikekg/add_zgdbk_aliases.py	/^def add_fudan_alias(dirname, fname):$/;"	f
codecs	projects/baikekg/add_zgdbk_aliases.py	/^import codecs$/;"	i
division	projects/baikekg/add_zgdbk_aliases.py	/^from __future__ import print_function, division$/;"	i
get_all_aliases	projects/baikekg/add_zgdbk_aliases.py	/^from load_alias import get_all_aliases$/;"	i
human_rule	projects/baikekg/add_zgdbk_aliases.py	/^def human_rule(entity):$/;"	f
itertools	projects/baikekg/add_zgdbk_aliases.py	/^import itertools$/;"	i
os	projects/baikekg/add_zgdbk_aliases.py	/^import os$/;"	i
print_function	projects/baikekg/add_zgdbk_aliases.py	/^from __future__ import print_function, division$/;"	i
sys	projects/baikekg/add_zgdbk_aliases.py	/^import sys$/;"	i
word_suffix_count	projects/baikekg/add_zgdbk_aliases.py	/^    def word_suffix_count():$/;"	f	function:human_rule
combination	projects/baikekg/algorithm.py	/^def combination(items):$/;"	f
defaultdict	projects/baikekg/algorithm.py	/^from collections import defaultdict$/;"	i
division	projects/baikekg/algorithm.py	/^from __future__ import print_function, division$/;"	i
postfix_match	projects/baikekg/algorithm.py	/^def postfix_match(word1, word2):$/;"	f
prefix_match	projects/baikekg/algorithm.py	/^def prefix_match(word1, word2):$/;"	f
print_function	projects/baikekg/algorithm.py	/^from __future__ import print_function, division$/;"	i
DIR	projects/baikekg/attr_engineer.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
attr_clustering	projects/baikekg/attr_engineer.py	/^def attr_clustering(fname):$/;"	f
combination	projects/baikekg/attr_engineer.py	/^from algorithm import combination$/;"	i
dirname	projects/baikekg/attr_engineer.py	/^    dirname = os.path.join(DIR, 'fudankg-json')$/;"	v
division	projects/baikekg/attr_engineer.py	/^from __future__ import print_function, division$/;"	i
fname	projects/baikekg/attr_engineer.py	/^    fname = os.path.join(DIR, 'attributes.txt')$/;"	v
get_attributes	projects/baikekg/attr_engineer.py	/^def get_attributes(dirname='fudankg-json'):$/;"	f
json	projects/baikekg/attr_engineer.py	/^import json$/;"	i
os	projects/baikekg/attr_engineer.py	/^import os$/;"	i
print_function	projects/baikekg/attr_engineer.py	/^from __future__ import print_function, division$/;"	i
read_file	projects/baikekg/attr_engineer.py	/^from load_entities import read_file, write_file$/;"	i
sys	projects/baikekg/attr_engineer.py	/^import sys$/;"	i
write_file	projects/baikekg/attr_engineer.py	/^from load_entities import read_file, write_file$/;"	i
compare	projects/baikekg/compare_dbpedia_wikidata.py	/^    compare = {}$/;"	v
db_data_unique	projects/baikekg/compare_dbpedia_wikidata.py	/^from entities_sort import db_data_unique$/;"	i
dbpediadata	projects/baikekg/compare_dbpedia_wikidata.py	/^    dbpediadata = load_dbpedia()$/;"	v
division	projects/baikekg/compare_dbpedia_wikidata.py	/^from __future__ import print_function, division$/;"	i
inter	projects/baikekg/compare_dbpedia_wikidata.py	/^    inter = random.sample(db_data_unique(), 10)$/;"	v
json	projects/baikekg/compare_dbpedia_wikidata.py	/^    import json$/;"	i
load_dbpedia	projects/baikekg/compare_dbpedia_wikidata.py	/^def load_dbpedia():$/;"	f
load_wikidata	projects/baikekg/compare_dbpedia_wikidata.py	/^def load_wikidata():$/;"	f
print_function	projects/baikekg/compare_dbpedia_wikidata.py	/^from __future__ import print_function, division$/;"	i
random	projects/baikekg/compare_dbpedia_wikidata.py	/^    import random$/;"	i
read_file_iter	projects/baikekg/compare_dbpedia_wikidata.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
regdisambiguation	projects/baikekg/compare_dbpedia_wikidata.py	/^from filter_lib import regdisambiguation$/;"	i
wikidata	projects/baikekg/compare_dbpedia_wikidata.py	/^    wikidata = load_wikidata()$/;"	v
write_file	projects/baikekg/compare_dbpedia_wikidata.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
DIR	projects/baikekg/dbpedia_to_es.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
division	projects/baikekg/dbpedia_to_es.py	/^from __future__ import print_function, division$/;"	i
load_dbpedia	projects/baikekg/dbpedia_to_es.py	/^def load_dbpedia():$/;"	f
print_function	projects/baikekg/dbpedia_to_es.py	/^from __future__ import print_function, division$/;"	i
read_file_iter	projects/baikekg/dbpedia_to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
send_definition_to_es	projects/baikekg/dbpedia_to_es.py	/^from to_es import send_definition_to_es$/;"	i
write_file	projects/baikekg/dbpedia_to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
Cache	projects/baikekg/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/baikekg/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/baikekg/downloader/cache.py	/^import base64$/;"	i
division	projects/baikekg/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/baikekg/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/baikekg/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/baikekg/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/baikekg/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/baikekg/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/baikekg/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/baikekg/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/baikekg/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/baikekg/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/baikekg/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/baikekg/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/baikekg/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/baikekg/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/baikekg/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/baikekg/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/baikekg/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/baikekg/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/baikekg/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/baikekg/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/baikekg/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/baikekg/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/baikekg/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/baikekg/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/baikekg/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/baikekg/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/baikekg/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/baikekg/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/baikekg/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/baikekg/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/baikekg/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/baikekg/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/baikekg/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/baikekg/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/baikekg/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/baikekg/downloader/downloader.py	/^import os$/;"	i
print_function	projects/baikekg/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/downloader/downloader.py	/^import re$/;"	i
request_download	projects/baikekg/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/baikekg/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/baikekg/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/baikekg/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/baikekg/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/baikekg/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/baikekg/downloader/downloader.py	/^import sys$/;"	i
time	projects/baikekg/downloader/downloader.py	/^import time$/;"	i
update_header	projects/baikekg/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/baikekg/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/baikekg/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/baikekg/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/baikekg/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/baikekg/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/baikekg/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/baikekg/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/baikekg/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/baikekg/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/baikekg/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/baikekg/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/baikekg/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/baikekg/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/baikekg/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/baikekg/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/baikekg/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/baikekg/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/baikekg/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/baikekg/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/baikekg/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/baikekg/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/baikekg/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/baikekg/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/baikekg/downloader/test_download.py	/^import datetime$/;"	i
json	projects/baikekg/downloader/test_download.py	/^import json$/;"	i
main	projects/baikekg/downloader/test_download.py	/^def main():$/;"	f
os	projects/baikekg/downloader/test_download.py	/^import os$/;"	i
re	projects/baikekg/downloader/test_download.py	/^import re$/;"	i
requests	projects/baikekg/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/baikekg/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/baikekg/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/baikekg/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/baikekg/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/baikekg/downloader/test_download.py	/^import time$/;"	i
urllib	projects/baikekg/downloader/test_download.py	/^import urllib$/;"	i
comic_song_extract_entity	projects/baikekg/entities_sort.py	/^from load_entities import (zgdbk_extract_entity, comic_song_extract_entity,$/;"	i
division	projects/baikekg/entities_sort.py	/^from __future__ import print_function, division$/;"	i
get_bdbk	projects/baikekg/entities_sort.py	/^def get_bdbk():$/;"	f
get_dbpedia_wikidata	projects/baikekg/entities_sort.py	/^def get_dbpedia_wikidata():$/;"	f
intersection_of3	projects/baikekg/entities_sort.py	/^def intersection_of3(dbpedia, wikidata, bdbk):$/;"	f
load_db_data_bd	projects/baikekg/entities_sort.py	/^def load_db_data_bd():$/;"	f
print_function	projects/baikekg/entities_sort.py	/^from __future__ import print_function, division$/;"	i
run	projects/baikekg/entities_sort.py	/^def run():$/;"	f
write_file	projects/baikekg/entities_sort.py	/^from hzlib.libfile import write_file$/;"	i
zgdbk_extract_entity	projects/baikekg/entities_sort.py	/^from load_entities import (zgdbk_extract_entity, comic_song_extract_entity,$/;"	i
DIR	projects/baikekg/entity_engineer.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
division	projects/baikekg/entity_engineer.py	/^from __future__ import print_function, division$/;"	i
entity_pure_chinese	projects/baikekg/entity_engineer.py	/^def entity_pure_chinese(fname):$/;"	f
fname	projects/baikekg/entity_engineer.py	/^    fname = os.path.join(DIR, 'zgdbk_entities.txt')$/;"	v
os	projects/baikekg/entity_engineer.py	/^import os$/;"	i
print_function	projects/baikekg/entity_engineer.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/entity_engineer.py	/^import re$/;"	i
regchinese	projects/baikekg/entity_engineer.py	/^from filter_lib import regchinese$/;"	i
sys	projects/baikekg/entity_engineer.py	/^import sys$/;"	i
INDEX_OPTION_DELETE	projects/baikekg/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	projects/baikekg/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	projects/baikekg/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	projects/baikekg/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	projects/baikekg/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	projects/baikekg/es/es_api.py	/^import codecs$/;"	i
collections	projects/baikekg/es/es_api.py	/^import collections$/;"	i
es_api_post	projects/baikekg/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	projects/baikekg/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	projects/baikekg/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	projects/baikekg/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	projects/baikekg/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	projects/baikekg/es/es_api.py	/^import hashlib$/;"	i
json	projects/baikekg/es/es_api.py	/^import json$/;"	i
os	projects/baikekg/es/es_api.py	/^import os$/;"	i
os	projects/baikekg/es/es_api.py	/^import os.path$/;"	i
path	projects/baikekg/es/es_api.py	/^import os.path$/;"	i
requests	projects/baikekg/es/es_api.py	/^import requests$/;"	i
run_batch	projects/baikekg/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	projects/baikekg/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	projects/baikekg/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	projects/baikekg/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	projects/baikekg/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	projects/baikekg/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	projects/baikekg/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	projects/baikekg/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	projects/baikekg/es/es_api.py	/^import sys$/;"	i
test	projects/baikekg/es/es_api.py	/^def test():$/;"	f
test_echo	projects/baikekg/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	projects/baikekg/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	projects/baikekg/es/es_api.py	/^import urllib$/;"	i
begin_filter_with_chinese	projects/baikekg/filter_entities.py	/^def begin_filter_with_chinese(fname):$/;"	f
begin_filter_with_lower	projects/baikekg/filter_entities.py	/^def begin_filter_with_lower(fname):$/;"	f
begin_filter_with_search	projects/baikekg/filter_entities.py	/^def begin_filter_with_search(fname):$/;"	f
division	projects/baikekg/filter_entities.py	/^from __future__ import print_function, division$/;"	i
entities	projects/baikekg/filter_entities.py	/^    entities = set()$/;"	v
print_function	projects/baikekg/filter_entities.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/filter_entities.py	/^import re$/;"	i
read_file_iter	projects/baikekg/filter_entities.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
regchinese	projects/baikekg/filter_entities.py	/^from filter_lib import regchinese, regentityfilt$/;"	i
regentityfilt	projects/baikekg/filter_entities.py	/^from filter_lib import regchinese, regentityfilt$/;"	i
sys	projects/baikekg/filter_entities.py	/^import sys$/;"	i
write_file	projects/baikekg/filter_entities.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
division	projects/baikekg/filter_lib.py	/^from __future__ import print_function, division$/;"	i
partial	projects/baikekg/filter_lib.py	/^from functools import partial$/;"	i
print_function	projects/baikekg/filter_lib.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/filter_lib.py	/^import re$/;"	i
regchinese	projects/baikekg/filter_lib.py	/^regchinese = re.compile(u'^[\\u4e00-\\u9fff]+$')$/;"	v
regdisambiguation	projects/baikekg/filter_lib.py	/^regdisambiguation = re.compile(u'(.*)_\\([^\\)]+\\)') # 101省道_(浙江)$/;"	v
regdropbrackets	projects/baikekg/filter_lib.py	/^regdropbrackets = re.compile(u'(.+?)(\\(|（).+(\\)|）)')$/;"	v
regentityfilt	projects/baikekg/filter_lib.py	/^regentityfilt = re.compile(u'^《?([\\u4e00-\\u9fff·\\-\\ A-Za-z0-9]+)》?(\\(|（)?[0-9,～\\u4e00-\\u9fff]*(\\)|）)?$')$/;"	v
regrmlabel	projects/baikekg/filter_lib.py	/^regrmlabel = partial(re.sub, '<\/?[A-Za-z]+>', '')$/;"	v
Counter	projects/baikekg/fudan_attr.py	/^from collections import Counter$/;"	i
DownloadWrapper	projects/baikekg/fudan_attr.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
FudanAttr	projects/baikekg/fudan_attr.py	/^class FudanAttr(object):$/;"	c
__init__	projects/baikekg/fudan_attr.py	/^    def __init__(self):$/;"	m	class:FudanAttr
batch_id	projects/baikekg/fudan_attr.py	/^    batch_id = {$/;"	v	class:FudanAttr
division	projects/baikekg/fudan_attr.py	/^from __future__ import print_function, division$/;"	i
fudan_attr_count	projects/baikekg/fudan_attr.py	/^    def fudan_attr_count(self, result):$/;"	m	class:FudanAttr
fudan_attrvalue	projects/baikekg/fudan_attr.py	/^    def fudan_attrvalue(self, entity):$/;"	m	class:FudanAttr
fudan_entities	projects/baikekg/fudan_attr.py	/^    def fudan_entities(self, word):$/;"	m	class:FudanAttr
fudan_gen_excel	projects/baikekg/fudan_attr.py	/^    def fudan_gen_excel(self, result):$/;"	m	class:FudanAttr
generate_entity_avp_excel	projects/baikekg/fudan_attr.py	/^def generate_entity_avp_excel():$/;"	f
generate_thousand_words	projects/baikekg/fudan_attr.py	/^def generate_thousand_words():$/;"	f
get_entity_avps_results	projects/baikekg/fudan_attr.py	/^def get_entity_avps_results():$/;"	f
itemgetter	projects/baikekg/fudan_attr.py	/^from operator import itemgetter$/;"	i
json	projects/baikekg/fudan_attr.py	/^import json$/;"	i
pick_some_words	projects/baikekg/fudan_attr.py	/^    def pick_some_words(self, words, num=1000):$/;"	m	class:FudanAttr
prepare_entities	projects/baikekg/fudan_attr.py	/^    def prepare_entities(self, entities_fname='entities_0623.txt'):$/;"	m	class:FudanAttr
print_function	projects/baikekg/fudan_attr.py	/^from __future__ import print_function, division$/;"	i
random	projects/baikekg/fudan_attr.py	/^import random$/;"	i
requests	projects/baikekg/fudan_attr.py	/^import requests$/;"	i
save_picked_words	projects/baikekg/fudan_attr.py	/^    def save_picked_words(self, words):$/;"	m	class:FudanAttr
sys	projects/baikekg/fudan_attr.py	/^import sys$/;"	i
urllib	projects/baikekg/fudan_attr.py	/^import urllib$/;"	i
writeExcel	projects/baikekg/fudan_attr.py	/^from hzlib.libfile import writeExcel$/;"	i
BATCH	projects/baikekg/fudankg_to_es.py	/^from to_es import summary, sendto_es, fudan_ea_to_json, send_definition_to_es, BATCH$/;"	i
Counter	projects/baikekg/fudankg_to_es.py	/^from collections import defaultdict, Counter$/;"	i
DIR	projects/baikekg/fudankg_to_es.py	/^DIR = '\/data\/crawler_file_cache\/fudankg_saved'$/;"	v
aliases	projects/baikekg/fudankg_to_es.py	/^def aliases():$/;"	f
class_attribute	projects/baikekg/fudankg_to_es.py	/^def class_attribute():$/;"	f
datetime	projects/baikekg/fudankg_to_es.py	/^from datetime import datetime$/;"	i
defaultdict	projects/baikekg/fudankg_to_es.py	/^from collections import defaultdict, Counter$/;"	i
division	projects/baikekg/fudankg_to_es.py	/^from __future__ import print_function, division$/;"	i
fudan_ea_to_json	projects/baikekg/fudankg_to_es.py	/^from to_es import summary, sendto_es, fudan_ea_to_json, send_definition_to_es, BATCH$/;"	i
json	projects/baikekg/fudankg_to_es.py	/^import json$/;"	i
load_fudankg_json_data	projects/baikekg/fudankg_to_es.py	/^def load_fudankg_json_data():$/;"	f
load_search_zhidao	projects/baikekg/fudankg_to_es.py	/^def load_search_zhidao():$/;"	f
os	projects/baikekg/fudankg_to_es.py	/^import os$/;"	i
print_function	projects/baikekg/fudankg_to_es.py	/^from __future__ import print_function, division$/;"	i
read_file_iter	projects/baikekg/fudankg_to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
regdropbrackets	projects/baikekg/fudankg_to_es.py	/^from filter_lib import regdropbrackets$/;"	i
send_definition_to_es	projects/baikekg/fudankg_to_es.py	/^from to_es import summary, sendto_es, fudan_ea_to_json, send_definition_to_es, BATCH$/;"	i
send_fudan_attribute_to_es	projects/baikekg/fudankg_to_es.py	/^def send_fudan_attribute_to_es(data):$/;"	f
sendto_es	projects/baikekg/fudankg_to_es.py	/^from to_es import summary, sendto_es, fudan_ea_to_json, send_definition_to_es, BATCH$/;"	i
summary	projects/baikekg/fudankg_to_es.py	/^from to_es import summary, sendto_es, fudan_ea_to_json, send_definition_to_es, BATCH$/;"	i
write_file	projects/baikekg/fudankg_to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
InstanceMgr	projects/baikekg/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/baikekg/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/baikekg/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/baikekg/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/baikekg/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/baikekg/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/baikekg/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/baikekg/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/baikekg/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/baikekg/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/baikekg/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/baikekg/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/baikekg/hzlib/api_aws.py	/^import json$/;"	i
list	projects/baikekg/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/baikekg/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/baikekg/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/baikekg/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/baikekg/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/baikekg/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/baikekg/hzlib/api_aws.py	/^import re$/;"	i
run	projects/baikekg/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/baikekg/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/baikekg/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/baikekg/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/baikekg/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/baikekg/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/baikekg/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/baikekg/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/baikekg/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/baikekg/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/baikekg/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/baikekg/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/baikekg/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/baikekg/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/baikekg/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/baikekg/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/baikekg/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/baikekg/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/baikekg/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/baikekg/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/baikekg/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/baikekg/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/baikekg/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/baikekg/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/baikekg/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/baikekg/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/baikekg/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/baikekg/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/baikekg/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/baikekg/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/baikekg/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/baikekg/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/baikekg/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/baikekg/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/baikekg/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/baikekg/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/baikekg/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/baikekg/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/baikekg/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/baikekg/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/baikekg/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/baikekg/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/baikekg/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/baikekg/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/baikekg/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/baikekg/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/baikekg/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/baikekg/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/baikekg/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/baikekg/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/baikekg/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/baikekg/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/baikekg/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/baikekg/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/baikekg/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/baikekg/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/baikekg/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/baikekg/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/baikekg/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/baikekg/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/baikekg/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/baikekg/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/baikekg/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/baikekg/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/baikekg/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/baikekg/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/baikekg/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/baikekg/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/baikekg/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/baikekg/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/baikekg/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/baikekg/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/baikekg/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/baikekg/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/baikekg/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/baikekg/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/baikekg/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/baikekg/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/baikekg/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/baikekg/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/baikekg/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/baikekg/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/baikekg/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/baikekg/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/baikekg/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/baikekg/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/baikekg/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/baikekg/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/baikekg/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/baikekg/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/baikekg/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/baikekg/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/baikekg/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/baikekg/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/baikekg/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/baikekg/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/baikekg/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/baikekg/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/baikekg/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/baikekg/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/baikekg/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/baikekg/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/baikekg/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/baikekg/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/baikekg/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/baikekg/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/baikekg/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/baikekg/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/baikekg/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/baikekg/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/baikekg/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/baikekg/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/baikekg/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/baikekg/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/baikekg/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/baikekg/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/baikekg/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/baikekg/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/baikekg/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/baikekg/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/baikekg/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/baikekg/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/baikekg/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/baikekg/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/baikekg/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/baikekg/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/baikekg/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/baikekg/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/baikekg/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/baikekg/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/baikekg/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/baikekg/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/baikekg/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/baikekg/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/baikekg/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/baikekg/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/baikekg/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/baikekg/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/baikekg/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/baikekg/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/baikekg/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/baikekg/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/baikekg/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/baikekg/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/baikekg/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/baikekg/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/baikekg/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/baikekg/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/baikekg/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/baikekg/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/baikekg/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/baikekg/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/baikekg/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/baikekg/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/baikekg/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/baikekg/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/baikekg/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/baikekg/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/baikekg/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/baikekg/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/baikekg/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/baikekg/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/baikekg/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/baikekg/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/baikekg/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/baikekg/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/baikekg/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/baikekg/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/baikekg/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/baikekg/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/baikekg/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/baikekg/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/baikekg/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/baikekg/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/baikekg/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/baikekg/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/baikekg/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/baikekg/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/baikekg/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/baikekg/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/baikekg/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/baikekg/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/baikekg/hzlib/libdata.py	/^import random$/;"	i
re	projects/baikekg/hzlib/libdata.py	/^import re$/;"	i
requests	projects/baikekg/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/baikekg/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/baikekg/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/baikekg/hzlib/libdata.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/baikekg/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/baikekg/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/baikekg/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/baikekg/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/baikekg/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/baikekg/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/baikekg/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/baikekg/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/baikekg/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/baikekg/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/baikekg/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/baikekg/hzlib/libfile.py	/^import os$/;"	i
re	projects/baikekg/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/baikekg/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/baikekg/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/baikekg/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/baikekg/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/baikekg/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/baikekg/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/baikekg/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/baikekg/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/baikekg/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/baikekg/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/baikekg/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/baikekg/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/baikekg/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/baikekg/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/baikekg/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/baikekg/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/baikekg/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/baikekg/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/baikekg/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/baikekg/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/baikekg/hzlib/libnlp.py	/^import os$/;"	i
re	projects/baikekg/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/baikekg/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/baikekg/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/baikekg/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/baikekg/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/baikekg/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/baikekg/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/baikekg/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/baikekg/hzlib/libregex.py	/^def main():$/;"	f
os	projects/baikekg/hzlib/libregex.py	/^import os$/;"	i
re	projects/baikekg/hzlib/libregex.py	/^import re$/;"	i
sys	projects/baikekg/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/baikekg/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/baikekg/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/baikekg/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/baikekg/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/baikekg/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/baikekg/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/baikekg/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/baikekg/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/baikekg/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/baikekg/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/baikekg/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/baikekg/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/baikekg/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/baikekg/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/baikekg/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/baikekg/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/baikekg/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/baikekg/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/baikekg/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/baikekg/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/baikekg/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/baikekg/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/baikekg/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/baikekg/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/baikekg/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/baikekg/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/baikekg/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/baikekg/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/baikekg/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/baikekg/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/baikekg/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/baikekg/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/baikekg/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/baikekg/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/baikekg/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/baikekg/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/baikekg/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/baikekg/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/baikekg/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/baikekg/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/baikekg/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/baikekg/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/baikekg/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/baikekg/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/baikekg/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/baikekg/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/baikekg/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/baikekg/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/baikekg/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/baikekg/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/baikekg/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/baikekg/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/baikekg/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/baikekg/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/baikekg/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/baikekg/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/baikekg/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/baikekg/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/baikekg/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/baikekg/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/baikekg/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/baikekg/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/baikekg/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/baikekg/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/baikekg/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/baikekg/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/baikekg/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/baikekg/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/baikekg/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/baikekg/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/baikekg/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/baikekg/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/baikekg/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/baikekg/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/baikekg/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/baikekg/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/baikekg/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/baikekg/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/baikekg/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/baikekg/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/baikekg/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/baikekg/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/baikekg/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/baikekg/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/baikekg/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/baikekg/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/baikekg/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/baikekg/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/baikekg/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/baikekg/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/baikekg/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/baikekg/hzlib/tests/test_api.py	/^def test_search():$/;"	f
DIR	projects/baikekg/load_alias.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
division	projects/baikekg/load_alias.py	/^from __future__ import print_function, division$/;"	i
extract_bdbk_with_alias	projects/baikekg/load_alias.py	/^def extract_bdbk_with_alias(ifilename):$/;"	f
get_all_aliases	projects/baikekg/load_alias.py	/^def get_all_aliases(entity):$/;"	f
load_bdbk_alias	projects/baikekg/load_alias.py	/^def load_bdbk_alias(dirname, fname):$/;"	f
load_fudankg_alias	projects/baikekg/load_alias.py	/^def load_fudankg_alias(dirname):$/;"	f
load_merge_step5_wiki_simplified	projects/baikekg/load_alias.py	/^def load_merge_step5_wiki_simplified(dirname, fname):$/;"	f
load_zhwiki_alias	projects/baikekg/load_alias.py	/^def load_zhwiki_alias(dirname, fname):$/;"	f
os	projects/baikekg/load_alias.py	/^import os$/;"	i
print_function	projects/baikekg/load_alias.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/load_alias.py	/^import re$/;"	i
read_file	projects/baikekg/load_alias.py	/^from hzlib.libfile import read_file, read_file_iter, write_file$/;"	i
read_file_iter	projects/baikekg/load_alias.py	/^from hzlib.libfile import read_file, read_file_iter, write_file$/;"	i
regchinese	projects/baikekg/load_alias.py	/^from filter_lib import regchinese, regdropbrackets$/;"	i
regdropbrackets	projects/baikekg/load_alias.py	/^from filter_lib import regchinese, regdropbrackets$/;"	i
write_file	projects/baikekg/load_alias.py	/^from hzlib.libfile import read_file, read_file_iter, write_file$/;"	i
bdbk_extract_entity	projects/baikekg/load_entities.py	/^def bdbk_extract_entity(ifilename, persistent=False):$/;"	f
codecs	projects/baikekg/load_entities.py	/^import codecs$/;"	i
comic_song_extract_entity	projects/baikekg/load_entities.py	/^def comic_song_extract_entity(fname, persistent=False):$/;"	f
dbpedia_extract_entity	projects/baikekg/load_entities.py	/^def dbpedia_extract_entity(fname, persistent=False):$/;"	f
division	projects/baikekg/load_entities.py	/^from __future__ import print_function, division$/;"	i
entities	projects/baikekg/load_entities.py	/^    entities = set()$/;"	v
json	projects/baikekg/load_entities.py	/^import json$/;"	i
print_function	projects/baikekg/load_entities.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/load_entities.py	/^import re$/;"	i
read_file_iter	projects/baikekg/load_entities.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
regdisambiguation	projects/baikekg/load_entities.py	/^from filter_lib import regdisambiguation, regdropbrackets, regrmlabel$/;"	i
regdropbrackets	projects/baikekg/load_entities.py	/^from filter_lib import regdisambiguation, regdropbrackets, regrmlabel$/;"	i
regrmlabel	projects/baikekg/load_entities.py	/^from filter_lib import regdisambiguation, regdropbrackets, regrmlabel$/;"	i
string	projects/baikekg/load_entities.py	/^import string$/;"	i
sys	projects/baikekg/load_entities.py	/^import sys$/;"	i
wiki_extract_entity	projects/baikekg/load_entities.py	/^def wiki_extract_entity(fname, persistent=False):$/;"	f
wiki_title_entity	projects/baikekg/load_entities.py	/^def wiki_title_entity(fname, persistent=False):$/;"	f
write_file	projects/baikekg/load_entities.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
zgdbk_extract_entity	projects/baikekg/load_entities.py	/^def zgdbk_extract_entity(infilename, persistent=False):$/;"	f
zgdbk_parse_entity	projects/baikekg/load_entities.py	/^def zgdbk_parse_entity(entity):$/;"	f
division	projects/baikekg/load_info.py	/^from __future__ import print_function, division$/;"	i
html	projects/baikekg/load_info.py	/^import lxml.html$/;"	i
lxml	projects/baikekg/load_info.py	/^import lxml.html$/;"	i
print_function	projects/baikekg/load_info.py	/^from __future__ import print_function, division$/;"	i
read_file	projects/baikekg/load_info.py	/^from hzlib.libfile import read_file, write_file$/;"	i
write_file	projects/baikekg/load_info.py	/^from hzlib.libfile import read_file, write_file$/;"	i
zgdbk_extract_info	projects/baikekg/load_info.py	/^def zgdbk_extract_info():$/;"	f
Counter	projects/baikekg/preprocess_fudankg.py	/^from collections import defaultdict, Counter$/;"	i
defaultdict	projects/baikekg/preprocess_fudankg.py	/^from collections import defaultdict, Counter$/;"	i
division	projects/baikekg/preprocess_fudankg.py	/^from __future__ import print_function, division$/;"	i
find_other_package	projects/baikekg/preprocess_fudankg.py	/^    def find_other_package(entity, original):$/;"	f	function:merge_fudankg
get_fudankg_entity	projects/baikekg/preprocess_fudankg.py	/^def get_fudankg_entity(entity_dict=False):$/;"	f
get_fudanperiod_entity	projects/baikekg/preprocess_fudankg.py	/^def get_fudanperiod_entity(entity_dict=False):     # get fudaninc entities stored in periodCache$/;"	f
hashlib	projects/baikekg/preprocess_fudankg.py	/^import hashlib$/;"	i
information_exist_proportion	projects/baikekg/preprocess_fudankg.py	/^def information_exist_proportion():$/;"	f
json	projects/baikekg/preprocess_fudankg.py	/^import json$/;"	i
merge_fudankg	projects/baikekg/preprocess_fudankg.py	/^def merge_fudankg(bucketname):$/;"	f
os	projects/baikekg/preprocess_fudankg.py	/^import os$/;"	i
print_function	projects/baikekg/preprocess_fudankg.py	/^from __future__ import print_function, division$/;"	i
regdropbrackets	projects/baikekg/preprocess_fudankg.py	/^from filter_lib import regdropbrackets$/;"	i
sys	projects/baikekg/preprocess_fudankg.py	/^    import sys$/;"	i
time	projects/baikekg/preprocess_fudankg.py	/^import time$/;"	i
urllib	projects/baikekg/preprocess_fudankg.py	/^import urllib$/;"	i
write_file	projects/baikekg/preprocess_fudankg.py	/^    from hzlib.libfile import write_file$/;"	i
Counter	projects/baikekg/script.py	/^from collections import Counter, defaultdict$/;"	i
alphabet	projects/baikekg/script.py	/^alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'$/;"	v
defaultdict	projects/baikekg/script.py	/^from collections import Counter, defaultdict$/;"	i
division	projects/baikekg/script.py	/^from __future__ import print_function, division$/;"	i
json	projects/baikekg/script.py	/^import json$/;"	i
print_function	projects/baikekg/script.py	/^from __future__ import print_function, division$/;"	i
punctuation	projects/baikekg/script.py	/^punctuation = '!@#$%^&*()-_+={}[]|\\;:<>,.\/?~`，。、！？（）‘’《》｛｝＊…～★【】“” ｜”『』'$/;"	v
random_pick_100_fudan_definition	projects/baikekg/script.py	/^def random_pick_100_fudan_definition(fname):$/;"	f
split_by_word_length	projects/baikekg/script.py	/^def split_by_word_length(fname):$/;"	f
statistics_length_by_word	projects/baikekg/script.py	/^def statistics_length_by_word():$/;"	f
symbol	projects/baikekg/script.py	/^symbol = alphabet + punctuation$/;"	v
sys	projects/baikekg/script.py	/^import sys$/;"	i
test_coverage	projects/baikekg/script.py	/^def test_coverage():$/;"	f
BATCH	projects/baikekg/to_es.py	/^BATCH = 5000$/;"	v
Counter	projects/baikekg/to_es.py	/^from collections import defaultdict, Counter$/;"	i
DIR	projects/baikekg/to_es.py	/^DIR = '\/Users\/bishop\/百度云同步盘\/'$/;"	v
ENV	projects/baikekg/to_es.py	/^ENV = 'local'$/;"	v
ES_DATASET_CONFIG	projects/baikekg/to_es.py	/^ES_DATASET_CONFIG = {$/;"	v
batch_init	projects/baikekg/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows, gen_es_id$/;"	i
datetime	projects/baikekg/to_es.py	/^from datetime import datetime$/;"	i
defaultdict	projects/baikekg/to_es.py	/^from collections import defaultdict, Counter$/;"	i
division	projects/baikekg/to_es.py	/^from __future__ import print_function, division$/;"	i
ea_to_json	projects/baikekg/to_es.py	/^def ea_to_json(entity, attribute, attribute_name, extra_tag, values):$/;"	f
fudan_ea_to_json	projects/baikekg/to_es.py	/^def fudan_ea_to_json(entity, attribute, attribute_name, extra_tag, values, category=None, searchscore=None, alias=[]):$/;"	f
gen_es_id	projects/baikekg/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows, gen_es_id$/;"	i
get_all_aliases	projects/baikekg/to_es.py	/^from load_alias import get_all_aliases$/;"	i
get_entity_avps_results	projects/baikekg/to_es.py	/^from fudan_attr import get_entity_avps_results$/;"	i
get_esconfig	projects/baikekg/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows, gen_es_id$/;"	i
hashlib	projects/baikekg/to_es.py	/^import hashlib$/;"	i
insert	projects/baikekg/to_es.py	/^def insert():$/;"	f
itemgetter	projects/baikekg/to_es.py	/^from operator import itemgetter$/;"	i
json	projects/baikekg/to_es.py	/^import json$/;"	i
load_alias_mapping	projects/baikekg/to_es.py	/^def load_alias_mapping():$/;"	f
load_attribute_mapping	projects/baikekg/to_es.py	/^def load_attribute_mapping():$/;"	f
load_fudan_json_files	projects/baikekg/to_es.py	/^def load_fudan_json_files(dirname='.'):$/;"	f
load_zgdbk_info	projects/baikekg/to_es.py	/^def load_zgdbk_info(dirname='.'):$/;"	f
os	projects/baikekg/to_es.py	/^import os$/;"	i
parse_fudan_entity	projects/baikekg/to_es.py	/^def parse_fudan_entity(entity, avps):$/;"	f
print_function	projects/baikekg/to_es.py	/^from __future__ import print_function, division$/;"	i
re	projects/baikekg/to_es.py	/^import re$/;"	i
readExcel	projects/baikekg/to_es.py	/^from hzlib.libfile import readExcel$/;"	i
read_file_iter	projects/baikekg/to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
regdropbrackets	projects/baikekg/to_es.py	/^from filter_lib import regdropbrackets$/;"	i
run_esbulk_rows	projects/baikekg/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows, gen_es_id$/;"	i
send_definition_to_es	projects/baikekg/to_es.py	/^def send_definition_to_es(data, field='definition', fudan=False):$/;"	f
sendto_es	projects/baikekg/to_es.py	/^def sendto_es(eavps):$/;"	f
summary	projects/baikekg/to_es.py	/^def summary(text):$/;"	f
write_file	projects/baikekg/to_es.py	/^from hzlib.libfile import read_file_iter, write_file$/;"	i
ES_DATASET_CONFIG	projects/chat4xianliao/chat/task_es.py	/^ES_DATASET_CONFIG ={$/;"	v
ZhidaoNlp	projects/chat4xianliao/chat/task_es.py	/^from hzlib.api_zhidao import ZhidaoNlp$/;"	i
ZhidaoQa	projects/chat4xianliao/chat/task_es.py	/^class ZhidaoQa():$/;"	c
__init__	projects/chat4xianliao/chat/task_es.py	/^    def __init__(self, config_option="prod", dryrun=True):$/;"	m	class:ZhidaoQa
_filter_filenames	projects/chat4xianliao/chat/task_es.py	/^    def _filter_filenames(self,  dataset_index, option):$/;"	m	class:ZhidaoQa
_index_qa	projects/chat4xianliao/chat/task_es.py	/^    def _index_qa(self, filenames, dataset_index, filter_option=0):$/;"	m	class:ZhidaoQa
_merge_chat	projects/chat4xianliao/chat/task_es.py	/^    def _merge_chat(self, filenames, option):$/;"	m	class:ZhidaoQa
clean_answer	projects/chat4xianliao/chat/task_es.py	/^def clean_answer(text):$/;"	f
clean_dupword	projects/chat4xianliao/chat/task_es.py	/^def clean_dupword(text):$/;"	f
clean_emoji	projects/chat4xianliao/chat/task_es.py	/^def clean_emoji(text):$/;"	f
clean_question	projects/chat4xianliao/chat/task_es.py	/^def clean_question(text):$/;"	f
codecs	projects/chat4xianliao/chat/task_es.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/chat/task_es.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/chat/task_es.py	/^import datetime$/;"	i
es_api	projects/chat4xianliao/chat/task_es.py	/^from es import es_api$/;"	i
filter_qa_by_label	projects/chat4xianliao/chat/task_es.py	/^    def filter_qa_by_label(self, cat, q, a, filter_option=0):$/;"	m	class:ZhidaoQa
gcounter	projects/chat4xianliao/chat/task_es.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/chat4xianliao/chat/task_es.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/chat4xianliao/chat/task_es.py	/^def getTheFile(filename):$/;"	f
glob	projects/chat4xianliao/chat/task_es.py	/^import glob$/;"	i
index_chat	projects/chat4xianliao/chat/task_es.py	/^    def index_chat(self, dataset_index = "chat8cmu6w", option="question"):$/;"	m	class:ZhidaoQa
index_edit	projects/chat4xianliao/chat/task_es.py	/^    def index_edit(self, option="question"):$/;"	m	class:ZhidaoQa
index_edit_xianer7w_rewrite	projects/chat4xianliao/chat/task_es.py	/^    def index_edit_xianer7w_rewrite(self):$/;"	m	class:ZhidaoQa
index_qa_prod	projects/chat4xianliao/chat/task_es.py	/^    def index_qa_prod(self, dataset_index):$/;"	m	class:ZhidaoQa
index_qa_simple	projects/chat4xianliao/chat/task_es.py	/^    def index_qa_simple(self, dataset_index):$/;"	m	class:ZhidaoQa
index_xianer12w_test	projects/chat4xianliao/chat/task_es.py	/^    def index_xianer12w_test(self):$/;"	m	class:ZhidaoQa
init_from_json	projects/chat4xianliao/chat/task_es.py	/^    def init_from_json(self):$/;"	m	class:ZhidaoQa
init_xianer7w_rewrite	projects/chat4xianliao/chat/task_es.py	/^    def init_xianer7w_rewrite(self):$/;"	m	class:ZhidaoQa
init_zhidao_qa	projects/chat4xianliao/chat/task_es.py	/^    def init_zhidao_qa(self):$/;"	m	class:ZhidaoQa
json	projects/chat4xianliao/chat/task_es.py	/^import json$/;"	i
libdata	projects/chat4xianliao/chat/task_es.py	/^from hzlib import libdata$/;"	i
libfile	projects/chat4xianliao/chat/task_es.py	/^from hzlib import libfile$/;"	i
main	projects/chat4xianliao/chat/task_es.py	/^def main():$/;"	f
merge_chat	projects/chat4xianliao/chat/task_es.py	/^    def merge_chat(self, option="question"):$/;"	m	class:ZhidaoQa
os	projects/chat4xianliao/chat/task_es.py	/^import os$/;"	i
random	projects/chat4xianliao/chat/task_es.py	/^import random$/;"	i
re	projects/chat4xianliao/chat/task_es.py	/^import re$/;"	i
sys	projects/chat4xianliao/chat/task_es.py	/^import sys$/;"	i
test	projects/chat4xianliao/chat/task_es.py	/^    def test(self, dataset_index="chat8xianer12w", option="query"):$/;"	m	class:ZhidaoQa
time	projects/chat4xianliao/chat/task_es.py	/^import time$/;"	i
upload	projects/chat4xianliao/chat/task_es.py	/^    def upload(self, dataset_index, item=None):$/;"	m	class:ZhidaoQa
urllib	projects/chat4xianliao/chat/task_es.py	/^import urllib$/;"	i
KIDS_2W_FILENAME	projects/chat4xianliao/chat/task_run.py	/^KIDS_2W_FILENAME = "raw\/kidsfaq2w.json"$/;"	v
KIDS_2W_QUERY_FILENAME	projects/chat4xianliao/chat/task_run.py	/^KIDS_2W_QUERY_FILENAME = "input\/kidsfaq2w.txt"$/;"	v
KIDS_2W_SAMPLE_RESULT_ANSWER	projects/chat4xianliao/chat/task_run.py	/^KIDS_2W_SAMPLE_RESULT_ANSWER = "output\/kids_faq_result_answer.xls"$/;"	v
KIDS_2W_SAMPLE_RESULT_QUESTION	projects/chat4xianliao/chat/task_run.py	/^KIDS_2W_SAMPLE_RESULT_QUESTION = "output\/kids_faq_result_question.xls"$/;"	v
LONGQUAN_18W_FILENAME	projects/chat4xianliao/chat/task_run.py	/^LONGQUAN_18W_FILENAME = getLocalFile("raw\/xianer_all_question.xlsx")$/;"	v
LONGQUAN_18W_FILENAME_QUESTION	projects/chat4xianliao/chat/task_run.py	/^LONGQUAN_18W_FILENAME_QUESTION = getLocalFile("input\/xianer_all_question.txt")$/;"	v
ZhidaoFetch	projects/chat4xianliao/chat/task_run.py	/^from hzlib.api_zhidao import ZhidaoFetch$/;"	i
clean_cmu	projects/chat4xianliao/chat/task_run.py	/^def clean_cmu():$/;"	f
clean_longquan_question	projects/chat4xianliao/chat/task_run.py	/^def clean_longquan_question(question):$/;"	f
codecs	projects/chat4xianliao/chat/task_run.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/chat/task_run.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/chat/task_run.py	/^import datetime$/;"	i
downloader	projects/chat4xianliao/chat/task_run.py	/^import downloader$/;"	i
es	projects/chat4xianliao/chat/task_run.py	/^import es$/;"	i
fetch_detail	projects/chat4xianliao/chat/task_run.py	/^def fetch_detail(worker_id=None, worker_num=None, limit=None, config_index="prod", filename_input=None, fetch_option="top_n", fetch_limit=100):$/;"	f
getLocalFile	projects/chat4xianliao/chat/task_run.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/chat4xianliao/chat/task_run.py	/^def getTheFile(filename):$/;"	f
glob	projects/chat4xianliao/chat/task_run.py	/^import glob$/;"	i
json	projects/chat4xianliao/chat/task_run.py	/^import json$/;"	i
libdata	projects/chat4xianliao/chat/task_run.py	/^from hzlib import libdata$/;"	i
libfile	projects/chat4xianliao/chat/task_run.py	/^from hzlib import libfile$/;"	i
main	projects/chat4xianliao/chat/task_run.py	/^def main():$/;"	f
os	projects/chat4xianliao/chat/task_run.py	/^import os$/;"	i
random	projects/chat4xianliao/chat/task_run.py	/^import random$/;"	i
re	projects/chat4xianliao/chat/task_run.py	/^import re$/;"	i
read_kidsfaq2w	projects/chat4xianliao/chat/task_run.py	/^def read_kidsfaq2w(limit=10):$/;"	f
read_longquan18w	projects/chat4xianliao/chat/task_run.py	/^def read_longquan18w():$/;"	f
run_chat_realtime	projects/chat4xianliao/chat/task_run.py	/^def run_chat_realtime(query_filter, query_parser, limit):$/;"	f
slack_msg	projects/chat4xianliao/chat/task_run.py	/^from hzlib.libdata import slack_msg$/;"	i
sys	projects/chat4xianliao/chat/task_run.py	/^import sys$/;"	i
time	projects/chat4xianliao/chat/task_run.py	/^import time$/;"	i
urllib	projects/chat4xianliao/chat/task_run.py	/^import urllib$/;"	i
Cache	projects/chat4xianliao/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/chat4xianliao/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/chat4xianliao/downloader/cache.py	/^import base64$/;"	i
division	projects/chat4xianliao/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/chat4xianliao/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/chat4xianliao/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/chat4xianliao/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/chat4xianliao/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/chat4xianliao/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/chat4xianliao/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/chat4xianliao/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/chat4xianliao/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/chat4xianliao/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/chat4xianliao/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/chat4xianliao/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/chat4xianliao/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/chat4xianliao/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/chat4xianliao/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/chat4xianliao/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/chat4xianliao/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/chat4xianliao/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/chat4xianliao/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/chat4xianliao/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/chat4xianliao/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/chat4xianliao/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/chat4xianliao/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/chat4xianliao/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/chat4xianliao/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/chat4xianliao/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/chat4xianliao/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/chat4xianliao/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/chat4xianliao/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/chat4xianliao/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/chat4xianliao/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/chat4xianliao/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/chat4xianliao/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/chat4xianliao/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/chat4xianliao/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/chat4xianliao/downloader/downloader.py	/^import os$/;"	i
print_function	projects/chat4xianliao/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/chat4xianliao/downloader/downloader.py	/^import re$/;"	i
request_download	projects/chat4xianliao/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/chat4xianliao/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/chat4xianliao/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/chat4xianliao/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/chat4xianliao/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/chat4xianliao/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/chat4xianliao/downloader/downloader.py	/^import sys$/;"	i
time	projects/chat4xianliao/downloader/downloader.py	/^import time$/;"	i
update_header	projects/chat4xianliao/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/chat4xianliao/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/chat4xianliao/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/chat4xianliao/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/chat4xianliao/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/chat4xianliao/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/chat4xianliao/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/chat4xianliao/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/chat4xianliao/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/chat4xianliao/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/chat4xianliao/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/chat4xianliao/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/chat4xianliao/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/chat4xianliao/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/chat4xianliao/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/chat4xianliao/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/chat4xianliao/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/chat4xianliao/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/chat4xianliao/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/chat4xianliao/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/chat4xianliao/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/chat4xianliao/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/chat4xianliao/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/downloader/test_download.py	/^import datetime$/;"	i
json	projects/chat4xianliao/downloader/test_download.py	/^import json$/;"	i
main	projects/chat4xianliao/downloader/test_download.py	/^def main():$/;"	f
os	projects/chat4xianliao/downloader/test_download.py	/^import os$/;"	i
re	projects/chat4xianliao/downloader/test_download.py	/^import re$/;"	i
requests	projects/chat4xianliao/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/chat4xianliao/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/chat4xianliao/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/chat4xianliao/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/chat4xianliao/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/chat4xianliao/downloader/test_download.py	/^import time$/;"	i
urllib	projects/chat4xianliao/downloader/test_download.py	/^import urllib$/;"	i
INDEX_OPTION_DELETE	projects/chat4xianliao/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	projects/chat4xianliao/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	projects/chat4xianliao/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	projects/chat4xianliao/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	projects/chat4xianliao/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	projects/chat4xianliao/es/es_api.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/es/es_api.py	/^import collections$/;"	i
es_api_post	projects/chat4xianliao/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	projects/chat4xianliao/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	projects/chat4xianliao/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	projects/chat4xianliao/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	projects/chat4xianliao/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	projects/chat4xianliao/es/es_api.py	/^import hashlib$/;"	i
json	projects/chat4xianliao/es/es_api.py	/^import json$/;"	i
os	projects/chat4xianliao/es/es_api.py	/^import os$/;"	i
os	projects/chat4xianliao/es/es_api.py	/^import os.path$/;"	i
path	projects/chat4xianliao/es/es_api.py	/^import os.path$/;"	i
requests	projects/chat4xianliao/es/es_api.py	/^import requests$/;"	i
run_batch	projects/chat4xianliao/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	projects/chat4xianliao/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	projects/chat4xianliao/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	projects/chat4xianliao/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	projects/chat4xianliao/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	projects/chat4xianliao/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	projects/chat4xianliao/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	projects/chat4xianliao/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	projects/chat4xianliao/es/es_api.py	/^import sys$/;"	i
test	projects/chat4xianliao/es/es_api.py	/^def test():$/;"	f
test_echo	projects/chat4xianliao/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	projects/chat4xianliao/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	projects/chat4xianliao/es/es_api.py	/^import urllib$/;"	i
InstanceMgr	projects/chat4xianliao/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/chat4xianliao/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/chat4xianliao/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/chat4xianliao/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/chat4xianliao/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/chat4xianliao/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/chat4xianliao/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/chat4xianliao/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/chat4xianliao/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/chat4xianliao/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/chat4xianliao/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/chat4xianliao/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/chat4xianliao/hzlib/api_aws.py	/^import json$/;"	i
list	projects/chat4xianliao/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/chat4xianliao/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/chat4xianliao/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/chat4xianliao/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/chat4xianliao/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/chat4xianliao/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/chat4xianliao/hzlib/api_aws.py	/^import re$/;"	i
run	projects/chat4xianliao/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/chat4xianliao/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/chat4xianliao/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/chat4xianliao/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/chat4xianliao/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/chat4xianliao/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/chat4xianliao/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/chat4xianliao/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/chat4xianliao/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/chat4xianliao/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/chat4xianliao/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/chat4xianliao/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/chat4xianliao/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/chat4xianliao/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/chat4xianliao/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/chat4xianliao/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/chat4xianliao/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/chat4xianliao/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/chat4xianliao/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/chat4xianliao/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/chat4xianliao/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/chat4xianliao/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/chat4xianliao/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/chat4xianliao/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/chat4xianliao/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/chat4xianliao/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/chat4xianliao/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/chat4xianliao/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/chat4xianliao/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/chat4xianliao/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/chat4xianliao/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/chat4xianliao/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/chat4xianliao/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/chat4xianliao/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/chat4xianliao/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/chat4xianliao/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/chat4xianliao/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/chat4xianliao/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/chat4xianliao/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/chat4xianliao/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/chat4xianliao/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/chat4xianliao/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/chat4xianliao/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/chat4xianliao/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/chat4xianliao/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/chat4xianliao/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/chat4xianliao/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/chat4xianliao/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/chat4xianliao/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/chat4xianliao/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/chat4xianliao/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/chat4xianliao/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/chat4xianliao/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/chat4xianliao/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/chat4xianliao/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/chat4xianliao/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/chat4xianliao/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/chat4xianliao/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/chat4xianliao/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/chat4xianliao/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/chat4xianliao/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/chat4xianliao/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/chat4xianliao/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/chat4xianliao/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/chat4xianliao/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/chat4xianliao/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/chat4xianliao/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/chat4xianliao/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/chat4xianliao/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/chat4xianliao/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/chat4xianliao/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/chat4xianliao/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/chat4xianliao/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/chat4xianliao/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/chat4xianliao/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/chat4xianliao/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/chat4xianliao/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/chat4xianliao/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/chat4xianliao/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/chat4xianliao/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/chat4xianliao/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/chat4xianliao/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/chat4xianliao/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/chat4xianliao/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/chat4xianliao/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/chat4xianliao/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/chat4xianliao/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/chat4xianliao/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/chat4xianliao/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/chat4xianliao/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/chat4xianliao/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/chat4xianliao/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/chat4xianliao/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/chat4xianliao/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/chat4xianliao/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/chat4xianliao/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/chat4xianliao/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/chat4xianliao/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/chat4xianliao/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/chat4xianliao/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/chat4xianliao/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/chat4xianliao/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/chat4xianliao/hzlib/libdata.py	/^import random$/;"	i
re	projects/chat4xianliao/hzlib/libdata.py	/^import re$/;"	i
requests	projects/chat4xianliao/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/chat4xianliao/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/chat4xianliao/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/chat4xianliao/hzlib/libdata.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/chat4xianliao/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/chat4xianliao/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/chat4xianliao/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/chat4xianliao/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/chat4xianliao/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/chat4xianliao/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/chat4xianliao/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/chat4xianliao/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/chat4xianliao/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/chat4xianliao/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/chat4xianliao/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/chat4xianliao/hzlib/libfile.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/chat4xianliao/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/chat4xianliao/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/chat4xianliao/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/chat4xianliao/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/chat4xianliao/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/chat4xianliao/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/chat4xianliao/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/chat4xianliao/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/chat4xianliao/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/chat4xianliao/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/chat4xianliao/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/chat4xianliao/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/chat4xianliao/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/chat4xianliao/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/chat4xianliao/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/chat4xianliao/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/chat4xianliao/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/chat4xianliao/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/chat4xianliao/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/chat4xianliao/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/chat4xianliao/hzlib/libnlp.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/chat4xianliao/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/chat4xianliao/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/chat4xianliao/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/chat4xianliao/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/chat4xianliao/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/chat4xianliao/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/chat4xianliao/hzlib/libregex.py	/^def main():$/;"	f
os	projects/chat4xianliao/hzlib/libregex.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/libregex.py	/^import re$/;"	i
sys	projects/chat4xianliao/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/chat4xianliao/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/chat4xianliao/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/chat4xianliao/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/chat4xianliao/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/chat4xianliao/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/chat4xianliao/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/chat4xianliao/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/chat4xianliao/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/chat4xianliao/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/chat4xianliao/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/chat4xianliao/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/chat4xianliao/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/chat4xianliao/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/chat4xianliao/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/chat4xianliao/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/chat4xianliao/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/chat4xianliao/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/chat4xianliao/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/chat4xianliao/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/chat4xianliao/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/chat4xianliao/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/chat4xianliao/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/chat4xianliao/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/chat4xianliao/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/chat4xianliao/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/chat4xianliao/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/chat4xianliao/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/chat4xianliao/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/chat4xianliao/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/chat4xianliao/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/chat4xianliao/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/chat4xianliao/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/chat4xianliao/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/chat4xianliao/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/chat4xianliao/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/chat4xianliao/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/chat4xianliao/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/chat4xianliao/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/chat4xianliao/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/chat4xianliao/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/chat4xianliao/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/chat4xianliao/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/chat4xianliao/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/chat4xianliao/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/chat4xianliao/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/chat4xianliao/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/chat4xianliao/hzlib/tests/test_api.py	/^def test_search():$/;"	f
Downloader	projects/chat4xianliao/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	projects/chat4xianliao/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/chat4xianliao/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	projects/chat4xianliao/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/chat4xianliao/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/chat4xianliao/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/chat4xianliao/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/chat4xianliao/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/chat4xianliao/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	projects/chat4xianliao/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/chat4xianliao/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	projects/chat4xianliao/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	projects/chat4xianliao/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/chat4xianliao/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/chat4xianliao/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	projects/chat4xianliao/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	projects/chat4xianliao/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	projects/chat4xianliao/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/chat4xianliao/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	projects/chat4xianliao/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/chat4xianliao/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	projects/chat4xianliao/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/chat4xianliao/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/chat4xianliao/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	projects/chat4xianliao/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	projects/chat4xianliao/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	projects/chat4xianliao/parsers/qichacha2.py	/^import re$/;"	i
traceback	projects/chat4xianliao/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	projects/chat4xianliao/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	projects/chat4xianliao/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	projects/chat4xianliao/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/chat4xianliao/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	projects/chat4xianliao/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	projects/chat4xianliao/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	projects/chat4xianliao/parsers/qiparser2.py	/^import re$/;"	i
string	projects/chat4xianliao/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	projects/chat4xianliao/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	projects/chat4xianliao/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	projects/chat4xianliao/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	projects/chat4xianliao/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	projects/chat4xianliao/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	projects/chat4xianliao/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	projects/chat4xianliao/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	projects/chat4xianliao/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	projects/chat4xianliao/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	projects/chat4xianliao/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	projects/chat4xianliao/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	projects/chat4xianliao/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	projects/chat4xianliao/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
ChemnetCleansing	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^class ChemnetCleansing(HpriceCleansing):$/;"	c
DB	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^from hcrawler_models import Hmaterial, Hentity$/;"	i
Hmaterial	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^from hcrawler_models import Hmaterial, Hentity$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
get_nid	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^    def get_nid(self, name):$/;"	m	class:ChemnetCleansing
json	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^import json$/;"	i
parse_single_item	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:ChemnetCleansing
re	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^import re$/;"	i
s	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^    s = ChemnetCleansing('chem-20160728')$/;"	v	class:ChemnetCleansing
sys	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^import sys$/;"	i
url2domain	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^def url2domain(url):$/;"	f
urlparse	projects/cleansing_hcrawler/chemnet_mongo_cleansing.py	/^    from urlparse import urlparse$/;"	i
CngrainCleansing	projects/cleansing_hcrawler/cngrain_cleansing.py	/^class CngrainCleansing(HpriceCleansing):$/;"	c
HpriceCleansing	projects/cleansing_hcrawler/cngrain_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
parse_single_item	projects/cleansing_hcrawler/cngrain_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:CngrainCleansing
s	projects/cleansing_hcrawler/cngrain_cleansing.py	/^    s = CngrainCleansing('cngrain-20160817')$/;"	v	class:CngrainCleansing
sendto_es	projects/cleansing_hcrawler/cngrain_cleansing.py	/^from to_es import sendto_es$/;"	i
sys	projects/cleansing_hcrawler/cngrain_cleansing.py	/^import sys$/;"	i
CngrainCleansing	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^class CngrainCleansing(HpriceCleansing):$/;"	c
DB	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
Hprice	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
get_nid	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^    def get_nid(self, name):$/;"	m	class:CngrainCleansing
parse_single_item	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:CngrainCleansing
s	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^    s = CngrainCleansing('cngrain-20160817')$/;"	v	class:CngrainCleansing
sys	projects/cleansing_hcrawler/cngrain_mongo_cleansing.py	/^import sys$/;"	i
INDEX_OPTION_DELETE	projects/cleansing_hcrawler/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	projects/cleansing_hcrawler/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	projects/cleansing_hcrawler/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	projects/cleansing_hcrawler/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	projects/cleansing_hcrawler/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	projects/cleansing_hcrawler/es/es_api.py	/^import codecs$/;"	i
collections	projects/cleansing_hcrawler/es/es_api.py	/^import collections$/;"	i
es_api_post	projects/cleansing_hcrawler/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	projects/cleansing_hcrawler/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	projects/cleansing_hcrawler/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	projects/cleansing_hcrawler/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	projects/cleansing_hcrawler/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	projects/cleansing_hcrawler/es/es_api.py	/^import hashlib$/;"	i
json	projects/cleansing_hcrawler/es/es_api.py	/^import json$/;"	i
os	projects/cleansing_hcrawler/es/es_api.py	/^import os$/;"	i
os	projects/cleansing_hcrawler/es/es_api.py	/^import os.path$/;"	i
path	projects/cleansing_hcrawler/es/es_api.py	/^import os.path$/;"	i
requests	projects/cleansing_hcrawler/es/es_api.py	/^import requests$/;"	i
run_batch	projects/cleansing_hcrawler/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	projects/cleansing_hcrawler/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	projects/cleansing_hcrawler/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	projects/cleansing_hcrawler/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	projects/cleansing_hcrawler/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	projects/cleansing_hcrawler/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	projects/cleansing_hcrawler/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	projects/cleansing_hcrawler/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	projects/cleansing_hcrawler/es/es_api.py	/^import sys$/;"	i
test	projects/cleansing_hcrawler/es/es_api.py	/^def test():$/;"	f
test_echo	projects/cleansing_hcrawler/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	projects/cleansing_hcrawler/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	projects/cleansing_hcrawler/es/es_api.py	/^import urllib$/;"	i
DB	projects/cleansing_hcrawler/get_static_file.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/get_static_file.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
Hprice	projects/cleansing_hcrawler/get_static_file.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
allocate_tag_by_score	projects/cleansing_hcrawler/get_static_file.py	/^def allocate_tag_by_score(tags_with_scores):$/;"	f
bad_list	projects/cleansing_hcrawler/get_static_file.py	/^bad_list = []$/;"	v
candidate_list	projects/cleansing_hcrawler/get_static_file.py	/^candidate_list = []$/;"	v
counter	projects/cleansing_hcrawler/get_static_file.py	/^counter = 0$/;"	v
csv	projects/cleansing_hcrawler/get_static_file.py	/^import csv$/;"	i
deal_with	projects/cleansing_hcrawler/get_static_file.py	/^def deal_with(name):$/;"	f
json	projects/cleansing_hcrawler/get_static_file.py	/^import json$/;"	i
judge_by_desc	projects/cleansing_hcrawler/get_static_file.py	/^def judge_by_desc(desc):$/;"	f
judge_by_sameas	projects/cleansing_hcrawler/get_static_file.py	/^def judge_by_sameas(sameas):$/;"	f
name	projects/cleansing_hcrawler/get_static_file.py	/^            name = line.strip() #mapper.get(raw, raw)$/;"	v
ok_list	projects/cleansing_hcrawler/get_static_file.py	/^ok_list = []$/;"	v
only_one_list	projects/cleansing_hcrawler/get_static_file.py	/^only_one_list = []$/;"	v
sys	projects/cleansing_hcrawler/get_static_file.py	/^import sys$/;"	i
write_to_file	projects/cleansing_hcrawler/get_static_file.py	/^def write_to_file(filename, content_list):$/;"	f
hprice	projects/cleansing_hcrawler/hcrawler.sql	/^create table hprice ($/;"	t
hprice.confidence	projects/cleansing_hcrawler/hcrawler.sql	/^  confidence varchar(8)$/;"	F
hprice.createdTime	projects/cleansing_hcrawler/hcrawler.sql	/^  createdTime timestamp default now() not null,$/;"	F
hprice.description	projects/cleansing_hcrawler/hcrawler.sql	/^  description varchar(1024),$/;"	F
hprice.mainEntityOfPage	projects/cleansing_hcrawler/hcrawler.sql	/^  mainEntityOfPage varchar(32) not null,$/;"	F
hprice.maxPrice	projects/cleansing_hcrawler/hcrawler.sql	/^  maxPrice varchar(32),$/;"	F
hprice.minPrice	projects/cleansing_hcrawler/hcrawler.sql	/^  minPrice varchar(32),$/;"	F
hprice.name	projects/cleansing_hcrawler/hcrawler.sql	/^  name varchar(128),$/;"	F
hprice.price	projects/cleansing_hcrawler/hcrawler.sql	/^  price varchar(32),$/;"	F
hprice.priceCurrency	projects/cleansing_hcrawler/hcrawler.sql	/^  priceCurrency varchar(8),$/;"	F
hprice.priceType	projects/cleansing_hcrawler/hcrawler.sql	/^  priceType varchar(16),$/;"	F
hprice.productGrade	projects/cleansing_hcrawler/hcrawler.sql	/^  productGrade varchar(32),$/;"	F
hprice.productPlaceOfOrigin	projects/cleansing_hcrawler/hcrawler.sql	/^  productPlaceOfOrigin varchar(32),$/;"	F
hprice.productSpecification	projects/cleansing_hcrawler/hcrawler.sql	/^  productSpecification varchar(32),$/;"	F
hprice.productionYear	projects/cleansing_hcrawler/hcrawler.sql	/^  productionYear varchar(16),$/;"	F
hprice.seller	projects/cleansing_hcrawler/hcrawler.sql	/^  seller varchar(512),$/;"	F
hprice.sellerMarket	projects/cleansing_hcrawler/hcrawler.sql	/^  sellerMarket varchar(32),$/;"	F
hprice.source	projects/cleansing_hcrawler/hcrawler.sql	/^  source varchar(2048) not null,$/;"	F
hprice.unitText	projects/cleansing_hcrawler/hcrawler.sql	/^  unitText varchar(16),$/;"	F
hprice.validDate	projects/cleansing_hcrawler/hcrawler.sql	/^  validDate varchar(32),$/;"	F
Abnormals	projects/cleansing_hcrawler/hcrawler_models.py	/^class Abnormals(EmbeddedDocument):$/;"	c
Branches	projects/cleansing_hcrawler/hcrawler_models.py	/^class Branches(EmbeddedDocument):$/;"	c
Changes	projects/cleansing_hcrawler/hcrawler_models.py	/^class Changes(EmbeddedDocument): $/;"	c
CompanyInfo	projects/cleansing_hcrawler/hcrawler_models.py	/^class CompanyInfo(EmbeddedDocument):$/;"	c
Confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^class Confidence(Document):$/;"	c
Executives	projects/cleansing_hcrawler/hcrawler_models.py	/^class Executives(EmbeddedDocument):$/;"	c
GmpInfo	projects/cleansing_hcrawler/hcrawler_models.py	/^class GmpInfo(EmbeddedDocument):$/;"	c
Hentity	projects/cleansing_hcrawler/hcrawler_models.py	/^class Hentity(Document):$/;"	c
Hmaterial	projects/cleansing_hcrawler/hcrawler_models.py	/^class Hmaterial(Document):$/;"	c
Hprice	projects/cleansing_hcrawler/hcrawler_models.py	/^class Hprice(Document):$/;"	c
MedicinesInfo	projects/cleansing_hcrawler/hcrawler_models.py	/^class MedicinesInfo(EmbeddedDocument):$/;"	c
News	projects/cleansing_hcrawler/hcrawler_models.py	/^class News(Document):$/;"	c
ProductionCapacity	projects/cleansing_hcrawler/hcrawler_models.py	/^class ProductionCapacity(Document):$/;"	c
Purchase	projects/cleansing_hcrawler/hcrawler_models.py	/^class Purchase(Document):$/;"	c
Shareholders	projects/cleansing_hcrawler/hcrawler_models.py	/^class Shareholders(EmbeddedDocument):$/;"	c
Supplier	projects/cleansing_hcrawler/hcrawler_models.py	/^class Supplier(Document):$/;"	c
abnormals	projects/cleansing_hcrawler/hcrawler_models.py	/^    abnormals = ListField(EmbeddedDocumentField(Abnormals))$/;"	v	class:Supplier
actual_money	projects/cleansing_hcrawler/hcrawler_models.py	/^    actual_money = StringField()$/;"	v	class:Shareholders
actual_time	projects/cleansing_hcrawler/hcrawler_models.py	/^    actual_time = StringField()$/;"	v	class:Shareholders
address	projects/cleansing_hcrawler/hcrawler_models.py	/^    address = StringField()$/;"	v	class:Supplier
after_change	projects/cleansing_hcrawler/hcrawler_models.py	/^    after_change = StringField()$/;"	v	class:Changes
alias	projects/cleansing_hcrawler/hcrawler_models.py	/^    alias = ListField(StringField()) # 别名$/;"	v	class:Hentity
alias_editor	projects/cleansing_hcrawler/hcrawler_models.py	/^    alias_editor = ListField(StringField()) # 人工编辑别名$/;"	v	class:Hentity
approval_date	projects/cleansing_hcrawler/hcrawler_models.py	/^    approval_date = StringField()$/;"	v	class:Supplier
before_change	projects/cleansing_hcrawler/hcrawler_models.py	/^    before_change = StringField()$/;"	v	class:Changes
begin	projects/cleansing_hcrawler/hcrawler_models.py	/^    begin = StringField()$/;"	v	class:Supplier
begin_date	projects/cleansing_hcrawler/hcrawler_models.py	/^    begin_date = DateTimeField()$/;"	v	class:GmpInfo
branches	projects/cleansing_hcrawler/hcrawler_models.py	/^    branches = ListField(EmbeddedDocumentField(Branches))$/;"	v	class:Supplier
business_scope	projects/cleansing_hcrawler/hcrawler_models.py	/^    business_scope = StringField()$/;"	v	class:Supplier
business_type	projects/cleansing_hcrawler/hcrawler_models.py	/^    business_type = StringField()$/;"	v	class:Supplier
category	projects/cleansing_hcrawler/hcrawler_models.py	/^    category = StringField() # 分类$/;"	v	class:Hmaterial
cellphone	projects/cleansing_hcrawler/hcrawler_models.py	/^    cellphone = StringField()$/;"	v	class:CompanyInfo
certification_number	projects/cleansing_hcrawler/hcrawler_models.py	/^    certification_number = StringField()$/;"	v	class:GmpInfo
certification_version	projects/cleansing_hcrawler/hcrawler_models.py	/^    certification_version = StringField()$/;"	v	class:GmpInfo
change_time	projects/cleansing_hcrawler/hcrawler_models.py	/^    change_time = StringField()$/;"	v	class:Changes
changes	projects/cleansing_hcrawler/hcrawler_models.py	/^    changes = ListField(EmbeddedDocumentField(Changes))$/;"	v	class:Supplier
company_info	projects/cleansing_hcrawler/hcrawler_models.py	/^    company_info = EmbeddedDocumentField(CompanyInfo)$/;"	v	class:Supplier
company_name	projects/cleansing_hcrawler/hcrawler_models.py	/^    company_name = StringField()$/;"	v	class:Supplier
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Confidence
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Hmaterial
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Hprice
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:News
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Purchase
confidence	projects/cleansing_hcrawler/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Supplier
contects	projects/cleansing_hcrawler/hcrawler_models.py	/^    contects = StringField()$/;"	v	class:CompanyInfo
content	projects/cleansing_hcrawler/hcrawler_models.py	/^    content = StringField() # 内容$/;"	v	class:News
cooperationIntention	projects/cleansing_hcrawler/hcrawler_models.py	/^    cooperationIntention = StringField() # 合作意向$/;"	v	class:CompanyInfo
createdTime	projects/cleansing_hcrawler/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Hmaterial
createdTime	projects/cleansing_hcrawler/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Hprice
createdTime	projects/cleansing_hcrawler/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:News
createdTime	projects/cleansing_hcrawler/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Purchase
createdTime	projects/cleansing_hcrawler/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Supplier
date	projects/cleansing_hcrawler/hcrawler_models.py	/^    date = StringField()$/;"	v	class:Abnormals
datetime	projects/cleansing_hcrawler/hcrawler_models.py	/^from datetime import datetime$/;"	i
description	projects/cleansing_hcrawler/hcrawler_models.py	/^    description = StringField() # 描述$/;"	v	class:Hmaterial
description	projects/cleansing_hcrawler/hcrawler_models.py	/^    description = StringField()$/;"	v	class:Hentity
description	projects/cleansing_hcrawler/hcrawler_models.py	/^    description = StringField()$/;"	v	class:Hprice
division	projects/cleansing_hcrawler/hcrawler_models.py	/^from __future__ import print_function, division$/;"	i
downstream_material	projects/cleansing_hcrawler/hcrawler_models.py	/^    downstream_material = ListField(StringField()) # 下游产品$/;"	v	class:Hmaterial
drug_form	projects/cleansing_hcrawler/hcrawler_models.py	/^    drug_form = StringField() # 剂型$/;"	v	class:Hmaterial
email	projects/cleansing_hcrawler/hcrawler_models.py	/^    email = StringField()$/;"	v	class:CompanyInfo
end	projects/cleansing_hcrawler/hcrawler_models.py	/^    end = StringField()$/;"	v	class:Supplier
end_date	projects/cleansing_hcrawler/hcrawler_models.py	/^    end_date = DateTimeField()$/;"	v	class:GmpInfo
end_date	projects/cleansing_hcrawler/hcrawler_models.py	/^    end_date = StringField()$/;"	v	class:Abnormals
end_reason	projects/cleansing_hcrawler/hcrawler_models.py	/^    end_reason = StringField()$/;"	v	class:Abnormals
establish_date	projects/cleansing_hcrawler/hcrawler_models.py	/^    establish_date = StringField()$/;"	v	class:Supplier
executives	projects/cleansing_hcrawler/hcrawler_models.py	/^    executives = ListField(EmbeddedDocumentField(Executives))$/;"	v	class:Supplier
fax	projects/cleansing_hcrawler/hcrawler_models.py	/^    fax = StringField()$/;"	v	class:CompanyInfo
gmp_info	projects/cleansing_hcrawler/hcrawler_models.py	/^    gmp_info = ListField(EmbeddedDocumentField(GmpInfo))$/;"	v	class:Supplier
legal_person	projects/cleansing_hcrawler/hcrawler_models.py	/^    legal_person = StringField()$/;"	v	class:Supplier
license_data	projects/cleansing_hcrawler/hcrawler_models.py	/^    license_data = StringField()$/;"	v	class:MedicinesInfo
license_number	projects/cleansing_hcrawler/hcrawler_models.py	/^    license_number = StringField()$/;"	v	class:MedicinesInfo
link	projects/cleansing_hcrawler/hcrawler_models.py	/^    link = StringField()$/;"	v	class:Branches
mainEntityOfPage	projects/cleansing_hcrawler/hcrawler_models.py	/^    mainEntityOfPage = StringField() # 实体$/;"	v	class:Hmaterial
mainEntityOfPage	projects/cleansing_hcrawler/hcrawler_models.py	/^    mainEntityOfPage = StringField() # 实体$/;"	v	class:Hprice
mainEntityOfPage	projects/cleansing_hcrawler/hcrawler_models.py	/^    mainEntityOfPage = StringField()$/;"	v	class:Purchase
maxPrice	projects/cleansing_hcrawler/hcrawler_models.py	/^    maxPrice = StringField() # 价格最大值$/;"	v	class:Hprice
medicines_info	projects/cleansing_hcrawler/hcrawler_models.py	/^    medicines_info = ListField(EmbeddedDocumentField(MedicinesInfo))$/;"	v	class:Supplier
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:Hentity
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:Hmaterial
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:Hprice
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:News
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:Purchase
meta	projects/cleansing_hcrawler/hcrawler_models.py	/^    meta = {$/;"	v	class:Supplier
minPrice	projects/cleansing_hcrawler/hcrawler_models.py	/^    minPrice = StringField() # 价格最小值$/;"	v	class:Hprice
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField() # 名字，爬到的名字$/;"	v	class:Hmaterial
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Branches
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Executives
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Hprice
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Purchase
name	projects/cleansing_hcrawler/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Shareholders
nid	projects/cleansing_hcrawler/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hentity
nid	projects/cleansing_hcrawler/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hmaterial
nid	projects/cleansing_hcrawler/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hprice
ns	projects/cleansing_hcrawler/hcrawler_models.py	/^    ns = StringField() # namespace$/;"	v	class:Hentity
orderDate	projects/cleansing_hcrawler/hcrawler_models.py	/^    orderDate = StringField()$/;"	v	class:Purchase
orderNumber	projects/cleansing_hcrawler/hcrawler_models.py	/^    orderNumber = StringField() # 总量$/;"	v	class:Purchase
organization_code	projects/cleansing_hcrawler/hcrawler_models.py	/^    organization_code = StringField()$/;"	v	class:Supplier
organs	projects/cleansing_hcrawler/hcrawler_models.py	/^    organs = StringField()$/;"	v	class:Abnormals
paymentMethod	projects/cleansing_hcrawler/hcrawler_models.py	/^    paymentMethod = StringField() # 付款方式$/;"	v	class:CompanyInfo
paymentMethod	projects/cleansing_hcrawler/hcrawler_models.py	/^    paymentMethod = StringField() # 付款方式$/;"	v	class:Purchase
plant_area	projects/cleansing_hcrawler/hcrawler_models.py	/^    plant_area = StringField() # 种植面积$/;"	v	class:ProductionCapacity
position	projects/cleansing_hcrawler/hcrawler_models.py	/^    position = StringField()$/;"	v	class:Executives
price	projects/cleansing_hcrawler/hcrawler_models.py	/^    price = StringField()$/;"	v	class:Hprice
price	projects/cleansing_hcrawler/hcrawler_models.py	/^    price = StringField()$/;"	v	class:Purchase
priceCurrency	projects/cleansing_hcrawler/hcrawler_models.py	/^    priceCurrency = StringField() # 报价币种$/;"	v	class:Hprice
priceCurrency	projects/cleansing_hcrawler/hcrawler_models.py	/^    priceCurrency = StringField() # 报价币种$/;"	v	class:Purchase
priceType	projects/cleansing_hcrawler/hcrawler_models.py	/^    priceType = StringField() # 价格类型，比如：车皮价$/;"	v	class:Hprice
priceType	projects/cleansing_hcrawler/hcrawler_models.py	/^    priceType = StringField() # 价格类型，比如：车皮价$/;"	v	class:Purchase
print_function	projects/cleansing_hcrawler/hcrawler_models.py	/^from __future__ import print_function, division$/;"	i
productGrade	projects/cleansing_hcrawler/hcrawler_models.py	/^    productGrade = StringField() # 商品等级$/;"	v	class:Hprice
productGrade	projects/cleansing_hcrawler/hcrawler_models.py	/^    productGrade = StringField() # 商品等级$/;"	v	class:Purchase
productPlaceOfOrigin	projects/cleansing_hcrawler/hcrawler_models.py	/^    productPlaceOfOrigin = StringField() # 商品产地$/;"	v	class:Hprice
productPlaceOfOrigin	projects/cleansing_hcrawler/hcrawler_models.py	/^    productPlaceOfOrigin = StringField() # 商品产地$/;"	v	class:ProductionCapacity
productSpecification	projects/cleansing_hcrawler/hcrawler_models.py	/^    productSpecification = StringField() # 商品说明$/;"	v	class:Hprice
productionYear	projects/cleansing_hcrawler/hcrawler_models.py	/^    productionYear = StringField() # 生产日期$/;"	v	class:Hprice
project	projects/cleansing_hcrawler/hcrawler_models.py	/^    project = StringField()$/;"	v	class:Changes
properties	projects/cleansing_hcrawler/hcrawler_models.py	/^    properties = DictField() # 属性$/;"	v	class:Hmaterial
properties	projects/cleansing_hcrawler/hcrawler_models.py	/^    properties = DictField() # 属性$/;"	v	class:Hprice
province	projects/cleansing_hcrawler/hcrawler_models.py	/^    province = StringField()$/;"	v	class:GmpInfo
pubdate	projects/cleansing_hcrawler/hcrawler_models.py	/^    pubdate = DateTimeField()$/;"	v	class:News
reason	projects/cleansing_hcrawler/hcrawler_models.py	/^    reason = StringField()$/;"	v	class:Abnormals
registered_capital	projects/cleansing_hcrawler/hcrawler_models.py	/^    registered_capital = StringField()$/;"	v	class:Supplier
registration_authority	projects/cleansing_hcrawler/hcrawler_models.py	/^    registration_authority = StringField()$/;"	v	class:Supplier
registration_id	projects/cleansing_hcrawler/hcrawler_models.py	/^    registration_id = StringField()$/;"	v	class:Supplier
role	projects/cleansing_hcrawler/hcrawler_models.py	/^    role = StringField()$/;"	v	class:Shareholders
s_label	projects/cleansing_hcrawler/hcrawler_models.py	/^    s_label = StringField() # name$/;"	v	class:Hentity
s_rank	projects/cleansing_hcrawler/hcrawler_models.py	/^    s_rank = StringField() # 搜索结果数$/;"	v	class:Hentity
sameas	projects/cleansing_hcrawler/hcrawler_models.py	/^    sameas = ListField(StringField()) # 实体链接$/;"	v	class:Hentity
scope_of_certification	projects/cleansing_hcrawler/hcrawler_models.py	/^    scope_of_certification = StringField()$/;"	v	class:GmpInfo
seller	projects/cleansing_hcrawler/hcrawler_models.py	/^    seller = StringField() # 销售商$/;"	v	class:Hprice
sellerMarket	projects/cleansing_hcrawler/hcrawler_models.py	/^    sellerMarket = StringField() # 卖场$/;"	v	class:Hprice
shareholders	projects/cleansing_hcrawler/hcrawler_models.py	/^    shareholders = ListField(EmbeddedDocumentField(Shareholders))$/;"	v	class:Supplier
shipping	projects/cleansing_hcrawler/hcrawler_models.py	/^    shipping = StringField() # 运输方式$/;"	v	class:Purchase
shippingFee	projects/cleansing_hcrawler/hcrawler_models.py	/^    shippingFee = StringField() # 运输费用$/;"	v	class:CompanyInfo
shippingFee	projects/cleansing_hcrawler/hcrawler_models.py	/^    shippingFee = StringField() # 运输费用$/;"	v	class:Purchase
site	projects/cleansing_hcrawler/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Hmaterial
site	projects/cleansing_hcrawler/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Hprice
site	projects/cleansing_hcrawler/hcrawler_models.py	/^    site = StringField()$/;"	v	class:News
site	projects/cleansing_hcrawler/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Purchase
site	projects/cleansing_hcrawler/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Supplier
source	projects/cleansing_hcrawler/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Hmaterial
source	projects/cleansing_hcrawler/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Hprice
source	projects/cleansing_hcrawler/hcrawler_models.py	/^    source = StringField()$/;"	v	class:News
source	projects/cleansing_hcrawler/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Purchase
source	projects/cleansing_hcrawler/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Supplier
specification	projects/cleansing_hcrawler/hcrawler_models.py	/^    specification = StringField()$/;"	v	class:MedicinesInfo
standard_code	projects/cleansing_hcrawler/hcrawler_models.py	/^    standard_code = StringField()$/;"	v	class:MedicinesInfo
standard_code_remark	projects/cleansing_hcrawler/hcrawler_models.py	/^    standard_code_remark = StringField()$/;"	v	class:MedicinesInfo
status	projects/cleansing_hcrawler/hcrawler_models.py	/^    status = StringField()$/;"	v	class:Supplier
storageMode	projects/cleansing_hcrawler/hcrawler_models.py	/^    storageMode = StringField() # 仓促方式$/;"	v	class:Purchase
subscribe_money	projects/cleansing_hcrawler/hcrawler_models.py	/^    subscribe_money = StringField()$/;"	v	class:Shareholders
subscribe_time	projects/cleansing_hcrawler/hcrawler_models.py	/^    subscribe_time = StringField()$/;"	v	class:Shareholders
supplier	projects/cleansing_hcrawler/hcrawler_models.py	/^    supplier = ReferenceField(Supplier)$/;"	v	class:ProductionCapacity
supplierGrade	projects/cleansing_hcrawler/hcrawler_models.py	/^    supplierGrade = StringField() # 供应商评级$/;"	v	class:CompanyInfo
telephone	projects/cleansing_hcrawler/hcrawler_models.py	/^    telephone = StringField()$/;"	v	class:CompanyInfo
title	projects/cleansing_hcrawler/hcrawler_models.py	/^    title = StringField()  # 标题$/;"	v	class:News
totalPrice	projects/cleansing_hcrawler/hcrawler_models.py	/^    totalPrice = StringField() # 总价$/;"	v	class:Purchase
turnout	projects/cleansing_hcrawler/hcrawler_models.py	/^    turnout = StringField() # 产量$/;"	v	class:ProductionCapacity
unified_social_credit_code	projects/cleansing_hcrawler/hcrawler_models.py	/^    unified_social_credit_code = StringField()$/;"	v	class:Supplier
unitText	projects/cleansing_hcrawler/hcrawler_models.py	/^    unitText = StringField() # 价格单位，比如：元\/吨$/;"	v	class:Hprice
unitText	projects/cleansing_hcrawler/hcrawler_models.py	/^    unitText = StringField() # 价格单位，比如：元\/吨$/;"	v	class:Purchase
upstream_material	projects/cleansing_hcrawler/hcrawler_models.py	/^    upstream_material = ListField(StringField()) # 上游产品$/;"	v	class:Hmaterial
validDate	projects/cleansing_hcrawler/hcrawler_models.py	/^    validDate = StringField() # 产能年份$/;"	v	class:ProductionCapacity
validDate	projects/cleansing_hcrawler/hcrawler_models.py	/^    validDate = StringField() # 报价日期$/;"	v	class:Hprice
validFrom	projects/cleansing_hcrawler/hcrawler_models.py	/^    validFrom = StringField()$/;"	v	class:ProductionCapacity
validFrom	projects/cleansing_hcrawler/hcrawler_models.py	/^    validFrom = StringField()$/;"	v	class:Purchase
validThrough	projects/cleansing_hcrawler/hcrawler_models.py	/^    validThrough = StringField()$/;"	v	class:ProductionCapacity
validThrough	projects/cleansing_hcrawler/hcrawler_models.py	/^    validThrough = StringField()$/;"	v	class:Purchase
website	projects/cleansing_hcrawler/hcrawler_models.py	/^    website = StringField()$/;"	v	class:CompanyInfo
website	projects/cleansing_hcrawler/hcrawler_models.py	/^    website = StringField()$/;"	v	class:Confidence
HpriceCleansing	projects/cleansing_hcrawler/hprice_cleaning.py	/^class HpriceCleansing(object):$/;"	c
__init__	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def __init__(self, dir_name, debug = False):$/;"	m	class:HpriceCleansing
clean_item_data	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def clean_item_data(self, schema):$/;"	m	class:HpriceCleansing
clean_item_schema	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def clean_item_schema(self, schema):  $/;"	m	class:HpriceCleansing
collections	projects/cleansing_hcrawler/hprice_cleaning.py	/^import collections$/;"	i
datetime	projects/cleansing_hcrawler/hprice_cleaning.py	/^from datetime import datetime$/;"	i
init_item_schema	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def init_item_schema(self):$/;"	m	class:HpriceCleansing
json	projects/cleansing_hcrawler/hprice_cleaning.py	/^import json$/;"	i
os	projects/cleansing_hcrawler/hprice_cleaning.py	/^import os$/;"	i
parse_single_file	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def parse_single_file(self, file_path):$/;"	m	class:HpriceCleansing
parse_single_item	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def parse_single_item(self, item):$/;"	m	class:HpriceCleansing
re	projects/cleansing_hcrawler/hprice_cleaning.py	/^import re$/;"	i
run	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def run(self):$/;"	m	class:HpriceCleansing
sendto_es	projects/cleansing_hcrawler/hprice_cleaning.py	/^from to_es import sendto_es$/;"	i
set_source_files_path	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def set_source_files_path(self):$/;"	m	class:HpriceCleansing
sys	projects/cleansing_hcrawler/hprice_cleaning.py	/^import sys$/;"	i
url2domain	projects/cleansing_hcrawler/hprice_cleaning.py	/^    def url2domain(self,url):$/;"	m	class:HpriceCleansing
urlparse	projects/cleansing_hcrawler/hprice_cleaning.py	/^from urlparse import urlparse$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/kmzy_cleaning.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
Kmzycleansing	projects/cleansing_hcrawler/kmzy_cleaning.py	/^class Kmzycleansing(HpriceCleansing):$/;"	c
datetime	projects/cleansing_hcrawler/kmzy_cleaning.py	/^from datetime import datetime$/;"	i
k	projects/cleansing_hcrawler/kmzy_cleaning.py	/^    k = Kmzycleansing('kmzy-20160808')$/;"	v	class:Kmzycleansing
parse_single_item	projects/cleansing_hcrawler/kmzy_cleaning.py	/^    def parse_single_item(self, item):$/;"	m	class:Kmzycleansing
DB	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
Hprice	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
KmzyCleansing	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^class KmzyCleansing(HpriceCleansing):$/;"	c
c	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^    c = KmzyCleansing('kmzy-20160808')$/;"	v	class:KmzyCleansing
get_nid	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^    def get_nid(self, name):$/;"	m	class:KmzyCleansing
parse_single_item	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:KmzyCleansing
re	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^import re$/;"	i
sys	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^import sys$/;"	i
url2domain	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^def url2domain(url):$/;"	f
urlparse	projects/cleansing_hcrawler/kmzy_mongo_cleansing.py	/^    from urlparse import urlparse$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
Shengyishecleansing	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^class Shengyishecleansing(HpriceCleansing):$/;"	c
c	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^    c = Shengyishecleansing('chemppi')$/;"	v	class:Shengyishecleansing
datetime	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^from datetime import datetime$/;"	i
parse_single_item	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:Shengyishecleansing
s	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^    s = Shengyishecleansing('agricul')$/;"	v	class:Shengyishecleansing
sendto_es	projects/cleansing_hcrawler/shengyishe_cleansing.py	/^from to_es import sendto_es$/;"	i
DB	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
Hprice	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
ShengyisheCleansing	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^class ShengyisheCleansing(HpriceCleansing):$/;"	c
c	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^    c = ShengyisheCleansing('chemppi')$/;"	v	class:ShengyisheCleansing
get_nid	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^    def get_nid(self, name):$/;"	m	class:ShengyisheCleansing
json	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^import json$/;"	i
parse_single_item	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:ShengyisheCleansing
re	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^import re$/;"	i
s	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^    s = ShengyisheCleansing('agricul')$/;"	v	class:ShengyisheCleansing
sys	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^import sys$/;"	i
url2domain	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^def url2domain(url):$/;"	f
urlparse	projects/cleansing_hcrawler/shengyishe_mongo_cleansing.py	/^    from urlparse import urlparse$/;"	i
CONFIG	projects/cleansing_hcrawler/to_es.py	/^CONFIG = {$/;"	v
ENV	projects/cleansing_hcrawler/to_es.py	/^ENV = 'xiami'$/;"	v
ES_DATASET_CONFIG	projects/cleansing_hcrawler/to_es.py	/^ES_DATASET_CONFIG = {$/;"	v
ES_DATASET_CONFIG_M	projects/cleansing_hcrawler/to_es.py	/^ES_DATASET_CONFIG_M = {$/;"	v
batch_init	projects/cleansing_hcrawler/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
division	projects/cleansing_hcrawler/to_es.py	/^from __future__ import print_function, division$/;"	i
get_esconfig	projects/cleansing_hcrawler/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
os	projects/cleansing_hcrawler/to_es.py	/^import os$/;"	i
print_function	projects/cleansing_hcrawler/to_es.py	/^from __future__ import print_function, division$/;"	i
run_esbulk_rows	projects/cleansing_hcrawler/to_es.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
sendto_es	projects/cleansing_hcrawler/to_es.py	/^def sendto_es(jsons):$/;"	f
DB	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^DB = 'hcrawler'$/;"	v
Hentity	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
Hprice	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^from hcrawler_models import Hprice, Hentity$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
YtyaocaiCleansing	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^class YtyaocaiCleansing(HpriceCleansing):$/;"	c
datetime	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^import datetime$/;"	i
get_nid	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^    def get_nid(self, name):$/;"	m	class:YtyaocaiCleansing
m	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^    m = YtyaocaiCleansing('ytyaocai-20160815')$/;"	v	class:YtyaocaiCleansing
parse_single_item	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:YtyaocaiCleansing
sys	projects/cleansing_hcrawler/yaotong_mongo_cleansing.py	/^import sys$/;"	i
HpriceCleansing	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^from hprice_cleaning import HpriceCleansing$/;"	i
YtyaocaiCleansing	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^class YtyaocaiCleansing(HpriceCleansing):$/;"	c
datetime	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^from datetime import datetime$/;"	i
m	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^    m = YtyaocaiCleansing('ytyaocai-20160815')$/;"	v	class:YtyaocaiCleansing
parse_single_item	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^    def parse_single_item(self, item):$/;"	m	class:YtyaocaiCleansing
sendto_es	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^from to_es import sendto_es$/;"	i
sys	projects/cleansing_hcrawler/ytyaocai_cleansing.py	/^import sys$/;"	i
ENV	projects/devops/monitor.py	/^ENV = 'test'$/;"	v
PIPE	projects/devops/monitor.py	/^    from subprocess import Popen, PIPE, STDOUT$/;"	i
Popen	projects/devops/monitor.py	/^    from subprocess import Popen, PIPE, STDOUT$/;"	i
STDOUT	projects/devops/monitor.py	/^    from subprocess import Popen, PIPE, STDOUT$/;"	i
connection	projects/devops/monitor.py	/^def connection():$/;"	f
datetime	projects/devops/monitor.py	/^from datetime import datetime$/;"	i
get_running_stat	projects/devops/monitor.py	/^def get_running_stat(url_temlate):$/;"	f
json	projects/devops/monitor.py	/^import json$/;"	i
jsvc_fd	projects/devops/monitor.py	/^def jsvc_fd():$/;"	f
jsvc_thread	projects/devops/monitor.py	/^def jsvc_thread():$/;"	f
main	projects/devops/monitor.py	/^def main():$/;"	f
mongo_connection	projects/devops/monitor.py	/^def mongo_connection():$/;"	f
os	projects/devops/monitor.py	/^import os$/;"	i
random	projects/devops/monitor.py	/^import random$/;"	i
random_url	projects/devops/monitor.py	/^def random_url(url, length=4):$/;"	f
requests	projects/devops/monitor.py	/^import requests$/;"	i
run	projects/devops/monitor.py	/^def run(cmd):$/;"	f
slack	projects/devops/monitor.py	/^def slack(msg):$/;"	f
string	projects/devops/monitor.py	/^import string$/;"	i
subprocess	projects/devops/monitor.py	/^import subprocess$/;"	i
time	projects/devops/monitor.py	/^import time$/;"	i
datetime	projects/devops/shuoshuorili_monitor.py	/^from datetime import datetime, timedelta$/;"	i
json	projects/devops/shuoshuorili_monitor.py	/^import json$/;"	i
os	projects/devops/shuoshuorili_monitor.py	/^import os$/;"	i
requests	projects/devops/shuoshuorili_monitor.py	/^import requests$/;"	i
schedule	projects/devops/shuoshuorili_monitor.py	/^def schedule():$/;"	f
slack	projects/devops/shuoshuorili_monitor.py	/^def slack(msg):$/;"	f
time	projects/devops/shuoshuorili_monitor.py	/^import time$/;"	i
timedelta	projects/devops/shuoshuorili_monitor.py	/^from datetime import datetime, timedelta$/;"	i
weixin_log	projects/devops/shuoshuorili_monitor.py	/^def weixin_log(date_str):$/;"	f
Company	projects/dongfangcaifu/dongfangcaifu/items.py	/^class Company(scrapy.Item):$/;"	c
content	projects/dongfangcaifu/dongfangcaifu/items.py	/^    content=scrapy.Field()$/;"	v	class:Company
scrapy	projects/dongfangcaifu/dongfangcaifu/items.py	/^import scrapy$/;"	i
title	projects/dongfangcaifu/dongfangcaifu/items.py	/^    title=scrapy.Field()$/;"	v	class:Company
url	projects/dongfangcaifu/dongfangcaifu/items.py	/^    url=scrapy.Field()$/;"	v	class:Company
BATCH_ID	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^BATCH_ID = 'dongfang-201606test'$/;"	v
DownloadWrapper	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
MyMiddleWare	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^class MyMiddleWare(object):$/;"	c
SERVER	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^SERVER='http:\/\/192.168.1.179:8000\/'$/;"	v
m	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^m = DownloadWrapper(SERVER)$/;"	v
process_request	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^    def process_request(self, request,  spider):$/;"	m	class:MyMiddleWare
scrapy	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^import scrapy$/;"	i
sys	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^import sys$/;"	i
url	projects/dongfangcaifu/dongfangcaifu/middlewares.py	/^url='http:\/\/data.eastmoney.com\/Notice'$/;"	v
DongfangcaifuPipeline	projects/dongfangcaifu/dongfangcaifu/pipelines.py	/^class DongfangcaifuPipeline(object):$/;"	c
__init__	projects/dongfangcaifu/dongfangcaifu/pipelines.py	/^    def __init__(self):$/;"	m	class:DongfangcaifuPipeline
codecs	projects/dongfangcaifu/dongfangcaifu/pipelines.py	/^import codecs$/;"	i
json	projects/dongfangcaifu/dongfangcaifu/pipelines.py	/^import json$/;"	i
process_item	projects/dongfangcaifu/dongfangcaifu/pipelines.py	/^    def process_item(self, item, spider):$/;"	m	class:DongfangcaifuPipeline
BOT_NAME	projects/dongfangcaifu/dongfangcaifu/settings.py	/^BOT_NAME = 'dongfangcaifu'$/;"	v
COOKIES_ENABLED	projects/dongfangcaifu/dongfangcaifu/settings.py	/^COOKIES_ENABLED = False$/;"	v
DEFAULT_REQUEST_HEADERS	projects/dongfangcaifu/dongfangcaifu/settings.py	/^DEFAULT_REQUEST_HEADERS = {$/;"	v
DOWNLOADER_MIDDLEWARES	projects/dongfangcaifu/dongfangcaifu/settings.py	/^DOWNLOADER_MIDDLEWARES = {$/;"	v
DOWNLOAD_DELAY	projects/dongfangcaifu/dongfangcaifu/settings.py	/^DOWNLOAD_DELAY = 3$/;"	v
ITEM_PIPELINES	projects/dongfangcaifu/dongfangcaifu/settings.py	/^ITEM_PIPELINES = {$/;"	v
NEWSPIDER_MODULE	projects/dongfangcaifu/dongfangcaifu/settings.py	/^NEWSPIDER_MODULE = 'dongfangcaifu.spiders'$/;"	v
ROBOTSTXT_OBEY	projects/dongfangcaifu/dongfangcaifu/settings.py	/^ROBOTSTXT_OBEY = True$/;"	v
SPIDER_MODULES	projects/dongfangcaifu/dongfangcaifu/settings.py	/^SPIDER_MODULES = ['dongfangcaifu.spiders']$/;"	v
Company	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^from dongfangcaifu.items import Company  # url,title,content$/;"	i
DongfangSpider	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^class DongfangSpider(Spider):$/;"	c
Spider	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^from scrapy.spiders import Spider$/;"	i
allowed_domains	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    allowed_domains = []$/;"	v	class:DongfangSpider
content	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^from dongfangcaifu.items import Company  # url,title,content$/;"	i
name	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    name = 'dongfang'$/;"	v	class:DongfangSpider
parse	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    def parse(self, response):$/;"	m	class:DongfangSpider
parse_notice	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    def parse_notice(self, response):$/;"	m	class:DongfangSpider
parse_one_page	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    def parse_one_page(self, response):$/;"	m	class:DongfangSpider
pass_item	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    def pass_item(self, i):$/;"	m	class:DongfangSpider
scrapy	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^import scrapy$/;"	i
start_urls	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^    start_urls = ['http:\/\/data.eastmoney.com\/Notice\/Noticelist.aspx']$/;"	v	class:DongfangSpider
title	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^from dongfangcaifu.items import Company  # url,title,content$/;"	i
url	projects/dongfangcaifu/dongfangcaifu/spiders/dongfang.py	/^from dongfangcaifu.items import Company  # url,title,content$/;"	i
CONFIG	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^CONFIG = {$/;"	v
CONFIG_T	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^CONFIG_T = {$/;"	v
Cache	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^from downloader.cache import Cache$/;"	i
DownloadWrapper	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
VERSION	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^VERSION ='v20160620'$/;"	v
codecs	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import datetime$/;"	i
downloader	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import downloader$/;"	i
gen_url	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^def gen_url():$/;"	f
getLocalFile	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^def getTheFile(filename):$/;"	f
getWorkFile	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^def getWorkFile(filename):$/;"	f
libfile	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^from hzlib import libfile$/;"	i
main	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^def main():$/;"	f
os	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import os$/;"	i
sys	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import sys$/;"	i
urllib	projects/dongfangcaifu/dongfangcaifu/task_dongfang.py	/^import urllib$/;"	i
BATCH_ID	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^BATCH_ID = 'dongfang-201606test'$/;"	v
Cache	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^from downloader.cache import Cache$/;"	i
NO	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^NO = 0$/;"	v
OK	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^OK = 0$/;"	v
content	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^    content = m.get(url)$/;"	v
content	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^content = m.get(url)$/;"	v
m	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^m = Cache(BATCH_ID,'http:\/\/192.168.1.179:8000\/')$/;"	v
re	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^import re$/;"	i
requests	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^import requests$/;"	i
sys	projects/dongfangcaifu/dongfangcaifu/testlose.py	/^import sys$/;"	i
Cache	projects/dongfangcaifu/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/dongfangcaifu/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/dongfangcaifu/downloader/cache.py	/^import base64$/;"	i
division	projects/dongfangcaifu/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/dongfangcaifu/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/dongfangcaifu/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/dongfangcaifu/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/dongfangcaifu/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/dongfangcaifu/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/dongfangcaifu/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/dongfangcaifu/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/dongfangcaifu/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/dongfangcaifu/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/dongfangcaifu/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/dongfangcaifu/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/dongfangcaifu/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/dongfangcaifu/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/dongfangcaifu/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/dongfangcaifu/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/dongfangcaifu/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/dongfangcaifu/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/dongfangcaifu/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/dongfangcaifu/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/dongfangcaifu/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/dongfangcaifu/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/dongfangcaifu/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/dongfangcaifu/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/dongfangcaifu/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/dongfangcaifu/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/dongfangcaifu/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/dongfangcaifu/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/dongfangcaifu/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/dongfangcaifu/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/dongfangcaifu/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/dongfangcaifu/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/dongfangcaifu/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/dongfangcaifu/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/dongfangcaifu/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/dongfangcaifu/downloader/downloader.py	/^import os$/;"	i
print_function	projects/dongfangcaifu/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/dongfangcaifu/downloader/downloader.py	/^import re$/;"	i
request_download	projects/dongfangcaifu/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/dongfangcaifu/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/dongfangcaifu/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/dongfangcaifu/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/dongfangcaifu/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/dongfangcaifu/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/dongfangcaifu/downloader/downloader.py	/^import sys$/;"	i
time	projects/dongfangcaifu/downloader/downloader.py	/^import time$/;"	i
update_header	projects/dongfangcaifu/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/dongfangcaifu/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/dongfangcaifu/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/dongfangcaifu/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/dongfangcaifu/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/dongfangcaifu/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/dongfangcaifu/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/dongfangcaifu/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/downloader/test_download.py	/^import datetime$/;"	i
json	projects/dongfangcaifu/downloader/test_download.py	/^import json$/;"	i
main	projects/dongfangcaifu/downloader/test_download.py	/^def main():$/;"	f
os	projects/dongfangcaifu/downloader/test_download.py	/^import os$/;"	i
re	projects/dongfangcaifu/downloader/test_download.py	/^import re$/;"	i
requests	projects/dongfangcaifu/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/dongfangcaifu/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/dongfangcaifu/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/dongfangcaifu/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/dongfangcaifu/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/dongfangcaifu/downloader/test_download.py	/^import time$/;"	i
urllib	projects/dongfangcaifu/downloader/test_download.py	/^import urllib$/;"	i
DownloadWrapper	projects/dongfangcaifu/get_from_file.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Downloader	projects/dongfangcaifu/get_from_file.py	/^from downloader.downloader import Downloader$/;"	i
download_url	projects/dongfangcaifu/get_from_file.py	/^def download_url(url):$/;"	f
generate_json	projects/dongfangcaifu/get_from_file.py	/^def generate_json(url, content):$/;"	f
html	projects/dongfangcaifu/get_from_file.py	/^import lxml.html$/;"	i
json	projects/dongfangcaifu/get_from_file.py	/^import json$/;"	i
lxml	projects/dongfangcaifu/get_from_file.py	/^import lxml.html$/;"	i
run	projects/dongfangcaifu/get_from_file.py	/^def run(filename):$/;"	f
sys	projects/dongfangcaifu/get_from_file.py	/^import sys$/;"	i
InstanceMgr	projects/dongfangcaifu/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/dongfangcaifu/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/dongfangcaifu/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/dongfangcaifu/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/dongfangcaifu/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/dongfangcaifu/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/dongfangcaifu/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/dongfangcaifu/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/dongfangcaifu/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/dongfangcaifu/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/dongfangcaifu/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/dongfangcaifu/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/dongfangcaifu/hzlib/api_aws.py	/^import json$/;"	i
list	projects/dongfangcaifu/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/dongfangcaifu/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/dongfangcaifu/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/dongfangcaifu/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/dongfangcaifu/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/dongfangcaifu/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/dongfangcaifu/hzlib/api_aws.py	/^import re$/;"	i
run	projects/dongfangcaifu/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/dongfangcaifu/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/dongfangcaifu/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/dongfangcaifu/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/dongfangcaifu/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/dongfangcaifu/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/dongfangcaifu/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/dongfangcaifu/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/dongfangcaifu/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/dongfangcaifu/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/dongfangcaifu/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/dongfangcaifu/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/dongfangcaifu/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/dongfangcaifu/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/dongfangcaifu/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/dongfangcaifu/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/dongfangcaifu/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/dongfangcaifu/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/dongfangcaifu/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/dongfangcaifu/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/dongfangcaifu/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/dongfangcaifu/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/dongfangcaifu/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/dongfangcaifu/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/dongfangcaifu/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/dongfangcaifu/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/dongfangcaifu/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/dongfangcaifu/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/dongfangcaifu/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/dongfangcaifu/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/dongfangcaifu/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/dongfangcaifu/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/dongfangcaifu/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/dongfangcaifu/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/dongfangcaifu/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/dongfangcaifu/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/dongfangcaifu/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/dongfangcaifu/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/dongfangcaifu/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/dongfangcaifu/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/dongfangcaifu/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/dongfangcaifu/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/dongfangcaifu/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/dongfangcaifu/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/dongfangcaifu/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/dongfangcaifu/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/dongfangcaifu/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/dongfangcaifu/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/dongfangcaifu/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/dongfangcaifu/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/dongfangcaifu/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/dongfangcaifu/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/dongfangcaifu/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/dongfangcaifu/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/dongfangcaifu/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/dongfangcaifu/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/dongfangcaifu/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/dongfangcaifu/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/dongfangcaifu/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/dongfangcaifu/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/dongfangcaifu/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/dongfangcaifu/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/dongfangcaifu/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/dongfangcaifu/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/dongfangcaifu/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/dongfangcaifu/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/dongfangcaifu/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/dongfangcaifu/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/dongfangcaifu/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/dongfangcaifu/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/dongfangcaifu/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/dongfangcaifu/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/dongfangcaifu/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/dongfangcaifu/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/dongfangcaifu/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/dongfangcaifu/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/dongfangcaifu/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/dongfangcaifu/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/dongfangcaifu/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/dongfangcaifu/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/dongfangcaifu/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/dongfangcaifu/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/dongfangcaifu/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/dongfangcaifu/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/dongfangcaifu/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/dongfangcaifu/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/dongfangcaifu/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/dongfangcaifu/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/dongfangcaifu/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/dongfangcaifu/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/dongfangcaifu/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/dongfangcaifu/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/dongfangcaifu/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/dongfangcaifu/hzlib/libdata.py	/^import random$/;"	i
re	projects/dongfangcaifu/hzlib/libdata.py	/^import re$/;"	i
requests	projects/dongfangcaifu/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/dongfangcaifu/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/dongfangcaifu/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/dongfangcaifu/hzlib/libdata.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/dongfangcaifu/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/dongfangcaifu/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/dongfangcaifu/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/dongfangcaifu/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/dongfangcaifu/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/dongfangcaifu/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/dongfangcaifu/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/dongfangcaifu/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/dongfangcaifu/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/dongfangcaifu/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/dongfangcaifu/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/dongfangcaifu/hzlib/libfile.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/dongfangcaifu/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/dongfangcaifu/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/dongfangcaifu/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/dongfangcaifu/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/dongfangcaifu/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/dongfangcaifu/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/dongfangcaifu/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/dongfangcaifu/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/dongfangcaifu/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/dongfangcaifu/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/dongfangcaifu/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/dongfangcaifu/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/dongfangcaifu/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/dongfangcaifu/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/dongfangcaifu/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/dongfangcaifu/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/dongfangcaifu/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/dongfangcaifu/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/dongfangcaifu/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/dongfangcaifu/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/dongfangcaifu/hzlib/libnlp.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/dongfangcaifu/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/dongfangcaifu/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/dongfangcaifu/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/dongfangcaifu/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/dongfangcaifu/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/dongfangcaifu/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/dongfangcaifu/hzlib/libregex.py	/^def main():$/;"	f
os	projects/dongfangcaifu/hzlib/libregex.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/libregex.py	/^import re$/;"	i
sys	projects/dongfangcaifu/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/dongfangcaifu/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/dongfangcaifu/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/dongfangcaifu/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/dongfangcaifu/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/dongfangcaifu/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/dongfangcaifu/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/dongfangcaifu/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/dongfangcaifu/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/dongfangcaifu/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/dongfangcaifu/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/dongfangcaifu/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/dongfangcaifu/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/dongfangcaifu/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/dongfangcaifu/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/dongfangcaifu/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/dongfangcaifu/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/dongfangcaifu/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/dongfangcaifu/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/dongfangcaifu/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/dongfangcaifu/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/dongfangcaifu/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/dongfangcaifu/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/dongfangcaifu/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/dongfangcaifu/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/dongfangcaifu/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/dongfangcaifu/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/dongfangcaifu/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/dongfangcaifu/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/dongfangcaifu/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/dongfangcaifu/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/dongfangcaifu/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/dongfangcaifu/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/dongfangcaifu/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/dongfangcaifu/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/dongfangcaifu/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/dongfangcaifu/hzlib/tests/test_api.py	/^def test_search():$/;"	f
json	projects/dongfangcaifu/tests/test_dongfang.py	/^import json$/;"	i
requests	projects/dongfangcaifu/tests/test_dongfang.py	/^import requests$/;"	i
session	projects/dongfangcaifu/tests/test_dongfang.py	/^session = requests.Session()$/;"	v
sys	projects/dongfangcaifu/tests/test_dongfang.py	/^import sys$/;"	i
test_notice	projects/dongfangcaifu/tests/test_dongfang.py	/^def test_notice():$/;"	f
test_page	projects/dongfangcaifu/tests/test_dongfang.py	/^def test_page():$/;"	f
time	projects/dongfangcaifu/tests/test_dongfang.py	/^import time$/;"	i
BaseController	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/BaseController.java	/^public class BaseController {$/;"	c
com.haizhi.hbrain.controller	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/BaseController.java	/^package com.haizhi.hbrain.controller;$/;"	p
mongoTemplate	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/BaseController.java	/^	public MongoTemplate mongoTemplate;$/;"	f	class:BaseController
HbrainAPIController	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^public class HbrainAPIController extends BaseController{$/;"	c
com.haizhi.hbrain.controller	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^package com.haizhi.hbrain.controller;$/;"	p
companies	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^	public void companies(@RequestParam(required = true) String q,$/;"	m	class:HbrainAPIController
findHData	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^	public void findHData(@RequestParam(required = false) String q,$/;"	m	class:HbrainAPIController
getHPrice	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^	public void getHPrice(@RequestParam(required = false) String q,$/;"	m	class:HbrainAPIController
news	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^    public void news(@RequestParam(required = true) String q,$/;"	m	class:HbrainAPIController
version	projects/hbrain/src/main/java/com/haizhi/hbrain/controller/HbrainAPIController.java	/^	public void version(HttpServletRequest request, HttpServletResponse response) throws Exception {$/;"	m	class:HbrainAPIController
CharacterFilter	projects/hbrain/src/main/java/com/haizhi/hbrain/filter/CharacterFilter.java	/^public class CharacterFilter implements Filter {$/;"	c
com.haizhi.hbrain.filter	projects/hbrain/src/main/java/com/haizhi/hbrain/filter/CharacterFilter.java	/^package com.haizhi.hbrain.filter;$/;"	p
destroy	projects/hbrain/src/main/java/com/haizhi/hbrain/filter/CharacterFilter.java	/^	public void destroy() {$/;"	m	class:CharacterFilter
doFilter	projects/hbrain/src/main/java/com/haizhi/hbrain/filter/CharacterFilter.java	/^	public void doFilter(ServletRequest servletRequest, ServletResponse response, FilterChain chain)$/;"	m	class:CharacterFilter
init	projects/hbrain/src/main/java/com/haizhi/hbrain/filter/CharacterFilter.java	/^	public void init(FilterConfig arg0) throws ServletException {$/;"	m	class:CharacterFilter
CompaniesModel	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^public class CompaniesModel extends ToString {$/;"	c
alias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private List<String> alias;$/;"	f	class:CompaniesModel	file:
claims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private List<Map<String, String>> claims;$/;"	f	class:CompaniesModel	file:
com.haizhi.hbrain.model	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^package com.haizhi.hbrain.model;$/;"	p
createdTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String createdTime;$/;"	f	class:CompaniesModel	file:
deletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String deletedTime;$/;"	f	class:CompaniesModel	file:
getAlias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public List<String> getAlias() {$/;"	m	class:CompaniesModel
getClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public List<Map<String, String>> getClaims() {$/;"	m	class:CompaniesModel
getCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getCreatedTime() {$/;"	m	class:CompaniesModel
getDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getDeletedTime() {$/;"	m	class:CompaniesModel
getGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getGid() {$/;"	m	class:CompaniesModel
getId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getId() {$/;"	m	class:CompaniesModel
getNid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getNid() {$/;"	m	class:CompaniesModel
getSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public Map<String, String> getSource() {$/;"	m	class:CompaniesModel
getSrank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getSrank() {$/;"	m	class:CompaniesModel
getUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public String getUpdatedTime() {$/;"	m	class:CompaniesModel
gid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String gid;$/;"	f	class:CompaniesModel	file:
id	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String id;$/;"	f	class:CompaniesModel	file:
nid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String nid;$/;"	f	class:CompaniesModel	file:
serialVersionUID	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private static final long serialVersionUID = 8493213091600211460L;$/;"	f	class:CompaniesModel	file:
setAlias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setAlias(List<String> alias) {$/;"	m	class:CompaniesModel
setClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setClaims(List<Map<String, String>> claims) {$/;"	m	class:CompaniesModel
setCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setCreatedTime(String createdTime) {$/;"	m	class:CompaniesModel
setDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setDeletedTime(String deletedTime) {$/;"	m	class:CompaniesModel
setGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setGid(String gid) {$/;"	m	class:CompaniesModel
setId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setId(String id) {$/;"	m	class:CompaniesModel
setNid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setNid(String nid) {$/;"	m	class:CompaniesModel
setSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setSource(Map<String, String> source) {$/;"	m	class:CompaniesModel
setSrank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setSrank(String srank) {$/;"	m	class:CompaniesModel
setUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	public void setUpdatedTime(String updatedTime) {$/;"	m	class:CompaniesModel
source	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private Map<String, String> source;$/;"	f	class:CompaniesModel	file:
srank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String srank;$/;"	f	class:CompaniesModel	file:
updatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/CompaniesModel.java	/^	private String updatedTime;$/;"	f	class:CompaniesModel	file:
EntitiesModel	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^public class EntitiesModel extends ToString{$/;"	c
alias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private List<String> alias;$/;"	f	class:EntitiesModel	file:
claims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private List<Map<String, String>> claims;$/;"	f	class:EntitiesModel	file:
com.haizhi.hbrain.model	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^package com.haizhi.hbrain.model;$/;"	p
createdTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String createdTime;$/;"	f	class:EntitiesModel	file:
deletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String deletedTime;$/;"	f	class:EntitiesModel	file:
format	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String format;$/;"	f	class:EntitiesModel	file:
getAlias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public List<String> getAlias() {$/;"	m	class:EntitiesModel
getClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public List<Map<String, String>> getClaims() {$/;"	m	class:EntitiesModel
getCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getCreatedTime() {$/;"	m	class:EntitiesModel
getDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getDeletedTime() {$/;"	m	class:EntitiesModel
getFormat	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getFormat() {$/;"	m	class:EntitiesModel
getGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getGid() {$/;"	m	class:EntitiesModel
getId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getId() {$/;"	m	class:EntitiesModel
getNid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getNid() {$/;"	m	class:EntitiesModel
getSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public Map<String, String> getSource() {$/;"	m	class:EntitiesModel
getSrank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public int getSrank() {$/;"	m	class:EntitiesModel
getTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public List<String> getTags() {$/;"	m	class:EntitiesModel
getTotal	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public int getTotal() {$/;"	m	class:EntitiesModel
getUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public String getUpdatedTime() {$/;"	m	class:EntitiesModel
gid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String gid;$/;"	f	class:EntitiesModel	file:
id	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String id;$/;"	f	class:EntitiesModel	file:
nid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String nid;$/;"	f	class:EntitiesModel	file:
serialVersionUID	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private static final long serialVersionUID = -8007826315486887330L;$/;"	f	class:EntitiesModel	file:
setAlias	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setAlias(List<String> alias) {$/;"	m	class:EntitiesModel
setClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setClaims(List<Map<String, String>> claims) {$/;"	m	class:EntitiesModel
setCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setCreatedTime(String createdTime) {$/;"	m	class:EntitiesModel
setDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setDeletedTime(String deletedTime) {$/;"	m	class:EntitiesModel
setFormat	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setFormat(String format) {$/;"	m	class:EntitiesModel
setGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setGid(String gid) {$/;"	m	class:EntitiesModel
setId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setId(String id) {$/;"	m	class:EntitiesModel
setNid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setNid(String nid) {$/;"	m	class:EntitiesModel
setSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setSource(Map<String, String> source) {$/;"	m	class:EntitiesModel
setSrank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setSrank(int srank) {$/;"	m	class:EntitiesModel
setTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setTags(List<String> tags) {$/;"	m	class:EntitiesModel
setTotal	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setTotal(int total) {$/;"	m	class:EntitiesModel
setUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	public void setUpdatedTime(String updatedTime) {$/;"	m	class:EntitiesModel
source	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private Map<String, String> source;$/;"	f	class:EntitiesModel	file:
srank	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private int srank;$/;"	f	class:EntitiesModel	file:
tags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private List<String> tags;$/;"	f	class:EntitiesModel	file:
total	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private int total;$/;"	f	class:EntitiesModel	file:
updatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/EntitiesModel.java	/^	private String updatedTime;$/;"	f	class:EntitiesModel	file:
NewsModel	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^public class NewsModel extends ToString {$/;"	c
claims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private List<Map<String, String>> claims;$/;"	f	class:NewsModel	file:
com.haizhi.hbrain.model	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^package com.haizhi.hbrain.model;$/;"	p
createdTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String createdTime;$/;"	f	class:NewsModel	file:
deletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String deletedTime;$/;"	f	class:NewsModel	file:
getClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public List<Map<String, String>> getClaims() {$/;"	m	class:NewsModel
getCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getCreatedTime() {$/;"	m	class:NewsModel
getDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getDeletedTime() {$/;"	m	class:NewsModel
getGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getGid() {$/;"	m	class:NewsModel
getId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getId() {$/;"	m	class:NewsModel
getRid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getRid() {$/;"	m	class:NewsModel
getSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public Map<String, String> getSource() {$/;"	m	class:NewsModel
getTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public List<String> getTags() {$/;"	m	class:NewsModel
getUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public String getUpdatedTime() {$/;"	m	class:NewsModel
gid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String gid;$/;"	f	class:NewsModel	file:
id	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String id;$/;"	f	class:NewsModel	file:
rid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String rid;$/;"	f	class:NewsModel	file:
serialVersionUID	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private static final long serialVersionUID = 1L;$/;"	f	class:NewsModel	file:
setClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setClaims(List<Map<String, String>> claims) {$/;"	m	class:NewsModel
setCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setCreatedTime(String createdTime) {$/;"	m	class:NewsModel
setDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setDeletedTime(String deletedTime) {$/;"	m	class:NewsModel
setGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setGid(String gid) {$/;"	m	class:NewsModel
setId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setId(String id) {$/;"	m	class:NewsModel
setRid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setRid(String rid) {$/;"	m	class:NewsModel
setSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setSource(Map<String, String> source) {$/;"	m	class:NewsModel
setTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setTags(List<String> tags) {$/;"	m	class:NewsModel
setUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    public void setUpdatedTime(String updatedTime) {$/;"	m	class:NewsModel
source	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private Map<String, String> source;$/;"	f	class:NewsModel	file:
tags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private List<String> tags;$/;"	f	class:NewsModel	file:
updatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/NewsModel.java	/^    private String updatedTime;$/;"	f	class:NewsModel	file:
PriceModel	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^public class PriceModel extends ToString{$/;"	c
claims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private List<Map<String, String>> claims;$/;"	f	class:PriceModel	file:
com.haizhi.hbrain.model	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^package com.haizhi.hbrain.model;$/;"	p
createdTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String createdTime;$/;"	f	class:PriceModel	file:
dataSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String dataSource;$/;"	f	class:PriceModel	file:
deletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String deletedTime;$/;"	f	class:PriceModel	file:
getClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public List<Map<String, String>> getClaims() {$/;"	m	class:PriceModel
getCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getCreatedTime() {$/;"	m	class:PriceModel
getDataSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getDataSource() {$/;"	m	class:PriceModel
getDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getDeletedTime() {$/;"	m	class:PriceModel
getGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getGid() {$/;"	m	class:PriceModel
getId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getId() {$/;"	m	class:PriceModel
getQuotedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getQuotedTime() {$/;"	m	class:PriceModel
getRid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getRid() {$/;"	m	class:PriceModel
getSeries	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getSeries() {$/;"	m	class:PriceModel
getSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public Map<String, String> getSource() {$/;"	m	class:PriceModel
getTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getTags() {$/;"	m	class:PriceModel
getUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public String getUpdatedTime() {$/;"	m	class:PriceModel
gid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String gid;$/;"	f	class:PriceModel	file:
id	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String id;$/;"	f	class:PriceModel	file:
quotedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String quotedTime;$/;"	f	class:PriceModel	file:
rid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String rid;$/;"	f	class:PriceModel	file:
serialVersionUID	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private static final long serialVersionUID = 4948172401697253231L;$/;"	f	class:PriceModel	file:
series	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String series;$/;"	f	class:PriceModel	file:
setClaims	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setClaims(List<Map<String, String>> claims) {$/;"	m	class:PriceModel
setCreatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setCreatedTime(String createdTime) {$/;"	m	class:PriceModel
setDataSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setDataSource(String dataSource) {$/;"	m	class:PriceModel
setDeletedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setDeletedTime(String deletedTime) {$/;"	m	class:PriceModel
setGid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setGid(String gid) {$/;"	m	class:PriceModel
setId	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setId(String id) {$/;"	m	class:PriceModel
setQuotedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setQuotedTime(String quotedTime) {$/;"	m	class:PriceModel
setRid	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setRid(String rid) {$/;"	m	class:PriceModel
setSeries	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setSeries(String series) {$/;"	m	class:PriceModel
setSource	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setSource(Map<String, String> source) {$/;"	m	class:PriceModel
setTags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setTags(String tags) {$/;"	m	class:PriceModel
setUpdatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	public void setUpdatedTime(String updatedTime) {$/;"	m	class:PriceModel
source	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private Map<String, String> source;$/;"	f	class:PriceModel	file:
tags	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String tags;$/;"	f	class:PriceModel	file:
updatedTime	projects/hbrain/src/main/java/com/haizhi/hbrain/model/PriceModel.java	/^	private String updatedTime;$/;"	f	class:PriceModel	file:
APIUtils	projects/hbrain/src/main/java/com/haizhi/hbrain/util/APIUtils.java	/^public class APIUtils {$/;"	c
com.haizhi.hbrain.util	projects/hbrain/src/main/java/com/haizhi/hbrain/util/APIUtils.java	/^package com.haizhi.hbrain.util;$/;"	p
constructQuery	projects/hbrain/src/main/java/com/haizhi/hbrain/util/APIUtils.java	/^	public static Query constructQuery(String q, int offset, int limit){$/;"	m	class:APIUtils
parseInterISODate	projects/hbrain/src/main/java/com/haizhi/hbrain/util/APIUtils.java	/^	public static String parseInterISODate(String date){$/;"	m	class:APIUtils
SmartvApiResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public SmartvApiResult() {$/;"	m	class:SmartvApiResult
SmartvApiResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public SmartvApiResult(int code, String msg, Object result) {$/;"	m	class:SmartvApiResult
SmartvApiResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public SmartvApiResult(int code, String msg, Object result, int total) {$/;"	m	class:SmartvApiResult
SmartvApiResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^public class SmartvApiResult {$/;"	c
code	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	private int code;$/;"	f	class:SmartvApiResult	file:
com.haizhi.hbrain.util	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^package com.haizhi.hbrain.util;$/;"	p
failure	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static String failure(String msg) {$/;"	m	class:SmartvApiResult
getCode	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public int getCode() {$/;"	m	class:SmartvApiResult
getMessage	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public String getMessage() {$/;"	m	class:SmartvApiResult
getResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public Object getResult() {$/;"	m	class:SmartvApiResult
getTotal	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public int getTotal() {$/;"	m	class:SmartvApiResult
log	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	private static final Logger log = Logger.getLogger(SmartvApiResult.class);$/;"	f	class:SmartvApiResult	file:
message	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	private String message;$/;"	f	class:SmartvApiResult	file:
packInput	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static JsonObject packInput(HttpServletRequest request, JsonObject metadata, String... args) {$/;"	m	class:SmartvApiResult
packMetadata	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static JsonObject packMetadata(String type, String release_version, String build_version) {$/;"	m	class:SmartvApiResult
result	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	private Object result;$/;"	f	class:SmartvApiResult	file:
setCode	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public void setCode(int code) {$/;"	m	class:SmartvApiResult
setMessage	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public void setMessage(String msg) {$/;"	m	class:SmartvApiResult
setResult	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public void setResult(Object result) {$/;"	m	class:SmartvApiResult
setTotal	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public void setTotal(int total) {$/;"	m	class:SmartvApiResult
success	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static String success(String msg) {$/;"	m	class:SmartvApiResult
successForObj	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static String successForObj(Object result) {$/;"	m	class:SmartvApiResult
total	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	private int total;$/;"	f	class:SmartvApiResult	file:
writeResponse	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static void writeResponse(HttpServletRequest request, HttpServletResponse response, String output)$/;"	m	class:SmartvApiResult
writeResponseException	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static void writeResponseException(HttpServletRequest request, HttpServletResponse response, Exception e) {$/;"	m	class:SmartvApiResult
writeResponseOk	projects/hbrain/src/main/java/com/haizhi/hbrain/util/SmartvApiResult.java	/^	public static void writeResponseOk(HttpServletRequest request, HttpServletResponse response, Object output)$/;"	m	class:SmartvApiResult
ToString	projects/hbrain/src/main/java/com/haizhi/hbrain/util/ToString.java	/^public class ToString implements Serializable {$/;"	c
com.haizhi.hbrain.util	projects/hbrain/src/main/java/com/haizhi/hbrain/util/ToString.java	/^package com.haizhi.hbrain.util;$/;"	p
filedMap	projects/hbrain/src/main/java/com/haizhi/hbrain/util/ToString.java	/^	private static Map<Class<?>, Field[]> filedMap = new HashMap<Class<?>, Field[]>();$/;"	f	class:ToString	file:
serialVersionUID	projects/hbrain/src/main/java/com/haizhi/hbrain/util/ToString.java	/^	private static final long serialVersionUID = -7187454415838423368L;$/;"	f	class:ToString	file:
toString	projects/hbrain/src/main/java/com/haizhi/hbrain/util/ToString.java	/^	public String toString() {$/;"	m	class:ToString
ChemppiLoader	projects/hcleansing/chemppi_loader.py	/^class ChemppiLoader(Loader):$/;"	c
DuplicateKeyError	projects/hcleansing/chemppi_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/chemppi_loader.py	/^from loader import Loader$/;"	i
MongoClient	projects/hcleansing/chemppi_loader.py	/^from pymongo import MongoClient$/;"	i
__init__	projects/hcleansing/chemppi_loader.py	/^    def __init__(self):$/;"	m	class:ChemppiLoader
datetime	projects/hcleansing/chemppi_loader.py	/^from datetime import datetime$/;"	i
dateutil	projects/hcleansing/chemppi_loader.py	/^import dateutil.parser$/;"	i
division	projects/hcleansing/chemppi_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/chemppi_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/chemppi_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/chemppi_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/chemppi_loader.py	/^    obj = ChemppiLoader()$/;"	v	class:ChemppiLoader
os	projects/hcleansing/chemppi_loader.py	/^import os$/;"	i
parse_info	projects/hcleansing/chemppi_loader.py	/^    def parse_info(self, jsn):$/;"	m	class:ChemppiLoader
parser	projects/hcleansing/chemppi_loader.py	/^import dateutil.parser$/;"	i
print_function	projects/hcleansing/chemppi_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/chemppi_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:ChemppiLoader
sys	projects/hcleansing/chemppi_loader.py	/^import sys$/;"	i
urllib	projects/hcleansing/chemppi_loader.py	/^import urllib$/;"	i
InstanceMgr	projects/hcleansing/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/hcleansing/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/hcleansing/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/hcleansing/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/hcleansing/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/hcleansing/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/hcleansing/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/hcleansing/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/hcleansing/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/hcleansing/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/hcleansing/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/hcleansing/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/hcleansing/hzlib/api_aws.py	/^import json$/;"	i
list	projects/hcleansing/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/hcleansing/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/hcleansing/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/hcleansing/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/hcleansing/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/hcleansing/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/hcleansing/hzlib/api_aws.py	/^import re$/;"	i
run	projects/hcleansing/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/hcleansing/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/hcleansing/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/hcleansing/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/hcleansing/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/hcleansing/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/hcleansing/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/hcleansing/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/hcleansing/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/hcleansing/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/hcleansing/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/hcleansing/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/hcleansing/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/hcleansing/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/hcleansing/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/hcleansing/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/hcleansing/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/hcleansing/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/hcleansing/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/hcleansing/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/hcleansing/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/hcleansing/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/hcleansing/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/hcleansing/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/hcleansing/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/hcleansing/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/hcleansing/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/hcleansing/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/hcleansing/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/hcleansing/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/hcleansing/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/hcleansing/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/hcleansing/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/hcleansing/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/hcleansing/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/hcleansing/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/hcleansing/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/hcleansing/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/hcleansing/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/hcleansing/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/hcleansing/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/hcleansing/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/hcleansing/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/hcleansing/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/hcleansing/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/hcleansing/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/hcleansing/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/hcleansing/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/hcleansing/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/hcleansing/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/hcleansing/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/hcleansing/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/hcleansing/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/hcleansing/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/hcleansing/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/hcleansing/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/hcleansing/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/hcleansing/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/hcleansing/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/hcleansing/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/hcleansing/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/hcleansing/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/hcleansing/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/hcleansing/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/hcleansing/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/hcleansing/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/hcleansing/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/hcleansing/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/hcleansing/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/hcleansing/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/hcleansing/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/hcleansing/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/hcleansing/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/hcleansing/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/hcleansing/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/hcleansing/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/hcleansing/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/hcleansing/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/hcleansing/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/hcleansing/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/hcleansing/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/hcleansing/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/hcleansing/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/hcleansing/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/hcleansing/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/hcleansing/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/hcleansing/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/hcleansing/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/hcleansing/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/hcleansing/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/hcleansing/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/hcleansing/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/hcleansing/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/hcleansing/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/hcleansing/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/hcleansing/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/hcleansing/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/hcleansing/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/hcleansing/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/hcleansing/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/hcleansing/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/hcleansing/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/hcleansing/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/hcleansing/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/hcleansing/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/hcleansing/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/hcleansing/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/hcleansing/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/hcleansing/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/hcleansing/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/hcleansing/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/hcleansing/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/hcleansing/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/hcleansing/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/hcleansing/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/hcleansing/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/hcleansing/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/hcleansing/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/hcleansing/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/hcleansing/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/hcleansing/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/hcleansing/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/hcleansing/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/hcleansing/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/hcleansing/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/hcleansing/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/hcleansing/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/hcleansing/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/hcleansing/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/hcleansing/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/hcleansing/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/hcleansing/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/hcleansing/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/hcleansing/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/hcleansing/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/hcleansing/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/hcleansing/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/hcleansing/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/hcleansing/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/hcleansing/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/hcleansing/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/hcleansing/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/hcleansing/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/hcleansing/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/hcleansing/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/hcleansing/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/hcleansing/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/hcleansing/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/hcleansing/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/hcleansing/hzlib/libdata.py	/^import random$/;"	i
re	projects/hcleansing/hzlib/libdata.py	/^import re$/;"	i
requests	projects/hcleansing/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/hcleansing/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/hcleansing/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/hcleansing/hzlib/libdata.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/hcleansing/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/hcleansing/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/hcleansing/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/hcleansing/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/hcleansing/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/hcleansing/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/hcleansing/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/hcleansing/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/hcleansing/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/hcleansing/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/hcleansing/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/hcleansing/hzlib/libfile.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/hcleansing/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/hcleansing/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/hcleansing/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/hcleansing/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/hcleansing/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/hcleansing/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/hcleansing/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/hcleansing/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/hcleansing/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/hcleansing/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/hcleansing/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/hcleansing/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/hcleansing/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/hcleansing/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/hcleansing/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/hcleansing/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/hcleansing/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/hcleansing/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/hcleansing/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/hcleansing/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/hcleansing/hzlib/libnlp.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/hcleansing/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/hcleansing/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/hcleansing/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/hcleansing/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/hcleansing/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/hcleansing/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/hcleansing/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/hcleansing/hzlib/libregex.py	/^def main():$/;"	f
os	projects/hcleansing/hzlib/libregex.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/libregex.py	/^import re$/;"	i
sys	projects/hcleansing/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/hcleansing/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/hcleansing/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/hcleansing/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/hcleansing/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/hcleansing/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/hcleansing/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/hcleansing/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/hcleansing/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/hcleansing/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/hcleansing/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/hcleansing/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/hcleansing/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/hcleansing/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/hcleansing/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/hcleansing/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/hcleansing/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/hcleansing/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/hcleansing/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/hcleansing/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/hcleansing/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/hcleansing/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/hcleansing/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/hcleansing/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/hcleansing/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/hcleansing/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/hcleansing/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/hcleansing/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/hcleansing/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/hcleansing/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/hcleansing/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/hcleansing/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/hcleansing/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/hcleansing/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/hcleansing/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/hcleansing/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/hcleansing/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/hcleansing/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/hcleansing/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/hcleansing/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/hcleansing/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/hcleansing/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/hcleansing/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/hcleansing/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/hcleansing/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/hcleansing/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/hcleansing/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/hcleansing/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/hcleansing/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/hcleansing/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/hcleansing/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/hcleansing/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/hcleansing/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/hcleansing/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/hcleansing/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/hcleansing/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/hcleansing/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/hcleansing/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/hcleansing/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/hcleansing/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/hcleansing/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/hcleansing/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/hcleansing/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/hcleansing/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/hcleansing/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/hcleansing/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/hcleansing/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/hcleansing/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/hcleansing/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/hcleansing/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/hcleansing/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/hcleansing/hzlib/tests/test_api.py	/^def test_search():$/;"	f
DuplicateKeyError	projects/hcleansing/kmzy_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
KmzyLoader	projects/hcleansing/kmzy_loader.py	/^class KmzyLoader(Loader):$/;"	c
Loader	projects/hcleansing/kmzy_loader.py	/^from loader import Loader$/;"	i
datetime	projects/hcleansing/kmzy_loader.py	/^from datetime import datetime$/;"	i
division	projects/hcleansing/kmzy_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/kmzy_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/kmzy_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/kmzy_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/kmzy_loader.py	/^    obj = KmzyLoader()$/;"	v	class:KmzyLoader
os	projects/hcleansing/kmzy_loader.py	/^import os$/;"	i
parse	projects/hcleansing/kmzy_loader.py	/^    def parse(self, jsn):$/;"	m	class:KmzyLoader
print_function	projects/hcleansing/kmzy_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/kmzy_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:KmzyLoader
sys	projects/hcleansing/kmzy_loader.py	/^import sys$/;"	i
DuplicateKeyError	projects/hcleansing/kmzydaily_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
KmzydailyLoader	projects/hcleansing/kmzydaily_loader.py	/^class KmzydailyLoader(Loader):$/;"	c
Loader	projects/hcleansing/kmzydaily_loader.py	/^from loader import Loader$/;"	i
datetime	projects/hcleansing/kmzydaily_loader.py	/^from datetime import datetime$/;"	i
division	projects/hcleansing/kmzydaily_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/kmzydaily_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/kmzydaily_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/kmzydaily_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/kmzydaily_loader.py	/^    obj = KmzydailyLoader()$/;"	v	class:KmzydailyLoader
os	projects/hcleansing/kmzydaily_loader.py	/^import os$/;"	i
parse	projects/hcleansing/kmzydaily_loader.py	/^    def parse(self, jsn):$/;"	m	class:KmzydailyLoader
print_function	projects/hcleansing/kmzydaily_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/kmzydaily_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:KmzydailyLoader
sys	projects/hcleansing/kmzydaily_loader.py	/^import sys$/;"	i
Loader	projects/hcleansing/loader.py	/^class Loader(object):$/;"	c
MongoClient	projects/hcleansing/loader.py	/^from pymongo import MongoClient$/;"	i
__init__	projects/hcleansing/loader.py	/^    def __init__(self):$/;"	m	class:Loader
division	projects/hcleansing/loader.py	/^from __future__ import print_function, division$/;"	i
get_tags_alias	projects/hcleansing/loader.py	/^    def get_tags_alias(tags_datadir):$/;"	m	class:Loader
json	projects/hcleansing/loader.py	/^import json$/;"	i
parser	projects/hcleansing/loader.py	/^    def parser(self, jsn):$/;"	m	class:Loader
print_function	projects/hcleansing/loader.py	/^from __future__ import print_function, division$/;"	i
re	projects/hcleansing/loader.py	/^import re$/;"	i
read_jsn	projects/hcleansing/loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:Loader
requests	projects/hcleansing/loader.py	/^import requests$/;"	i
slack	projects/hcleansing/loader.py	/^def slack(msg):$/;"	f
url2domain	projects/hcleansing/loader.py	/^    def url2domain(url):$/;"	m	class:Loader
urlparse	projects/hcleansing/loader.py	/^from urlparse import urlparse$/;"	i
DataMover	projects/hcleansing/movedata.py	/^class DataMover(object):$/;"	c
__init__	projects/hcleansing/movedata.py	/^    def __init__(self, ipaddr = '52.198.100.109', username='admin', batch_id='kmzydaily'):$/;"	m	class:DataMover
check_dailydir_exist	projects/hcleansing/movedata.py	/^    def check_dailydir_exist(self):                     # 当日的数据文件夹格式为：kmzydaily-20160909$/;"	m	class:DataMover
datetime	projects/hcleansing/movedata.py	/^import datetime$/;"	i
eg	projects/hcleansing/movedata.py	/^    eg = DataMover()$/;"	v
get_dir_name	projects/hcleansing/movedata.py	/^    def get_dir_name(self, batch_id):$/;"	m	class:DataMover
get_newest_create_time	projects/hcleansing/movedata.py	/^    def get_newest_create_time(self):$/;"	m	class:DataMover
hashlib	projects/hcleansing/movedata.py	/^import hashlib$/;"	i
move_data	projects/hcleansing/movedata.py	/^    def move_data(self):$/;"	m	class:DataMover
os	projects/hcleansing/movedata.py	/^import os$/;"	i
paramiko	projects/hcleansing/movedata.py	/^import paramiko$/;"	i
pytz	projects/hcleansing/movedata.py	/^import pytz$/;"	i
run	projects/hcleansing/movedata.py	/^    def run(self):$/;"	m	class:DataMover
slack	projects/hcleansing/movedata.py	/^from loader import slack$/;"	i
time	projects/hcleansing/movedata.py	/^import time$/;"	i
wait_for_finished	projects/hcleansing/movedata.py	/^    def wait_for_finished(self):$/;"	m	class:DataMover
DuplicateKeyError	projects/hcleansing/news_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
FILE	projects/hcleansing/news_loader.py	/^FILE = '1111.xlsx'$/;"	v
HEADER	projects/hcleansing/news_loader.py	/^HEADER = [ '分类', '实体', 'o1', '日期', '标题', '摘要', '数据源', '数据更新时间', '原文链接' ]$/;"	v
MongoClient	projects/hcleansing/news_loader.py	/^from pymongo import MongoClient$/;"	i
NewsLoader	projects/hcleansing/news_loader.py	/^class NewsLoader(object):$/;"	c
__init__	projects/hcleansing/news_loader.py	/^    def __init__(self):$/;"	m	class:NewsLoader
base	projects/hcleansing/news_loader.py	/^base = date(1900, 1, 1)$/;"	v
date	projects/hcleansing/news_loader.py	/^from datetime import timedelta, date, datetime$/;"	i
datetime	projects/hcleansing/news_loader.py	/^from datetime import timedelta, date, datetime$/;"	i
format_date	projects/hcleansing/news_loader.py	/^    def format_date(sheet):$/;"	m	class:NewsLoader
hashlib	projects/hcleansing/news_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/news_loader.py	/^import json$/;"	i
load_file	projects/hcleansing/news_loader.py	/^    def load_file(self, file):$/;"	m	class:NewsLoader
load_header	projects/hcleansing/news_loader.py	/^    def load_header(self, header):$/;"	m	class:NewsLoader
loader	projects/hcleansing/news_loader.py	/^    loader = NewsLoader()$/;"	v	class:NewsLoader
re	projects/hcleansing/news_loader.py	/^import re$/;"	i
readExcel	projects/hcleansing/news_loader.py	/^from hzlib.libfile import readExcel$/;"	i
save_to_db	projects/hcleansing/news_loader.py	/^    def save_to_db(self):$/;"	m	class:NewsLoader
sys	projects/hcleansing/news_loader.py	/^import sys$/;"	i
timedelta	projects/hcleansing/news_loader.py	/^from datetime import timedelta, date, datetime$/;"	i
url2domain	projects/hcleansing/news_loader.py	/^    def url2domain(url):$/;"	m	class:NewsLoader
urlparse	projects/hcleansing/news_loader.py	/^        from urlparse import urlparse$/;"	i
DuplicateKeyError	projects/hcleansing/qichacha_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/qichacha_loader.py	/^from loader import Loader$/;"	i
MongoClient	projects/hcleansing/qichacha_loader.py	/^from pymongo import MongoClient$/;"	i
QichachaLoader	projects/hcleansing/qichacha_loader.py	/^class QichachaLoader(Loader):$/;"	c
__init__	projects/hcleansing/qichacha_loader.py	/^    def __init__(self):$/;"	m	class:QichachaLoader
datetime	projects/hcleansing/qichacha_loader.py	/^from datetime import datetime$/;"	i
division	projects/hcleansing/qichacha_loader.py	/^from __future__ import print_function, division$/;"	i
generate_rid	projects/hcleansing/qichacha_loader.py	/^        def generate_rid():$/;"	f	function:QichachaLoader.parse_info
generate_rid	projects/hcleansing/qichacha_loader.py	/^        def generate_rid():$/;"	f	function:QichachaLoader.parse_subcompany
hashlib	projects/hcleansing/qichacha_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/qichacha_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/qichacha_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/qichacha_loader.py	/^    obj = QichachaLoader()$/;"	v	class:QichachaLoader
os	projects/hcleansing/qichacha_loader.py	/^import os$/;"	i
parse_alias	projects/hcleansing/qichacha_loader.py	/^    def parse_alias(self, jsn):$/;"	m	class:QichachaLoader
parse_info	projects/hcleansing/qichacha_loader.py	/^    def parse_info(self, jsn):$/;"	m	class:QichachaLoader
parse_subcompany	projects/hcleansing/qichacha_loader.py	/^    def parse_subcompany(self, jsn):$/;"	m	class:QichachaLoader
print_function	projects/hcleansing/qichacha_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/qichacha_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:QichachaLoader
sys	projects/hcleansing/qichacha_loader.py	/^import sys$/;"	i
urllib	projects/hcleansing/qichacha_loader.py	/^import urllib$/;"	i
DuplicateKeyError	projects/hcleansing/shanghaigold_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/shanghaigold_loader.py	/^from loader import Loader$/;"	i
MongoClient	projects/hcleansing/shanghaigold_loader.py	/^from pymongo import MongoClient$/;"	i
ShanghaigoldLoader	projects/hcleansing/shanghaigold_loader.py	/^class ShanghaigoldLoader(Loader):$/;"	c
__init__	projects/hcleansing/shanghaigold_loader.py	/^    def __init__(self):$/;"	m	class:ShanghaigoldLoader
datetime	projects/hcleansing/shanghaigold_loader.py	/^from datetime import datetime$/;"	i
dateutil	projects/hcleansing/shanghaigold_loader.py	/^import dateutil.parser$/;"	i
division	projects/hcleansing/shanghaigold_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/shanghaigold_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/shanghaigold_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/shanghaigold_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/shanghaigold_loader.py	/^    obj = ShanghaigoldLoader()$/;"	v	class:ShanghaigoldLoader
os	projects/hcleansing/shanghaigold_loader.py	/^import os$/;"	i
parse_info	projects/hcleansing/shanghaigold_loader.py	/^    def parse_info(self, jsn):$/;"	m	class:ShanghaigoldLoader
parser	projects/hcleansing/shanghaigold_loader.py	/^import dateutil.parser$/;"	i
print_function	projects/hcleansing/shanghaigold_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/shanghaigold_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:ShanghaigoldLoader
sys	projects/hcleansing/shanghaigold_loader.py	/^import sys$/;"	i
urllib	projects/hcleansing/shanghaigold_loader.py	/^import urllib$/;"	i
DataMover	projects/hcleansing/update_schedule.py	/^from movedata import DataMover$/;"	i
argparse	projects/hcleansing/update_schedule.py	/^import argparse$/;"	i
importlib	projects/hcleansing/update_schedule.py	/^import importlib$/;"	i
main	projects/hcleansing/update_schedule.py	/^def main():$/;"	f
os	projects/hcleansing/update_schedule.py	/^import os$/;"	i
sys	projects/hcleansing/update_schedule.py	/^import sys$/;"	i
DuplicateKeyError	projects/hcleansing/yaodian_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/yaodian_loader.py	/^from loader import Loader$/;"	i
YaodianLoader	projects/hcleansing/yaodian_loader.py	/^class YaodianLoader(Loader):$/;"	c
datetime	projects/hcleansing/yaodian_loader.py	/^from datetime import datetime$/;"	i
division	projects/hcleansing/yaodian_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/yaodian_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/yaodian_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/yaodian_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/yaodian_loader.py	/^    obj = YaodianLoader()$/;"	v	class:YaodianLoader
os	projects/hcleansing/yaodian_loader.py	/^import os$/;"	i
parse	projects/hcleansing/yaodian_loader.py	/^    def parse(self, jsn):$/;"	m	class:YaodianLoader
print_function	projects/hcleansing/yaodian_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/yaodian_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:YaodianLoader
DuplicateKeyError	projects/hcleansing/yaotong_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/yaotong_loader.py	/^from loader import Loader$/;"	i
YaotongLoader	projects/hcleansing/yaotong_loader.py	/^class YaotongLoader(Loader):$/;"	c
datetime	projects/hcleansing/yaotong_loader.py	/^from datetime import datetime$/;"	i
division	projects/hcleansing/yaotong_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/yaotong_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/yaotong_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/yaotong_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/yaotong_loader.py	/^    obj = YaotongLoader()$/;"	v	class:YaotongLoader
os	projects/hcleansing/yaotong_loader.py	/^import os$/;"	i
parse	projects/hcleansing/yaotong_loader.py	/^    def parse(self, jsn):$/;"	m	class:YaotongLoader
print_function	projects/hcleansing/yaotong_loader.py	/^from __future__ import print_function, division$/;"	i
read_jsn	projects/hcleansing/yaotong_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:YaotongLoader
sys	projects/hcleansing/yaotong_loader.py	/^import sys$/;"	i
DuplicateKeyError	projects/hcleansing/yaotongnewdaily_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/yaotongnewdaily_loader.py	/^from loader import Loader$/;"	i
YaotongnewdailyLoader	projects/hcleansing/yaotongnewdaily_loader.py	/^class YaotongnewdailyLoader(Loader):$/;"	c
datetime	projects/hcleansing/yaotongnewdaily_loader.py	/^from datetime import datetime$/;"	i
hashlib	projects/hcleansing/yaotongnewdaily_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/yaotongnewdaily_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/yaotongnewdaily_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/yaotongnewdaily_loader.py	/^    obj = YaotongnewdailyLoader()$/;"	v	class:YaotongnewdailyLoader
os	projects/hcleansing/yaotongnewdaily_loader.py	/^import os$/;"	i
parse	projects/hcleansing/yaotongnewdaily_loader.py	/^    def parse(self, jsn):$/;"	m	class:YaotongnewdailyLoader
read_jsn	projects/hcleansing/yaotongnewdaily_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:YaotongnewdailyLoader
sys	projects/hcleansing/yaotongnewdaily_loader.py	/^import sys$/;"	i
DuplicateKeyError	projects/hcleansing/zysj_loader.py	/^from pymongo.errors import DuplicateKeyError$/;"	i
Loader	projects/hcleansing/zysj_loader.py	/^from loader import Loader$/;"	i
ZysjLoader	projects/hcleansing/zysj_loader.py	/^class ZysjLoader(Loader):$/;"	c
datetime	projects/hcleansing/zysj_loader.py	/^from datetime import datetime$/;"	i
deal_with_alias	projects/hcleansing/zysj_loader.py	/^def deal_with_alias(name, content):  # 处理别名字符串，返回别名列表$/;"	f
division	projects/hcleansing/zysj_loader.py	/^from __future__ import print_function, division$/;"	i
hashlib	projects/hcleansing/zysj_loader.py	/^import hashlib$/;"	i
json	projects/hcleansing/zysj_loader.py	/^import json$/;"	i
libfile	projects/hcleansing/zysj_loader.py	/^from hzlib import libfile$/;"	i
obj	projects/hcleansing/zysj_loader.py	/^    obj = ZysjLoader()$/;"	v	class:ZysjLoader
os	projects/hcleansing/zysj_loader.py	/^import os$/;"	i
parse	projects/hcleansing/zysj_loader.py	/^    def parse(self, jsn):$/;"	m	class:ZysjLoader
print_function	projects/hcleansing/zysj_loader.py	/^from __future__ import print_function, division$/;"	i
re	projects/hcleansing/zysj_loader.py	/^import re$/;"	i
read_jsn	projects/hcleansing/zysj_loader.py	/^    def read_jsn(self, data_dir):$/;"	m	class:ZysjLoader
sys	projects/hcleansing/zysj_loader.py	/^import sys$/;"	i
admin	projects/hcrawler/dataapi/admin.py	/^from django.contrib import admin$/;"	i
AppConfig	projects/hcrawler/dataapi/apps.py	/^from django.apps import AppConfig$/;"	i
DataapiConfig	projects/hcrawler/dataapi/apps.py	/^class DataapiConfig(AppConfig):$/;"	c
name	projects/hcrawler/dataapi/apps.py	/^    name = 'dataapi'$/;"	v	class:DataapiConfig
unicode_literals	projects/hcrawler/dataapi/apps.py	/^from __future__ import unicode_literals$/;"	i
Abnormals	projects/hcrawler/dataapi/hcrawler_models.py	/^class Abnormals(EmbeddedDocument):$/;"	c
Branches	projects/hcrawler/dataapi/hcrawler_models.py	/^class Branches(EmbeddedDocument):$/;"	c
Changes	projects/hcrawler/dataapi/hcrawler_models.py	/^class Changes(EmbeddedDocument): $/;"	c
CompanyInfo	projects/hcrawler/dataapi/hcrawler_models.py	/^class CompanyInfo(EmbeddedDocument):$/;"	c
Confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^class Confidence(Document):$/;"	c
Executives	projects/hcrawler/dataapi/hcrawler_models.py	/^class Executives(EmbeddedDocument):$/;"	c
GmpInfo	projects/hcrawler/dataapi/hcrawler_models.py	/^class GmpInfo(EmbeddedDocument):$/;"	c
Hentity	projects/hcrawler/dataapi/hcrawler_models.py	/^class Hentity(Document):$/;"	c
Hmaterial	projects/hcrawler/dataapi/hcrawler_models.py	/^class Hmaterial(Document):$/;"	c
Hprice	projects/hcrawler/dataapi/hcrawler_models.py	/^class Hprice(Document):$/;"	c
MedicinesInfo	projects/hcrawler/dataapi/hcrawler_models.py	/^class MedicinesInfo(EmbeddedDocument):$/;"	c
News	projects/hcrawler/dataapi/hcrawler_models.py	/^class News(Document):$/;"	c
ProductionCapacity	projects/hcrawler/dataapi/hcrawler_models.py	/^class ProductionCapacity(Document):$/;"	c
Purchase	projects/hcrawler/dataapi/hcrawler_models.py	/^class Purchase(Document):$/;"	c
Shareholders	projects/hcrawler/dataapi/hcrawler_models.py	/^class Shareholders(EmbeddedDocument):$/;"	c
Supplier	projects/hcrawler/dataapi/hcrawler_models.py	/^class Supplier(Document):$/;"	c
abnormals	projects/hcrawler/dataapi/hcrawler_models.py	/^    abnormals = ListField(EmbeddedDocumentField(Abnormals))$/;"	v	class:Supplier
actual_money	projects/hcrawler/dataapi/hcrawler_models.py	/^    actual_money = StringField()$/;"	v	class:Shareholders
actual_time	projects/hcrawler/dataapi/hcrawler_models.py	/^    actual_time = StringField()$/;"	v	class:Shareholders
address	projects/hcrawler/dataapi/hcrawler_models.py	/^    address = StringField()$/;"	v	class:Supplier
after_change	projects/hcrawler/dataapi/hcrawler_models.py	/^    after_change = StringField()$/;"	v	class:Changes
alias	projects/hcrawler/dataapi/hcrawler_models.py	/^    alias = ListField(StringField()) # 别名$/;"	v	class:Hentity
alias_editor	projects/hcrawler/dataapi/hcrawler_models.py	/^    alias_editor = ListField(StringField()) # 人工编辑别名$/;"	v	class:Hentity
approval_date	projects/hcrawler/dataapi/hcrawler_models.py	/^    approval_date = StringField()$/;"	v	class:Supplier
before_change	projects/hcrawler/dataapi/hcrawler_models.py	/^    before_change = StringField()$/;"	v	class:Changes
begin	projects/hcrawler/dataapi/hcrawler_models.py	/^    begin = StringField()$/;"	v	class:Supplier
begin_date	projects/hcrawler/dataapi/hcrawler_models.py	/^    begin_date = DateTimeField()$/;"	v	class:GmpInfo
branches	projects/hcrawler/dataapi/hcrawler_models.py	/^    branches = ListField(EmbeddedDocumentField(Branches))$/;"	v	class:Supplier
business_scope	projects/hcrawler/dataapi/hcrawler_models.py	/^    business_scope = StringField()$/;"	v	class:Supplier
business_type	projects/hcrawler/dataapi/hcrawler_models.py	/^    business_type = StringField()$/;"	v	class:Supplier
category	projects/hcrawler/dataapi/hcrawler_models.py	/^    category = StringField() # 分类$/;"	v	class:Hmaterial
cellphone	projects/hcrawler/dataapi/hcrawler_models.py	/^    cellphone = StringField()$/;"	v	class:CompanyInfo
certification_number	projects/hcrawler/dataapi/hcrawler_models.py	/^    certification_number = StringField()$/;"	v	class:GmpInfo
certification_version	projects/hcrawler/dataapi/hcrawler_models.py	/^    certification_version = StringField()$/;"	v	class:GmpInfo
change_time	projects/hcrawler/dataapi/hcrawler_models.py	/^    change_time = StringField()$/;"	v	class:Changes
changes	projects/hcrawler/dataapi/hcrawler_models.py	/^    changes = ListField(EmbeddedDocumentField(Changes))$/;"	v	class:Supplier
company_info	projects/hcrawler/dataapi/hcrawler_models.py	/^    company_info = EmbeddedDocumentField(CompanyInfo)$/;"	v	class:Supplier
company_name	projects/hcrawler/dataapi/hcrawler_models.py	/^    company_name = StringField()$/;"	v	class:Supplier
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Confidence
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Hmaterial
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Hprice
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:News
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Purchase
confidence	projects/hcrawler/dataapi/hcrawler_models.py	/^    confidence = StringField()$/;"	v	class:Supplier
contects	projects/hcrawler/dataapi/hcrawler_models.py	/^    contects = StringField()$/;"	v	class:CompanyInfo
content	projects/hcrawler/dataapi/hcrawler_models.py	/^    content = StringField() # 内容$/;"	v	class:News
cooperationIntention	projects/hcrawler/dataapi/hcrawler_models.py	/^    cooperationIntention = StringField() # 合作意向$/;"	v	class:CompanyInfo
createdTime	projects/hcrawler/dataapi/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Hmaterial
createdTime	projects/hcrawler/dataapi/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Hprice
createdTime	projects/hcrawler/dataapi/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:News
createdTime	projects/hcrawler/dataapi/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Purchase
createdTime	projects/hcrawler/dataapi/hcrawler_models.py	/^    createdTime = DateTimeField(default=datetime.now)$/;"	v	class:Supplier
date	projects/hcrawler/dataapi/hcrawler_models.py	/^    date = StringField()$/;"	v	class:Abnormals
datetime	projects/hcrawler/dataapi/hcrawler_models.py	/^from datetime import datetime$/;"	i
description	projects/hcrawler/dataapi/hcrawler_models.py	/^    description = StringField() # 描述$/;"	v	class:Hmaterial
description	projects/hcrawler/dataapi/hcrawler_models.py	/^    description = StringField()$/;"	v	class:Hentity
description	projects/hcrawler/dataapi/hcrawler_models.py	/^    description = StringField()$/;"	v	class:Hprice
division	projects/hcrawler/dataapi/hcrawler_models.py	/^from __future__ import print_function, division$/;"	i
downstream_material	projects/hcrawler/dataapi/hcrawler_models.py	/^    downstream_material = ListField(StringField()) # 下游产品$/;"	v	class:Hmaterial
drug_form	projects/hcrawler/dataapi/hcrawler_models.py	/^    drug_form = StringField() # 剂型$/;"	v	class:Hmaterial
email	projects/hcrawler/dataapi/hcrawler_models.py	/^    email = StringField()$/;"	v	class:CompanyInfo
end	projects/hcrawler/dataapi/hcrawler_models.py	/^    end = StringField()$/;"	v	class:Supplier
end_date	projects/hcrawler/dataapi/hcrawler_models.py	/^    end_date = DateTimeField()$/;"	v	class:GmpInfo
end_date	projects/hcrawler/dataapi/hcrawler_models.py	/^    end_date = StringField()$/;"	v	class:Abnormals
end_reason	projects/hcrawler/dataapi/hcrawler_models.py	/^    end_reason = StringField()$/;"	v	class:Abnormals
establish_date	projects/hcrawler/dataapi/hcrawler_models.py	/^    establish_date = StringField()$/;"	v	class:Supplier
executives	projects/hcrawler/dataapi/hcrawler_models.py	/^    executives = ListField(EmbeddedDocumentField(Executives))$/;"	v	class:Supplier
fax	projects/hcrawler/dataapi/hcrawler_models.py	/^    fax = StringField()$/;"	v	class:CompanyInfo
gmp_info	projects/hcrawler/dataapi/hcrawler_models.py	/^    gmp_info = ListField(EmbeddedDocumentField(GmpInfo))$/;"	v	class:Supplier
legal_person	projects/hcrawler/dataapi/hcrawler_models.py	/^    legal_person = StringField()$/;"	v	class:Supplier
license_data	projects/hcrawler/dataapi/hcrawler_models.py	/^    license_data = StringField()$/;"	v	class:MedicinesInfo
license_number	projects/hcrawler/dataapi/hcrawler_models.py	/^    license_number = StringField()$/;"	v	class:MedicinesInfo
link	projects/hcrawler/dataapi/hcrawler_models.py	/^    link = StringField()$/;"	v	class:Branches
mainEntityOfPage	projects/hcrawler/dataapi/hcrawler_models.py	/^    mainEntityOfPage = StringField() # 实体$/;"	v	class:Hmaterial
mainEntityOfPage	projects/hcrawler/dataapi/hcrawler_models.py	/^    mainEntityOfPage = StringField() # 实体$/;"	v	class:Hprice
mainEntityOfPage	projects/hcrawler/dataapi/hcrawler_models.py	/^    mainEntityOfPage = StringField()$/;"	v	class:Purchase
maxPrice	projects/hcrawler/dataapi/hcrawler_models.py	/^    maxPrice = StringField() # 价格最大值$/;"	v	class:Hprice
medicines_info	projects/hcrawler/dataapi/hcrawler_models.py	/^    medicines_info = ListField(EmbeddedDocumentField(MedicinesInfo))$/;"	v	class:Supplier
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:Hentity
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:Hmaterial
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:Hprice
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:News
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:Purchase
meta	projects/hcrawler/dataapi/hcrawler_models.py	/^    meta = {$/;"	v	class:Supplier
minPrice	projects/hcrawler/dataapi/hcrawler_models.py	/^    minPrice = StringField() # 价格最小值$/;"	v	class:Hprice
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField() # 名字，爬到的名字$/;"	v	class:Hmaterial
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Branches
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Executives
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Hprice
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Purchase
name	projects/hcrawler/dataapi/hcrawler_models.py	/^    name = StringField()$/;"	v	class:Shareholders
nid	projects/hcrawler/dataapi/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hentity
nid	projects/hcrawler/dataapi/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hmaterial
nid	projects/hcrawler/dataapi/hcrawler_models.py	/^    nid = StringField()$/;"	v	class:Hprice
ns	projects/hcrawler/dataapi/hcrawler_models.py	/^    ns = StringField() # namespace$/;"	v	class:Hentity
orderDate	projects/hcrawler/dataapi/hcrawler_models.py	/^    orderDate = StringField()$/;"	v	class:Purchase
orderNumber	projects/hcrawler/dataapi/hcrawler_models.py	/^    orderNumber = StringField() # 总量$/;"	v	class:Purchase
organization_code	projects/hcrawler/dataapi/hcrawler_models.py	/^    organization_code = StringField()$/;"	v	class:Supplier
organs	projects/hcrawler/dataapi/hcrawler_models.py	/^    organs = StringField()$/;"	v	class:Abnormals
paymentMethod	projects/hcrawler/dataapi/hcrawler_models.py	/^    paymentMethod = StringField() # 付款方式$/;"	v	class:CompanyInfo
paymentMethod	projects/hcrawler/dataapi/hcrawler_models.py	/^    paymentMethod = StringField() # 付款方式$/;"	v	class:Purchase
plant_area	projects/hcrawler/dataapi/hcrawler_models.py	/^    plant_area = StringField() # 种植面积$/;"	v	class:ProductionCapacity
position	projects/hcrawler/dataapi/hcrawler_models.py	/^    position = StringField()$/;"	v	class:Executives
price	projects/hcrawler/dataapi/hcrawler_models.py	/^    price = StringField()$/;"	v	class:Hprice
price	projects/hcrawler/dataapi/hcrawler_models.py	/^    price = StringField()$/;"	v	class:Purchase
priceCurrency	projects/hcrawler/dataapi/hcrawler_models.py	/^    priceCurrency = StringField() # 报价币种$/;"	v	class:Hprice
priceCurrency	projects/hcrawler/dataapi/hcrawler_models.py	/^    priceCurrency = StringField() # 报价币种$/;"	v	class:Purchase
priceType	projects/hcrawler/dataapi/hcrawler_models.py	/^    priceType = StringField() # 价格类型，比如：车皮价$/;"	v	class:Hprice
priceType	projects/hcrawler/dataapi/hcrawler_models.py	/^    priceType = StringField() # 价格类型，比如：车皮价$/;"	v	class:Purchase
print_function	projects/hcrawler/dataapi/hcrawler_models.py	/^from __future__ import print_function, division$/;"	i
productGrade	projects/hcrawler/dataapi/hcrawler_models.py	/^    productGrade = StringField() # 商品等级$/;"	v	class:Hprice
productGrade	projects/hcrawler/dataapi/hcrawler_models.py	/^    productGrade = StringField() # 商品等级$/;"	v	class:Purchase
productPlaceOfOrigin	projects/hcrawler/dataapi/hcrawler_models.py	/^    productPlaceOfOrigin = StringField() # 商品产地$/;"	v	class:Hprice
productPlaceOfOrigin	projects/hcrawler/dataapi/hcrawler_models.py	/^    productPlaceOfOrigin = StringField() # 商品产地$/;"	v	class:ProductionCapacity
productSpecification	projects/hcrawler/dataapi/hcrawler_models.py	/^    productSpecification = StringField() # 商品说明$/;"	v	class:Hprice
productionYear	projects/hcrawler/dataapi/hcrawler_models.py	/^    productionYear = StringField() # 生产日期$/;"	v	class:Hprice
project	projects/hcrawler/dataapi/hcrawler_models.py	/^    project = StringField()$/;"	v	class:Changes
properties	projects/hcrawler/dataapi/hcrawler_models.py	/^    properties = DictField(default=None) # 属性$/;"	v	class:Hmaterial
properties	projects/hcrawler/dataapi/hcrawler_models.py	/^    properties = DictField(default=None) # 属性$/;"	v	class:Hprice
province	projects/hcrawler/dataapi/hcrawler_models.py	/^    province = StringField()$/;"	v	class:GmpInfo
pubdate	projects/hcrawler/dataapi/hcrawler_models.py	/^    pubdate = DateTimeField()$/;"	v	class:News
reason	projects/hcrawler/dataapi/hcrawler_models.py	/^    reason = StringField()$/;"	v	class:Abnormals
registered_capital	projects/hcrawler/dataapi/hcrawler_models.py	/^    registered_capital = StringField()$/;"	v	class:Supplier
registration_authority	projects/hcrawler/dataapi/hcrawler_models.py	/^    registration_authority = StringField()$/;"	v	class:Supplier
registration_id	projects/hcrawler/dataapi/hcrawler_models.py	/^    registration_id = StringField()$/;"	v	class:Supplier
role	projects/hcrawler/dataapi/hcrawler_models.py	/^    role = StringField()$/;"	v	class:Shareholders
s_label	projects/hcrawler/dataapi/hcrawler_models.py	/^    s_label = StringField() # name$/;"	v	class:Hentity
s_rank	projects/hcrawler/dataapi/hcrawler_models.py	/^    s_rank = StringField() # 搜索结果数$/;"	v	class:Hentity
sameas	projects/hcrawler/dataapi/hcrawler_models.py	/^    sameas = ListField(StringField()) # 实体链接$/;"	v	class:Hentity
scope_of_certification	projects/hcrawler/dataapi/hcrawler_models.py	/^    scope_of_certification = StringField()$/;"	v	class:GmpInfo
seller	projects/hcrawler/dataapi/hcrawler_models.py	/^    seller = StringField() # 销售商$/;"	v	class:Hprice
sellerMarket	projects/hcrawler/dataapi/hcrawler_models.py	/^    sellerMarket = StringField() # 卖场$/;"	v	class:Hprice
shareholders	projects/hcrawler/dataapi/hcrawler_models.py	/^    shareholders = ListField(EmbeddedDocumentField(Shareholders))$/;"	v	class:Supplier
shipping	projects/hcrawler/dataapi/hcrawler_models.py	/^    shipping = StringField() # 运输方式$/;"	v	class:Purchase
shippingFee	projects/hcrawler/dataapi/hcrawler_models.py	/^    shippingFee = StringField() # 运输费用$/;"	v	class:CompanyInfo
shippingFee	projects/hcrawler/dataapi/hcrawler_models.py	/^    shippingFee = StringField() # 运输费用$/;"	v	class:Purchase
site	projects/hcrawler/dataapi/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Hmaterial
site	projects/hcrawler/dataapi/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Hprice
site	projects/hcrawler/dataapi/hcrawler_models.py	/^    site = StringField()$/;"	v	class:News
site	projects/hcrawler/dataapi/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Purchase
site	projects/hcrawler/dataapi/hcrawler_models.py	/^    site = StringField()$/;"	v	class:Supplier
source	projects/hcrawler/dataapi/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Hmaterial
source	projects/hcrawler/dataapi/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Hprice
source	projects/hcrawler/dataapi/hcrawler_models.py	/^    source = StringField()$/;"	v	class:News
source	projects/hcrawler/dataapi/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Purchase
source	projects/hcrawler/dataapi/hcrawler_models.py	/^    source = StringField()$/;"	v	class:Supplier
specification	projects/hcrawler/dataapi/hcrawler_models.py	/^    specification = StringField()$/;"	v	class:MedicinesInfo
standard_code	projects/hcrawler/dataapi/hcrawler_models.py	/^    standard_code = StringField()$/;"	v	class:MedicinesInfo
standard_code_remark	projects/hcrawler/dataapi/hcrawler_models.py	/^    standard_code_remark = StringField()$/;"	v	class:MedicinesInfo
status	projects/hcrawler/dataapi/hcrawler_models.py	/^    status = StringField()$/;"	v	class:Supplier
storageMode	projects/hcrawler/dataapi/hcrawler_models.py	/^    storageMode = StringField() # 仓促方式$/;"	v	class:Purchase
subscribe_money	projects/hcrawler/dataapi/hcrawler_models.py	/^    subscribe_money = StringField()$/;"	v	class:Shareholders
subscribe_time	projects/hcrawler/dataapi/hcrawler_models.py	/^    subscribe_time = StringField()$/;"	v	class:Shareholders
supplier	projects/hcrawler/dataapi/hcrawler_models.py	/^    supplier = ReferenceField(Supplier)$/;"	v	class:ProductionCapacity
supplierGrade	projects/hcrawler/dataapi/hcrawler_models.py	/^    supplierGrade = StringField() # 供应商评级$/;"	v	class:CompanyInfo
telephone	projects/hcrawler/dataapi/hcrawler_models.py	/^    telephone = StringField()$/;"	v	class:CompanyInfo
title	projects/hcrawler/dataapi/hcrawler_models.py	/^    title = StringField()  # 标题$/;"	v	class:News
totalPrice	projects/hcrawler/dataapi/hcrawler_models.py	/^    totalPrice = StringField() # 总价$/;"	v	class:Purchase
turnout	projects/hcrawler/dataapi/hcrawler_models.py	/^    turnout = StringField() # 产量$/;"	v	class:ProductionCapacity
unified_social_credit_code	projects/hcrawler/dataapi/hcrawler_models.py	/^    unified_social_credit_code = StringField()$/;"	v	class:Supplier
unitText	projects/hcrawler/dataapi/hcrawler_models.py	/^    unitText = StringField() # 价格单位，比如：元\/吨$/;"	v	class:Hprice
unitText	projects/hcrawler/dataapi/hcrawler_models.py	/^    unitText = StringField() # 价格单位，比如：元\/吨$/;"	v	class:Purchase
upstream_material	projects/hcrawler/dataapi/hcrawler_models.py	/^    upstream_material = ListField(StringField()) # 上游产品$/;"	v	class:Hmaterial
validDate	projects/hcrawler/dataapi/hcrawler_models.py	/^    validDate = StringField() # 产能年份$/;"	v	class:ProductionCapacity
validDate	projects/hcrawler/dataapi/hcrawler_models.py	/^    validDate = StringField() # 报价日期$/;"	v	class:Hprice
validFrom	projects/hcrawler/dataapi/hcrawler_models.py	/^    validFrom = StringField()$/;"	v	class:ProductionCapacity
validFrom	projects/hcrawler/dataapi/hcrawler_models.py	/^    validFrom = StringField()$/;"	v	class:Purchase
validThrough	projects/hcrawler/dataapi/hcrawler_models.py	/^    validThrough = StringField()$/;"	v	class:ProductionCapacity
validThrough	projects/hcrawler/dataapi/hcrawler_models.py	/^    validThrough = StringField()$/;"	v	class:Purchase
website	projects/hcrawler/dataapi/hcrawler_models.py	/^    website = StringField()$/;"	v	class:CompanyInfo
website	projects/hcrawler/dataapi/hcrawler_models.py	/^    website = StringField()$/;"	v	class:Confidence
models	projects/hcrawler/dataapi/models.py	/^from django.db import models$/;"	i
unicode_literals	projects/hcrawler/dataapi/models.py	/^from __future__ import unicode_literals$/;"	i
DocumentSerializer	projects/hcrawler/dataapi/serializers.py	/^from rest_framework_mongoengine.serializers import DocumentSerializer$/;"	i
Hentity	projects/hcrawler/dataapi/serializers.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
Hmaterial	projects/hcrawler/dataapi/serializers.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
HmaterialSerializer	projects/hcrawler/dataapi/serializers.py	/^class HmaterialSerializer(DocumentSerializer):$/;"	c
Hprice	projects/hcrawler/dataapi/serializers.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
HpriceSerializer	projects/hcrawler/dataapi/serializers.py	/^class HpriceSerializer(DocumentSerializer):$/;"	c
Meta	projects/hcrawler/dataapi/serializers.py	/^    class Meta:$/;"	c	class:HmaterialSerializer
Meta	projects/hcrawler/dataapi/serializers.py	/^    class Meta:$/;"	c	class:HpriceSerializer
fields	projects/hcrawler/dataapi/serializers.py	/^        fields = ('name', 'price', 'validDate', 'sellerMarket', 'source', 'site')$/;"	v	class:HpriceSerializer.Meta
model	projects/hcrawler/dataapi/serializers.py	/^        model = Hmaterial$/;"	v	class:HmaterialSerializer.Meta
model	projects/hcrawler/dataapi/serializers.py	/^        model = Hprice$/;"	v	class:HpriceSerializer.Meta
TestCase	projects/hcrawler/dataapi/tests.py	/^from django.test import TestCase$/;"	i
Hentity	projects/hcrawler/dataapi/views.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
Hmaterial	projects/hcrawler/dataapi/views.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
HmaterialSerializer	projects/hcrawler/dataapi/views.py	/^from serializers import HpriceSerializer, HmaterialSerializer$/;"	i
Hprice	projects/hcrawler/dataapi/views.py	/^from hcrawler_models import Hentity, Hprice, Hmaterial$/;"	i
HpriceSerializer	projects/hcrawler/dataapi/views.py	/^from serializers import HpriceSerializer, HmaterialSerializer$/;"	i
JsonResponse	projects/hcrawler/dataapi/views.py	/^from django.http import JsonResponse$/;"	i
Response	projects/hcrawler/dataapi/views.py	/^from rest_framework.response import Response$/;"	i
api_view	projects/hcrawler/dataapi/views.py	/^from rest_framework.decorators import api_view$/;"	i
hprice	projects/hcrawler/dataapi/views.py	/^def hprice(request, name):$/;"	f
render	projects/hcrawler/dataapi/views.py	/^from django.shortcuts import render$/;"	i
updownstream	projects/hcrawler/dataapi/views.py	/^def updownstream(request, name):$/;"	f
ALLOWED_HOSTS	projects/hcrawler/hcrawler/settings.py	/^ALLOWED_HOSTS = []$/;"	v
AUTHENTICATION_BACKENDS	projects/hcrawler/hcrawler/settings.py	/^AUTHENTICATION_BACKENDS = ($/;"	v
AUTH_PASSWORD_VALIDATORS	projects/hcrawler/hcrawler/settings.py	/^AUTH_PASSWORD_VALIDATORS = [$/;"	v
BASE_DIR	projects/hcrawler/hcrawler/settings.py	/^BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))$/;"	v
DATABASES	projects/hcrawler/hcrawler/settings.py	/^DATABASES = {$/;"	v
DEBUG	projects/hcrawler/hcrawler/settings.py	/^DEBUG = True$/;"	v
INSTALLED_APPS	projects/hcrawler/hcrawler/settings.py	/^INSTALLED_APPS = [$/;"	v
LANGUAGE_CODE	projects/hcrawler/hcrawler/settings.py	/^LANGUAGE_CODE = 'en-us'$/;"	v
MIDDLEWARE	projects/hcrawler/hcrawler/settings.py	/^MIDDLEWARE = [$/;"	v
ROOT_URLCONF	projects/hcrawler/hcrawler/settings.py	/^ROOT_URLCONF = 'hcrawler.urls'$/;"	v
STATIC_URL	projects/hcrawler/hcrawler/settings.py	/^STATIC_URL = '\/static\/'$/;"	v
TEMPLATES	projects/hcrawler/hcrawler/settings.py	/^TEMPLATES = [$/;"	v
TIME_ZONE	projects/hcrawler/hcrawler/settings.py	/^TIME_ZONE = 'UTC'$/;"	v
USE_I18N	projects/hcrawler/hcrawler/settings.py	/^USE_I18N = True$/;"	v
USE_L10N	projects/hcrawler/hcrawler/settings.py	/^USE_L10N = True$/;"	v
USE_TZ	projects/hcrawler/hcrawler/settings.py	/^USE_TZ = True$/;"	v
WSGI_APPLICATION	projects/hcrawler/hcrawler/settings.py	/^WSGI_APPLICATION = 'hcrawler.wsgi.application'$/;"	v
_MONGODB_DATABASE_HOST	projects/hcrawler/hcrawler/settings.py	/^_MONGODB_DATABASE_HOST = 'mongodb:\/\/{}\/{}'.format(_MONGODB_HOST, _MONGODB_NAME)$/;"	v
_MONGODB_HOST	projects/hcrawler/hcrawler/settings.py	/^_MONGODB_HOST = 'localhost:27017'$/;"	v
_MONGODB_NAME	projects/hcrawler/hcrawler/settings.py	/^_MONGODB_NAME = 'hcrawler'$/;"	v
_MONGODB_PW	projects/hcrawler/hcrawler/settings.py	/^_MONGODB_PW = 'f#d1p9c'$/;"	v
_MONGODB_USER	projects/hcrawler/hcrawler/settings.py	/^_MONGODB_USER = 'hcrawler'$/;"	v
mongoengine	projects/hcrawler/hcrawler/settings.py	/^import mongoengine$/;"	i
os	projects/hcrawler/hcrawler/settings.py	/^import os$/;"	i
admin	projects/hcrawler/hcrawler/urls.py	/^from django.contrib import admin$/;"	i
sys	projects/hcrawler/hcrawler/urls.py	/^import sys$/;"	i
url	projects/hcrawler/hcrawler/urls.py	/^from django.conf.urls import url$/;"	i
urlpatterns	projects/hcrawler/hcrawler/urls.py	/^urlpatterns = [$/;"	v
views	projects/hcrawler/hcrawler/urls.py	/^from dataapi import views$/;"	i
application	projects/hcrawler/hcrawler/wsgi.py	/^application = get_wsgi_application()$/;"	v
get_wsgi_application	projects/hcrawler/hcrawler/wsgi.py	/^from django.core.wsgi import get_wsgi_application$/;"	i
os	projects/hcrawler/hcrawler/wsgi.py	/^import os$/;"	i
django	projects/hcrawler/manage.py	/^            import django$/;"	i
execute_from_command_line	projects/hcrawler/manage.py	/^        from django.core.management import execute_from_command_line$/;"	i
os	projects/hcrawler/manage.py	/^import os$/;"	i
sys	projects/hcrawler/manage.py	/^import sys$/;"	i
Cache	projects/kuwo/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/kuwo/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/kuwo/downloader/cache.py	/^import base64$/;"	i
division	projects/kuwo/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/kuwo/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/kuwo/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/kuwo/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/kuwo/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/kuwo/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/kuwo/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/kuwo/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/kuwo/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/kuwo/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/kuwo/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/kuwo/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/kuwo/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/kuwo/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/kuwo/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/kuwo/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/kuwo/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/kuwo/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/kuwo/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/kuwo/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/kuwo/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/kuwo/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/kuwo/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/kuwo/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/kuwo/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/kuwo/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/kuwo/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/kuwo/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/kuwo/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/kuwo/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/kuwo/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/kuwo/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/kuwo/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/kuwo/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/kuwo/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/kuwo/downloader/downloader.py	/^import os$/;"	i
print_function	projects/kuwo/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/kuwo/downloader/downloader.py	/^import re$/;"	i
request_download	projects/kuwo/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/kuwo/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/kuwo/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/kuwo/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/kuwo/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/kuwo/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/kuwo/downloader/downloader.py	/^import sys$/;"	i
time	projects/kuwo/downloader/downloader.py	/^import time$/;"	i
update_header	projects/kuwo/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/kuwo/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/kuwo/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/kuwo/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/kuwo/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/kuwo/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/kuwo/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/kuwo/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/kuwo/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/kuwo/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/kuwo/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/kuwo/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/kuwo/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/kuwo/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/kuwo/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/kuwo/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/kuwo/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/kuwo/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/kuwo/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/kuwo/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/kuwo/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/kuwo/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/kuwo/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/kuwo/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/kuwo/downloader/test_download.py	/^import datetime$/;"	i
json	projects/kuwo/downloader/test_download.py	/^import json$/;"	i
main	projects/kuwo/downloader/test_download.py	/^def main():$/;"	f
os	projects/kuwo/downloader/test_download.py	/^import os$/;"	i
re	projects/kuwo/downloader/test_download.py	/^import re$/;"	i
requests	projects/kuwo/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/kuwo/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/kuwo/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/kuwo/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/kuwo/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/kuwo/downloader/test_download.py	/^import time$/;"	i
urllib	projects/kuwo/downloader/test_download.py	/^import urllib$/;"	i
AlbumItem	projects/kuwo/kuwo/items.py	/^class AlbumItem(scrapy.Item):      #artist's album$/;"	c
ArtistInfoItem	projects/kuwo/kuwo/items.py	/^class ArtistInfoItem(scrapy.Item):    #artist information, some text $/;"	c
ArtistItem	projects/kuwo/kuwo/items.py	/^class ArtistItem(scrapy.Item):     #artist $/;"	c
KuwoItem	projects/kuwo/kuwo/items.py	/^class KuwoItem(scrapy.Item):$/;"	c
MusicCatItem	projects/kuwo/kuwo/items.py	/^class MusicCatItem(scrapy.Item):   #music from user's playlist$/;"	c
MusicInfoItem	projects/kuwo/kuwo/items.py	/^class MusicInfoItem(scrapy.Item):     #music information, lick lrc$/;"	c
MusicItem	projects/kuwo/kuwo/items.py	/^class MusicItem(scrapy.Item):      #music from artist$/;"	c
PlaylistItem	projects/kuwo/kuwo/items.py	/^class PlaylistItem(scrapy.Item):   #user's playlist$/;"	c
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:AlbumItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:ArtistInfoItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:ArtistItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:MusicCatItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:MusicInfoItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:MusicItem
content	projects/kuwo/kuwo/items.py	/^    content = scrapy.Field()$/;"	v	class:PlaylistItem
scrapy	projects/kuwo/kuwo/items.py	/^import scrapy$/;"	i
BATCH_ID	projects/kuwo/kuwo/middlewares.py	/^BATCH_ID = 'kuwo-20160706'$/;"	v
DownloadWrapper	projects/kuwo/kuwo/middlewares.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
MyMiddleWare	projects/kuwo/kuwo/middlewares.py	/^class MyMiddleWare(object):$/;"	c
SERVER	projects/kuwo/kuwo/middlewares.py	/^SERVER='http:\/\/192.168.1.179:8000\/'$/;"	v
f	projects/kuwo/kuwo/middlewares.py	/^f = open("\/home\/wl\/lostpn.txt","a")  #记录缺失结果的url$/;"	v
m	projects/kuwo/kuwo/middlewares.py	/^m = DownloadWrapper(SERVER)$/;"	v
process_request	projects/kuwo/kuwo/middlewares.py	/^    def process_request(self, request,  spider):$/;"	m	class:MyMiddleWare
scrapy	projects/kuwo/kuwo/middlewares.py	/^import scrapy$/;"	i
sys	projects/kuwo/kuwo/middlewares.py	/^import sys$/;"	i
AlbumItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
ArtistInfoItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
ArtistItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
KuwoPipeline	projects/kuwo/kuwo/pipelines.py	/^class KuwoPipeline(object):$/;"	c
MusicCatItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
MusicInfoItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
MusicItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
PlaylistItem	projects/kuwo/kuwo/pipelines.py	/^from kuwo.items import MusicCatItem, PlaylistItem, MusicItem, AlbumItem, ArtistItem, MusicInfoItem,ArtistInfoItem$/;"	i
__init__	projects/kuwo/kuwo/pipelines.py	/^    def __init__(self):$/;"	m	class:KuwoPipeline
codecs	projects/kuwo/kuwo/pipelines.py	/^import codecs$/;"	i
process_item	projects/kuwo/kuwo/pipelines.py	/^    def process_item(self, item, spider):$/;"	m	class:KuwoPipeline
BOT_NAME	projects/kuwo/kuwo/settings.py	/^BOT_NAME = 'kuwo'$/;"	v
DOWNLOADER_MIDDLEWARES	projects/kuwo/kuwo/settings.py	/^DOWNLOADER_MIDDLEWARES = {$/;"	v
ITEM_PIPELINES	projects/kuwo/kuwo/settings.py	/^ITEM_PIPELINES = {$/;"	v
NEWSPIDER_MODULE	projects/kuwo/kuwo/settings.py	/^NEWSPIDER_MODULE = 'kuwo.spiders'$/;"	v
ROBOTSTXT_OBEY	projects/kuwo/kuwo/settings.py	/^ROBOTSTXT_OBEY = True$/;"	v
SPIDER_MODULES	projects/kuwo/kuwo/settings.py	/^SPIDER_MODULES = ['kuwo.spiders']$/;"	v
ArtistInfoItem	projects/kuwo/kuwo/spiders/artist_info.py	/^from kuwo.items import ArtistInfoItem$/;"	i
artistInfo_spider	projects/kuwo/kuwo/spiders/artist_info.py	/^class artistInfo_spider(scrapy.Spider):$/;"	c
codecs	projects/kuwo/kuwo/spiders/artist_info.py	/^import codecs$/;"	i
json	projects/kuwo/kuwo/spiders/artist_info.py	/^import json$/;"	i
name	projects/kuwo/kuwo/spiders/artist_info.py	/^	name = "artist_info"$/;"	v	class:artistInfo_spider
parse	projects/kuwo/kuwo/spiders/artist_info.py	/^	def parse(self, response):$/;"	m	class:artistInfo_spider
parseArtistInfo	projects/kuwo/kuwo/spiders/artist_info.py	/^	def parseArtistInfo(self, response):  #返回歌手详细信息Item$/;"	m	class:artistInfo_spider
re	projects/kuwo/kuwo/spiders/artist_info.py	/^import re$/;"	i
scrapy	projects/kuwo/kuwo/spiders/artist_info.py	/^import scrapy$/;"	i
sys	projects/kuwo/kuwo/spiders/artist_info.py	/^import sys$/;"	i
AlbumItem	projects/kuwo/kuwo/spiders/artist_music_album.py	/^from kuwo.items import MusicItem, AlbumItem, ArtistItem, MusicInfoItem$/;"	i
ArtistItem	projects/kuwo/kuwo/spiders/artist_music_album.py	/^from kuwo.items import MusicItem, AlbumItem, ArtistItem, MusicInfoItem$/;"	i
MusicInfoItem	projects/kuwo/kuwo/spiders/artist_music_album.py	/^from kuwo.items import MusicItem, AlbumItem, ArtistItem, MusicInfoItem$/;"	i
MusicItem	projects/kuwo/kuwo/spiders/artist_music_album.py	/^from kuwo.items import MusicItem, AlbumItem, ArtistItem, MusicInfoItem$/;"	i
artistMusicAlbum_spider	projects/kuwo/kuwo/spiders/artist_music_album.py	/^class artistMusicAlbum_spider(scrapy.Spider):$/;"	c
codecs	projects/kuwo/kuwo/spiders/artist_music_album.py	/^import codecs$/;"	i
json	projects/kuwo/kuwo/spiders/artist_music_album.py	/^import json$/;"	i
name	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	name = "artist_list"$/;"	v	class:artistMusicAlbum_spider
parse	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	def parse(self, response):  #for every artist, crawl it's music and album, and write aritst in file$/;"	m	class:artistMusicAlbum_spider
parseAlbum	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	def parseAlbum(self, response):$/;"	m	class:artistMusicAlbum_spider
parseMusicByArtist	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	def parseMusicByArtist(self, response):$/;"	m	class:artistMusicAlbum_spider
parseMusicInfo	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	def parseMusicInfo(self, response):$/;"	m	class:artistMusicAlbum_spider
parseNext	projects/kuwo/kuwo/spiders/artist_music_album.py	/^	def parseNext(response, rn, func, url, id):   #crawl the next page$/;"	m	class:artistMusicAlbum_spider
re	projects/kuwo/kuwo/spiders/artist_music_album.py	/^import re$/;"	i
scrapy	projects/kuwo/kuwo/spiders/artist_music_album.py	/^import scrapy$/;"	i
sys	projects/kuwo/kuwo/spiders/artist_music_album.py	/^import sys$/;"	i
MusicCatItem	projects/kuwo/kuwo/spiders/category_playlist.py	/^from kuwo.items import MusicCatItem, PlaylistItem$/;"	i
PlaylistItem	projects/kuwo/kuwo/spiders/category_playlist.py	/^from kuwo.items import MusicCatItem, PlaylistItem$/;"	i
cate_spider	projects/kuwo/kuwo/spiders/category_playlist.py	/^class cate_spider(scrapy.Spider):$/;"	c
codecs	projects/kuwo/kuwo/spiders/category_playlist.py	/^import codecs$/;"	i
json	projects/kuwo/kuwo/spiders/category_playlist.py	/^import json$/;"	i
name	projects/kuwo/kuwo/spiders/category_playlist.py	/^    name = "cate_list"$/;"	v	class:cate_spider
parse	projects/kuwo/kuwo/spiders/category_playlist.py	/^    def parse(self, response):   #分类$/;"	m	class:cate_spider
parseCategoryList	projects/kuwo/kuwo/spiders/category_playlist.py	/^    def parseCategoryList(self, response):    #每类的歌单$/;"	m	class:cate_spider
parsePlaylist	projects/kuwo/kuwo/spiders/category_playlist.py	/^    def parsePlaylist(self, response):  #每个歌单的歌曲$/;"	m	class:cate_spider
re	projects/kuwo/kuwo/spiders/category_playlist.py	/^import re$/;"	i
scrapy	projects/kuwo/kuwo/spiders/category_playlist.py	/^import scrapy$/;"	i
sys	projects/kuwo/kuwo/spiders/category_playlist.py	/^import sys$/;"	i
Counter	projects/kuwo/tests/test_url.py	/^from collections import Counter$/;"	i
division	projects/kuwo/tests/test_url.py	/^from __future__ import print_function, division$/;"	i
func	projects/kuwo/tests/test_url.py	/^def func():$/;"	f
gcounter	projects/kuwo/tests/test_url.py	/^gcounter = Counter()$/;"	v
html	projects/kuwo/tests/test_url.py	/^import lxml.html$/;"	i
lxml	projects/kuwo/tests/test_url.py	/^import lxml.html$/;"	i
print_function	projects/kuwo/tests/test_url.py	/^from __future__ import print_function, division$/;"	i
requests	projects/kuwo/tests/test_url.py	/^import requests$/;"	i
time	projects/kuwo/tests/test_url.py	/^import time$/;"	i
aid	projects/kuwo/verification/kuwo_api_songs.py	/^		aid = art['artistlist'][0]['id']$/;"	v
aritst_number	projects/kuwo/verification/kuwo_api_songs.py	/^aritst_number = (int)(art_list['total'])  #总的歌手数目$/;"	v
art	projects/kuwo/verification/kuwo_api_songs.py	/^		art = json.loads(l.content)$/;"	v
art_list	projects/kuwo/verification/kuwo_api_songs.py	/^art_list = json.loads(r_art.content)$/;"	v
fsongNum	projects/kuwo/verification/kuwo_api_songs.py	/^fsongNum = open(".\/api_song_number.txt","w")   #统计每个歌手歌曲数目的文件$/;"	v
json	projects/kuwo/verification/kuwo_api_songs.py	/^import json$/;"	i
l	projects/kuwo/verification/kuwo_api_songs.py	/^	l = requests.get(list_url,timeout = 10)$/;"	v
list_url	projects/kuwo/verification/kuwo_api_songs.py	/^	list_url = art_url.format(pn)$/;"	v
r	projects/kuwo/verification/kuwo_api_songs.py	/^		r = requests.get(url, timeout=10)$/;"	v
r_art	projects/kuwo/verification/kuwo_api_songs.py	/^r_art = requests.get(art_url.format(0))$/;"	v
requests	projects/kuwo/verification/kuwo_api_songs.py	/^import requests$/;"	i
result	projects/kuwo/verification/kuwo_api_songs.py	/^			result = json.loads(r.content.decode('utf-8','ignore'))$/;"	v
sumSong	projects/kuwo/verification/kuwo_api_songs.py	/^sumSong = 0$/;"	v
sys	projects/kuwo/verification/kuwo_api_songs.py	/^import sys$/;"	i
time	projects/kuwo/verification/kuwo_api_songs.py	/^import time$/;"	i
url	projects/kuwo/verification/kuwo_api_songs.py	/^		url = base_url.format(aid)   #根据该歌手的id获得其歌曲数目 $/;"	v
art	projects/kuwo/verification/local_songs.py	/^	art = json.loads(line)$/;"	v
artists	projects/kuwo/verification/local_songs.py	/^artists = {}$/;"	v
defaultdict	projects/kuwo/verification/local_songs.py	/^from collections import defaultdict$/;"	i
dup_artist	projects/kuwo/verification/local_songs.py	/^dup_artist = []$/;"	v
dup_music	projects/kuwo/verification/local_songs.py	/^dup_music = []$/;"	v
fartist	projects/kuwo/verification/local_songs.py	/^fartist = open("\/home\/wl\/kuwoFile1\/artistFile.json")$/;"	v
fdupa	projects/kuwo/verification/local_songs.py	/^fdupa = open(".\/dup_artist.txt","w")   #dumplicate artist id$/;"	v
fdupm	projects/kuwo/verification/local_songs.py	/^fdupm = open(".\/dup_music.txt","w")    #dumplicate music id$/;"	v
fsong	projects/kuwo/verification/local_songs.py	/^fsong = open("\/home\/wl\/kuwoFile1\/musicFile.json","r")$/;"	v
fsum	projects/kuwo/verification/local_songs.py	/^fsum = open(".\/localsongs.txt","w")    #song number of each artist actually crawled$/;"	v
json	projects/kuwo/verification/local_songs.py	/^import json$/;"	i
mmusic	projects/kuwo/verification/local_songs.py	/^mmusic = {}$/;"	v
music	projects/kuwo/verification/local_songs.py	/^	music = json.loads(line)$/;"	v
s	projects/kuwo/verification/local_songs.py	/^s = sorted(artists.iteritems(),key = lambda x:x[0])$/;"	v
total	projects/kuwo/verification/local_songs.py	/^total = 0$/;"	v
collections	projects/kuwo/verification/uniq.py	/^import collections$/;"	i
print_function	projects/kuwo/verification/uniq.py	/^from __future__ import print_function$/;"	i
process	projects/kuwo/verification/uniq.py	/^def process(filename):$/;"	f
sys	projects/kuwo/verification/uniq.py	/^import sys$/;"	i
Advice	projects/mamabang/yuer/items.py	/^class Advice(scrapy.Item):$/;"	c
Food	projects/mamabang/yuer/items.py	/^class Food(scrapy.Item):$/;"	c
baby	projects/mamabang/yuer/items.py	/^    baby = scrapy.Field()$/;"	v	class:Food
content	projects/mamabang/yuer/items.py	/^    content = scrapy.Field()/;"	v	class:Advice
name	projects/mamabang/yuer/items.py	/^    name = scrapy.Field()$/;"	v	class:Food
pregnant	projects/mamabang/yuer/items.py	/^    pregnant = scrapy.Field()$/;"	v	class:Food
puerpera	projects/mamabang/yuer/items.py	/^    puerpera = scrapy.Field() $/;"	v	class:Food
scrapy	projects/mamabang/yuer/items.py	/^import scrapy$/;"	i
week	projects/mamabang/yuer/items.py	/^    week = scrapy.Field()$/;"	v	class:Advice
YuerPipeline	projects/mamabang/yuer/pipelines.py	/^class YuerPipeline(object):$/;"	c
process_item	projects/mamabang/yuer/pipelines.py	/^    def process_item(self, item, spider):$/;"	m	class:YuerPipeline
BOT_NAME	projects/mamabang/yuer/settings.py	/^BOT_NAME = 'yuer'$/;"	v
DOWNLOAD_DELAY	projects/mamabang/yuer/settings.py	/^DOWNLOAD_DELAY = 2$/;"	v
NEWSPIDER_MODULE	projects/mamabang/yuer/settings.py	/^NEWSPIDER_MODULE = 'yuer.spiders'$/;"	v
ROBOTSTXT_OBEY	projects/mamabang/yuer/settings.py	/^ROBOTSTXT_OBEY = True$/;"	v
SPIDER_MODULES	projects/mamabang/yuer/settings.py	/^SPIDER_MODULES = ['yuer.spiders']$/;"	v
Advice	projects/mamabang/yuer/spiders/guide.py	/^from yuer.items import Advice$/;"	i
GuideSpider	projects/mamabang/yuer/spiders/guide.py	/^class GuideSpider(scrapy.Spider):$/;"	c
allowed_domains	projects/mamabang/yuer/spiders/guide.py	/^    allowed_domains = []$/;"	v	class:GuideSpider
json	projects/mamabang/yuer/spiders/guide.py	/^import json$/;"	i
name	projects/mamabang/yuer/spiders/guide.py	/^    name = "guide"$/;"	v	class:GuideSpider
parse	projects/mamabang/yuer/spiders/guide.py	/^    def parse(self, response):$/;"	m	class:GuideSpider
parse_per_page	projects/mamabang/yuer/spiders/guide.py	/^    def parse_per_page(self, response):$/;"	m	class:GuideSpider
scrapy	projects/mamabang/yuer/spiders/guide.py	/^import scrapy$/;"	i
start_urls	projects/mamabang/yuer/spiders/guide.py	/^    start_urls = ($/;"	v	class:GuideSpider
sys	projects/mamabang/yuer/spiders/guide.py	/^import sys$/;"	i
urlparse	projects/mamabang/yuer/spiders/guide.py	/^import urlparse$/;"	i
Food	projects/mamabang/yuer/spiders/quick.py	/^from yuer.items import Food$/;"	i
QuickSpider	projects/mamabang/yuer/spiders/quick.py	/^class QuickSpider(scrapy.Spider):$/;"	c
after_parse	projects/mamabang/yuer/spiders/quick.py	/^    def after_parse(self, response):$/;"	m	class:QuickSpider
allowed_domains	projects/mamabang/yuer/spiders/quick.py	/^    allowed_domains = []$/;"	v	class:QuickSpider
json	projects/mamabang/yuer/spiders/quick.py	/^import json$/;"	i
name	projects/mamabang/yuer/spiders/quick.py	/^    name = "quick"$/;"	v	class:QuickSpider
parse	projects/mamabang/yuer/spiders/quick.py	/^    def parse(self, response):$/;"	m	class:QuickSpider
parse_per_food	projects/mamabang/yuer/spiders/quick.py	/^    def parse_per_food(self, response):$/;"	m	class:QuickSpider
re	projects/mamabang/yuer/spiders/quick.py	/^import re$/;"	i
scrapy	projects/mamabang/yuer/spiders/quick.py	/^import scrapy$/;"	i
start_urls	projects/mamabang/yuer/spiders/quick.py	/^    start_urls = ($/;"	v	class:QuickSpider
sys	projects/mamabang/yuer/spiders/quick.py	/^import sys$/;"	i
urlparse	projects/mamabang/yuer/spiders/quick.py	/^import urlparse$/;"	i
a	projects/mingluji/check.py	/^	a=count.get(provin)$/;"	v
content	projects/mingluji/check.py	/^content=f.read()$/;"	v
count	projects/mingluji/check.py	/^count={}$/;"	v
f	projects/mingluji/check.py	/^f=open('0','r')$/;"	v
f	projects/mingluji/check.py	/^f=open('mingluji_urls.txt','r')$/;"	v
item	projects/mingluji/check.py	/^	    item=json.loads(line)$/;"	v
json	projects/mingluji/check.py	/^import json$/;"	i
line	projects/mingluji/check.py	/^	line=f.readline().strip()$/;"	v
provin	projects/mingluji/check.py	/^	provin=re.search('com\/(.*?)\/',item['url']).group(1)$/;"	v
re	projects/mingluji/check.py	/^import re$/;"	i
total	projects/mingluji/check.py	/^total=0$/;"	v
f	projects/mingluji/convert.py	/^f = open(file_name, 'r')$/;"	v
file_name	projects/mingluji/convert.py	/^file_name = 'mingluji_urls.txt'$/;"	v
index	projects/mingluji/convert.py	/^            index=max_url.find('=')$/;"	v
item	projects/mingluji/convert.py	/^            item=json.loads(line)$/;"	v
json	projects/mingluji/convert.py	/^import json$/;"	i
line	projects/mingluji/convert.py	/^            line = line.strip()$/;"	v
line	projects/mingluji/convert.py	/^        line = f.readline()$/;"	v
re	projects/mingluji/convert.py	/^import re$/;"	i
Cache	projects/mingluji/mingluji/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/mingluji/mingluji/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/mingluji/mingluji/downloader/cache.py	/^import base64$/;"	i
division	projects/mingluji/mingluji/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/mingluji/mingluji/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/mingluji/mingluji/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/mingluji/mingluji/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/mingluji/mingluji/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/mingluji/mingluji/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/mingluji/mingluji/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/mingluji/mingluji/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/mingluji/mingluji/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/mingluji/mingluji/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/mingluji/mingluji/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/mingluji/mingluji/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/mingluji/mingluji/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/mingluji/mingluji/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/mingluji/mingluji/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/mingluji/mingluji/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/mingluji/mingluji/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/mingluji/mingluji/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/mingluji/mingluji/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/mingluji/mingluji/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/mingluji/mingluji/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/mingluji/mingluji/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/mingluji/mingluji/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/mingluji/mingluji/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/mingluji/mingluji/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/mingluji/mingluji/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/mingluji/mingluji/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/mingluji/mingluji/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/mingluji/mingluji/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/mingluji/mingluji/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/mingluji/mingluji/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/mingluji/mingluji/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/mingluji/mingluji/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/mingluji/mingluji/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/mingluji/mingluji/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/mingluji/mingluji/downloader/downloader.py	/^import os$/;"	i
print_function	projects/mingluji/mingluji/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/mingluji/mingluji/downloader/downloader.py	/^import re$/;"	i
request_download	projects/mingluji/mingluji/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/mingluji/mingluji/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/mingluji/mingluji/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/mingluji/mingluji/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/mingluji/mingluji/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/mingluji/mingluji/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/mingluji/mingluji/downloader/downloader.py	/^import sys$/;"	i
time	projects/mingluji/mingluji/downloader/downloader.py	/^import time$/;"	i
update_header	projects/mingluji/mingluji/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/mingluji/mingluji/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/mingluji/mingluji/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/mingluji/mingluji/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/mingluji/mingluji/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/mingluji/mingluji/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/mingluji/mingluji/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/mingluji/mingluji/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/mingluji/mingluji/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/mingluji/mingluji/downloader/test_download.py	/^import datetime$/;"	i
json	projects/mingluji/mingluji/downloader/test_download.py	/^import json$/;"	i
main	projects/mingluji/mingluji/downloader/test_download.py	/^def main():$/;"	f
os	projects/mingluji/mingluji/downloader/test_download.py	/^import os$/;"	i
re	projects/mingluji/mingluji/downloader/test_download.py	/^import re$/;"	i
requests	projects/mingluji/mingluji/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/mingluji/mingluji/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/mingluji/mingluji/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/mingluji/mingluji/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/mingluji/mingluji/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/mingluji/mingluji/downloader/test_download.py	/^import time$/;"	i
urllib	projects/mingluji/mingluji/downloader/test_download.py	/^import urllib$/;"	i
Company	projects/mingluji/mingluji/items.py	/^class Company(scrapy.Item):$/;"	c
id	projects/mingluji/mingluji/items.py	/^    id=scrapy.Field()$/;"	v	class:Company
name	projects/mingluji/mingluji/items.py	/^    name=scrapy.Field()$/;"	v	class:Company
num	projects/mingluji/mingluji/items.py	/^    num=scrapy.Field()$/;"	v	class:Company
province	projects/mingluji/mingluji/items.py	/^    province=scrapy.Field()$/;"	v	class:Company
scrapy	projects/mingluji/mingluji/items.py	/^import scrapy$/;"	i
url	projects/mingluji/mingluji/items.py	/^    url=scrapy.Field()$/;"	v	class:Company
BATCH_ID	projects/mingluji/mingluji/middlewares.py	/^BATCH_ID = 'mingluji-201606'$/;"	v
DownloadWrapper	projects/mingluji/mingluji/middlewares.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
MyMiddleWare	projects/mingluji/mingluji/middlewares.py	/^class MyMiddleWare(object):$/;"	c
SERVER	projects/mingluji/mingluji/middlewares.py	/^SERVER = 'http:\/\/192.168.1.179:8000\/'$/;"	v
process_request	projects/mingluji/mingluji/middlewares.py	/^    def process_request(self, request,  spider):$/;"	m	class:MyMiddleWare
scrapy	projects/mingluji/mingluji/middlewares.py	/^import scrapy$/;"	i
sys	projects/mingluji/mingluji/middlewares.py	/^import sys$/;"	i
MinglujiPipeline	projects/mingluji/mingluji/pipelines.py	/^class MinglujiPipeline(object):$/;"	c
__init__	projects/mingluji/mingluji/pipelines.py	/^    def __init__(self):$/;"	m	class:MinglujiPipeline
codecs	projects/mingluji/mingluji/pipelines.py	/^import codecs$/;"	i
json	projects/mingluji/mingluji/pipelines.py	/^import json$/;"	i
process_item	projects/mingluji/mingluji/pipelines.py	/^    def process_item(self, item, spider):$/;"	m	class:MinglujiPipeline
BOT_NAME	projects/mingluji/mingluji/settings.py	/^BOT_NAME = 'mingluji'$/;"	v
COOKIES_ENABLED	projects/mingluji/mingluji/settings.py	/^COOKIES_ENABLED = False$/;"	v
DOWNLOADER_MIDDLEWARES	projects/mingluji/mingluji/settings.py	/^DOWNLOADER_MIDDLEWARES = {$/;"	v
DOWNLOAD_DELAY	projects/mingluji/mingluji/settings.py	/^DOWNLOAD_DELAY = 0.01$/;"	v
ITEM_PIPELINES	projects/mingluji/mingluji/settings.py	/^ITEM_PIPELINES = {$/;"	v
NEWSPIDER_MODULE	projects/mingluji/mingluji/settings.py	/^NEWSPIDER_MODULE = 'mingluji.spiders'$/;"	v
ROBOTSTXT_OBEY	projects/mingluji/mingluji/settings.py	/^ROBOTSTXT_OBEY = True$/;"	v
SPIDER_MODULES	projects/mingluji/mingluji/settings.py	/^SPIDER_MODULES = ['mingluji.spiders']$/;"	v
Company	projects/mingluji/mingluji/spiders/mlj.py	/^from mingluji.items import Company$/;"	i
MinglujiSpider	projects/mingluji/mingluji/spiders/mlj.py	/^class MinglujiSpider(Spider):$/;"	c
Rule	projects/mingluji/mingluji/spiders/mlj.py	/^from scrapy.spiders import Rule$/;"	i
Spider	projects/mingluji/mingluji/spiders/mlj.py	/^from scrapy.spiders import Spider$/;"	i
allowed_domains	projects/mingluji/mingluji/spiders/mlj.py	/^    allowed_domains = ["mingluji.com"]$/;"	v	class:MinglujiSpider
json	projects/mingluji/mingluji/spiders/mlj.py	/^import json$/;"	i
name	projects/mingluji/mingluji/spiders/mlj.py	/^    name = "mingluji"$/;"	v	class:MinglujiSpider
parse	projects/mingluji/mingluji/spiders/mlj.py	/^    def parse(self, response):$/;"	m	class:MinglujiSpider
parse_for_industry	projects/mingluji/mingluji/spiders/mlj.py	/^    def parse_for_industry(self, response):$/;"	m	class:MinglujiSpider
parse_max_page	projects/mingluji/mingluji/spiders/mlj.py	/^    def parse_max_page(self, response):$/;"	m	class:MinglujiSpider
pass_item	projects/mingluji/mingluji/spiders/mlj.py	/^    def pass_item(self, i):$/;"	m	class:MinglujiSpider
re	projects/mingluji/mingluji/spiders/mlj.py	/^import re$/;"	i
scrapy	projects/mingluji/mingluji/spiders/mlj.py	/^import scrapy$/;"	i
start_urls	projects/mingluji/mingluji/spiders/mlj.py	/^    start_urls = ($/;"	v	class:MinglujiSpider
sys	projects/mingluji/mingluji/spiders/mlj.py	/^import sys$/;"	i
urllib	projects/mingluji/mingluji/spiders/mlj.py	/^import urllib$/;"	i
GetPosition	projects/mingluji/violence.py	/^    def GetPosition(self):$/;"	m	class:MingluSpider
MingluSpider	projects/mingluji/violence.py	/^class MingluSpider(object):$/;"	c
__init__	projects/mingluji/violence.py	/^    def __init__(self):$/;"	m	class:MingluSpider
get_name_with_re	projects/mingluji/violence.py	/^    def get_name_with_re(self, content):$/;"	m	class:MingluSpider
get_name_with_xpath	projects/mingluji/violence.py	/^    def get_name_with_xpath(self, content):$/;"	m	class:MingluSpider
html	projects/mingluji/violence.py	/^import lxml.html$/;"	i
json	projects/mingluji/violence.py	/^import json$/;"	i
lxml	projects/mingluji/violence.py	/^import lxml.html$/;"	i
obj	projects/mingluji/violence.py	/^obj = MingluSpider()$/;"	v
re	projects/mingluji/violence.py	/^import re$/;"	i
requests	projects/mingluji/violence.py	/^import requests$/;"	i
sys	projects/mingluji/violence.py	/^import sys$/;"	i
traversal	projects/mingluji/violence.py	/^    def traversal(self):$/;"	m	class:MingluSpider
update_record	projects/mingluji/violence.py	/^    def update_record(self):$/;"	m	class:MingluSpider
Cache	projects/qastream/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/qastream/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/qastream/downloader/cache.py	/^import base64$/;"	i
division	projects/qastream/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/qastream/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/qastream/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/qastream/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/qastream/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/qastream/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/qastream/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/qastream/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/qastream/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/qastream/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/qastream/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/qastream/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/qastream/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/qastream/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/qastream/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/qastream/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/qastream/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/qastream/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/qastream/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/qastream/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/qastream/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/qastream/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/qastream/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/qastream/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/qastream/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/qastream/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/qastream/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/qastream/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/qastream/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/qastream/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/qastream/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/qastream/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/qastream/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/qastream/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/qastream/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/qastream/downloader/downloader.py	/^import os$/;"	i
print_function	projects/qastream/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/qastream/downloader/downloader.py	/^import re$/;"	i
request_download	projects/qastream/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/qastream/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/qastream/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/qastream/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/qastream/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/qastream/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/qastream/downloader/downloader.py	/^import sys$/;"	i
time	projects/qastream/downloader/downloader.py	/^import time$/;"	i
update_header	projects/qastream/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/qastream/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/qastream/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/qastream/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/qastream/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/qastream/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/qastream/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/qastream/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/qastream/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/qastream/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/qastream/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/qastream/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/qastream/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/qastream/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/qastream/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/qastream/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/qastream/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/qastream/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/qastream/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/qastream/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/qastream/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/qastream/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/qastream/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/qastream/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/qastream/downloader/test_download.py	/^import datetime$/;"	i
json	projects/qastream/downloader/test_download.py	/^import json$/;"	i
main	projects/qastream/downloader/test_download.py	/^def main():$/;"	f
os	projects/qastream/downloader/test_download.py	/^import os$/;"	i
re	projects/qastream/downloader/test_download.py	/^import re$/;"	i
requests	projects/qastream/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/qastream/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/qastream/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/qastream/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/qastream/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/qastream/downloader/test_download.py	/^import time$/;"	i
urllib	projects/qastream/downloader/test_download.py	/^import urllib$/;"	i
INDEX_OPTION_DELETE	projects/qastream/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	projects/qastream/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	projects/qastream/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	projects/qastream/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	projects/qastream/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	projects/qastream/es/es_api.py	/^import codecs$/;"	i
collections	projects/qastream/es/es_api.py	/^import collections$/;"	i
es_api_post	projects/qastream/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	projects/qastream/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	projects/qastream/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	projects/qastream/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	projects/qastream/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	projects/qastream/es/es_api.py	/^import hashlib$/;"	i
json	projects/qastream/es/es_api.py	/^import json$/;"	i
os	projects/qastream/es/es_api.py	/^import os$/;"	i
os	projects/qastream/es/es_api.py	/^import os.path$/;"	i
path	projects/qastream/es/es_api.py	/^import os.path$/;"	i
requests	projects/qastream/es/es_api.py	/^import requests$/;"	i
run_batch	projects/qastream/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	projects/qastream/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	projects/qastream/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	projects/qastream/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	projects/qastream/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	projects/qastream/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	projects/qastream/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	projects/qastream/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	projects/qastream/es/es_api.py	/^import sys$/;"	i
test	projects/qastream/es/es_api.py	/^def test():$/;"	f
test_echo	projects/qastream/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	projects/qastream/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	projects/qastream/es/es_api.py	/^import urllib$/;"	i
InstanceMgr	projects/qastream/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/qastream/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/qastream/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/qastream/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/qastream/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/qastream/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/qastream/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/qastream/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/qastream/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/qastream/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/qastream/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/qastream/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/qastream/hzlib/api_aws.py	/^import json$/;"	i
list	projects/qastream/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/qastream/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/qastream/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/qastream/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/qastream/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/qastream/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/qastream/hzlib/api_aws.py	/^import re$/;"	i
run	projects/qastream/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/qastream/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/qastream/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/qastream/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/qastream/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/qastream/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/qastream/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/qastream/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/qastream/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/qastream/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/qastream/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/qastream/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/qastream/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/qastream/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/qastream/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/qastream/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/qastream/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/qastream/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/qastream/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/qastream/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/qastream/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/qastream/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/qastream/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/qastream/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/qastream/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/qastream/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/qastream/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/qastream/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/qastream/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/qastream/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/qastream/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/qastream/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/qastream/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/qastream/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/qastream/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/qastream/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/qastream/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/qastream/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/qastream/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/qastream/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/qastream/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/qastream/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/qastream/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/qastream/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/qastream/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/qastream/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/qastream/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/qastream/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/qastream/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/qastream/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/qastream/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/qastream/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/qastream/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/qastream/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/qastream/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/qastream/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/qastream/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/qastream/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/qastream/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/qastream/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/qastream/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/qastream/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/qastream/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/qastream/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/qastream/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/qastream/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/qastream/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/qastream/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/qastream/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/qastream/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/qastream/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/qastream/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/qastream/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/qastream/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/qastream/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/qastream/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/qastream/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/qastream/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/qastream/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/qastream/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/qastream/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/qastream/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/qastream/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/qastream/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/qastream/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/qastream/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/qastream/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/qastream/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/qastream/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/qastream/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/qastream/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/qastream/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/qastream/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/qastream/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/qastream/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/qastream/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/qastream/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/qastream/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/qastream/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/qastream/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/qastream/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/qastream/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/qastream/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/qastream/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/qastream/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/qastream/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/qastream/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/qastream/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/qastream/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/qastream/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/qastream/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/qastream/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/qastream/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/qastream/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/qastream/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/qastream/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/qastream/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/qastream/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/qastream/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/qastream/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/qastream/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/qastream/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/qastream/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/qastream/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/qastream/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/qastream/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/qastream/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/qastream/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/qastream/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/qastream/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/qastream/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/qastream/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/qastream/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/qastream/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/qastream/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/qastream/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/qastream/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/qastream/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/qastream/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/qastream/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/qastream/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/qastream/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/qastream/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/qastream/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/qastream/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/qastream/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/qastream/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/qastream/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/qastream/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/qastream/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/qastream/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/qastream/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/qastream/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/qastream/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/qastream/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/qastream/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/qastream/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/qastream/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/qastream/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/qastream/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/qastream/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/qastream/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/qastream/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/qastream/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/qastream/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/qastream/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/qastream/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/qastream/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/qastream/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/qastream/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/qastream/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/qastream/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/qastream/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/qastream/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/qastream/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/qastream/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/qastream/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/qastream/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/qastream/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/qastream/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/qastream/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/qastream/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/qastream/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/qastream/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/qastream/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/qastream/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/qastream/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/qastream/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/qastream/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/qastream/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/qastream/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/qastream/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/qastream/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/qastream/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/qastream/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/qastream/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/qastream/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/qastream/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/qastream/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/qastream/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/qastream/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/qastream/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/qastream/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/qastream/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/qastream/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/qastream/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/qastream/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/qastream/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/qastream/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/qastream/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/qastream/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/qastream/hzlib/libdata.py	/^import random$/;"	i
re	projects/qastream/hzlib/libdata.py	/^import re$/;"	i
requests	projects/qastream/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/qastream/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/qastream/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/qastream/hzlib/libdata.py	/^import sys$/;"	i
time	projects/qastream/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/qastream/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/qastream/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/qastream/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/qastream/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/qastream/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/qastream/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/qastream/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/qastream/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/qastream/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/qastream/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/qastream/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/qastream/hzlib/libfile.py	/^import os$/;"	i
re	projects/qastream/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/qastream/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/qastream/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/qastream/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/qastream/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/qastream/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/qastream/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/qastream/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/qastream/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/qastream/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/qastream/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/qastream/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/qastream/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/qastream/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/qastream/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/qastream/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/qastream/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/qastream/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/qastream/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/qastream/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/qastream/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/qastream/hzlib/libnlp.py	/^import os$/;"	i
re	projects/qastream/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/qastream/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/qastream/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/qastream/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/qastream/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/qastream/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/qastream/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/qastream/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/qastream/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/qastream/hzlib/libregex.py	/^def main():$/;"	f
os	projects/qastream/hzlib/libregex.py	/^import os$/;"	i
re	projects/qastream/hzlib/libregex.py	/^import re$/;"	i
sys	projects/qastream/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/qastream/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/qastream/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/qastream/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/qastream/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/qastream/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/qastream/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/qastream/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/qastream/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/qastream/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/qastream/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/qastream/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/qastream/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/qastream/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/qastream/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/qastream/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/qastream/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/qastream/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/qastream/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/qastream/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/qastream/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/qastream/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/qastream/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/qastream/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/qastream/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/qastream/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/qastream/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/qastream/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/qastream/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/qastream/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/qastream/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/qastream/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/qastream/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/qastream/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/qastream/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/qastream/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/qastream/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/qastream/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/qastream/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/qastream/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/qastream/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/qastream/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/qastream/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/qastream/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/qastream/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/qastream/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/qastream/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/qastream/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/qastream/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/qastream/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/qastream/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/qastream/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/qastream/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/qastream/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/qastream/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/qastream/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/qastream/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/qastream/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/qastream/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/qastream/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/qastream/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/qastream/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/qastream/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/qastream/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/qastream/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/qastream/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/qastream/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/qastream/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/qastream/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/qastream/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/qastream/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/qastream/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/qastream/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/qastream/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/qastream/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/qastream/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/qastream/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/qastream/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/qastream/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/qastream/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/qastream/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/qastream/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/qastream/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/qastream/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/qastream/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/qastream/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/qastream/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/qastream/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/qastream/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/qastream/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/qastream/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/qastream/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/qastream/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/qastream/hzlib/tests/test_api.py	/^def test_search():$/;"	f
Downloader	projects/qastream/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	projects/qastream/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/qastream/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	projects/qastream/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/qastream/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/qastream/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/qastream/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/qastream/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/qastream/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	projects/qastream/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/qastream/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	projects/qastream/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	projects/qastream/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/qastream/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/qastream/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	projects/qastream/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	projects/qastream/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	projects/qastream/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/qastream/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	projects/qastream/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/qastream/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	projects/qastream/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/qastream/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/qastream/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	projects/qastream/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	projects/qastream/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	projects/qastream/parsers/qichacha2.py	/^import re$/;"	i
traceback	projects/qastream/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	projects/qastream/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	projects/qastream/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	projects/qastream/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/qastream/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/qastream/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/qastream/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/qastream/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/qastream/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/qastream/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	projects/qastream/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	projects/qastream/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	projects/qastream/parsers/qiparser2.py	/^import re$/;"	i
string	projects/qastream/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	projects/qastream/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	projects/qastream/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	projects/qastream/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	projects/qastream/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	projects/qastream/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	projects/qastream/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	projects/qastream/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	projects/qastream/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	projects/qastream/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	projects/qastream/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	projects/qastream/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	projects/qastream/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	projects/qastream/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	projects/qastream/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	projects/qastream/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	projects/qastream/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	projects/qastream/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	projects/qastream/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	projects/qastream/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	projects/qastream/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	projects/qastream/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
QUEUE	projects/qastream/receiver/handler.py	/^from stream_process import QUEUE, return_best_answer$/;"	i
ZhidaoAsyncESHandler	projects/qastream/receiver/handler.py	/^class ZhidaoAsyncESHandler(tornado.web.RequestHandler):$/;"	c
ZhidaoBaikeAsyncESHandler	projects/qastream/receiver/handler.py	/^class ZhidaoBaikeAsyncESHandler(tornado.web.RequestHandler):$/;"	c
ZhidaoSearchHandler	projects/qastream/receiver/handler.py	/^class ZhidaoSearchHandler(tornado.web.RequestHandler):$/;"	c
division	projects/qastream/receiver/handler.py	/^from __future__ import print_function, division$/;"	i
get	projects/qastream/receiver/handler.py	/^    def get(self,  qword):$/;"	m	class:ZhidaoAsyncESHandler
get	projects/qastream/receiver/handler.py	/^    def get(self,  qword):$/;"	m	class:ZhidaoBaikeAsyncESHandler
get	projects/qastream/receiver/handler.py	/^    def get(self, qword):$/;"	m	class:ZhidaoSearchHandler
libregex	projects/qastream/receiver/handler.py	/^from hzlib import libregex$/;"	i
print_function	projects/qastream/receiver/handler.py	/^from __future__ import print_function, division$/;"	i
return_best_answer	projects/qastream/receiver/handler.py	/^from stream_process import QUEUE, return_best_answer$/;"	i
sys	projects/qastream/receiver/handler.py	/^import sys$/;"	i
tornado	projects/qastream/receiver/handler.py	/^import tornado.web$/;"	i
web	projects/qastream/receiver/handler.py	/^import tornado.web$/;"	i
define	projects/qastream/receiver/main.py	/^from tornado.options import define, options$/;"	i
division	projects/qastream/receiver/main.py	/^from __future__ import print_function, division$/;"	i
gevent	projects/qastream/receiver/main.py	/^import gevent$/;"	i
http_server	projects/qastream/receiver/main.py	/^    http_server = tornado.httpserver.HTTPServer(urls, xheaders=True)$/;"	v
httpserver	projects/qastream/receiver/main.py	/^import tornado.httpserver$/;"	i
ioloop	projects/qastream/receiver/main.py	/^import tornado.ioloop$/;"	i
monkey	projects/qastream/receiver/main.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
options	projects/qastream/receiver/main.py	/^from tornado.options import define, options$/;"	i
patch_all	projects/qastream/receiver/main.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
print_function	projects/qastream/receiver/main.py	/^from __future__ import print_function, division$/;"	i
stream_process	projects/qastream/receiver/main.py	/^from stream_process import stream_process$/;"	i
tornado	projects/qastream/receiver/main.py	/^import tornado.httpserver$/;"	i
tornado	projects/qastream/receiver/main.py	/^import tornado.ioloop$/;"	i
urls	projects/qastream/receiver/main.py	/^from router import urls$/;"	i
division	projects/qastream/receiver/router.py	/^from __future__ import print_function, division$/;"	i
print_function	projects/qastream/receiver/router.py	/^from __future__ import print_function, division$/;"	i
settings	projects/qastream/receiver/router.py	/^settings = {$/;"	v
tornado	projects/qastream/receiver/router.py	/^import tornado.web$/;"	i
urls	projects/qastream/receiver/router.py	/^urls = tornado.web.Application([$/;"	v
web	projects/qastream/receiver/router.py	/^import tornado.web$/;"	i
CONFIG	projects/qastream/receiver/stream_process.py	/^CONFIG = {$/;"	v
ENV	projects/qastream/receiver/stream_process.py	/^ENV = 'local'$/;"	v
ES_DATASET_CONFIG	projects/qastream/receiver/stream_process.py	/^ES_DATASET_CONFIG = {$/;"	v
QUEUE	projects/qastream/receiver/stream_process.py	/^QUEUE = gevent.queue.Queue()$/;"	v
Scheduler	projects/qastream/receiver/stream_process.py	/^from zhidao.zhidao_scheduler import Scheduler$/;"	i
batch_init	projects/qastream/receiver/stream_process.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
division	projects/qastream/receiver/stream_process.py	/^from __future__ import print_function, division$/;"	i
get_esconfig	projects/qastream/receiver/stream_process.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
gevent	projects/qastream/receiver/stream_process.py	/^import gevent$/;"	i
gevent	projects/qastream/receiver/stream_process.py	/^import gevent.queue$/;"	i
monkey	projects/qastream/receiver/stream_process.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
os	projects/qastream/receiver/stream_process.py	/^import os$/;"	i
patch_all	projects/qastream/receiver/stream_process.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
print_function	projects/qastream/receiver/stream_process.py	/^from __future__ import print_function, division$/;"	i
queue	projects/qastream/receiver/stream_process.py	/^import gevent.queue$/;"	i
return_best_answer	projects/qastream/receiver/stream_process.py	/^def return_best_answer(qword):$/;"	f
run_esbulk_rows	projects/qastream/receiver/stream_process.py	/^from es.es_api import get_esconfig, batch_init, run_esbulk_rows$/;"	i
search_questions	projects/qastream/receiver/stream_process.py	/^def search_questions(qword):$/;"	f
sendto_es	projects/qastream/receiver/stream_process.py	/^def sendto_es(questions):$/;"	f
stream_process	projects/qastream/receiver/stream_process.py	/^def stream_process():$/;"	f
codecs	projects/qastream/receiver/web_server.py	/^import codecs$/;"	i
datetime	projects/qastream/receiver/web_server.py	/^from datetime import datetime$/;"	i
get	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
logging	projects/qastream/receiver/web_server.py	/^import logging$/;"	i
os	projects/qastream/receiver/web_server.py	/^import os$/;"	i
post	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
request	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
response	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
route	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
run	projects/qastream/receiver/web_server.py	/^from bottle import route, run, request, get, post, response$/;"	i
search	projects/qastream/receiver/web_server.py	/^def search():$/;"	f
socket	projects/qastream/receiver/web_server.py	/^    import socket$/;"	i
start1	projects/qastream/receiver/web_server.py	/^def start1():$/;"	f
start2	projects/qastream/receiver/web_server.py	/^def start2():$/;"	f
sys	projects/qastream/receiver/web_server.py	/^import sys$/;"	i
timedelta	projects/qastream/receiver/web_server.py	/^from datetime import timedelta$/;"	i
Scheduler	projects/qastream/zhidao/test_zhidao.py	/^from zhidao_scheduler import Scheduler$/;"	i
codecs	projects/qastream/zhidao/test_zhidao.py	/^import codecs$/;"	i
collections	projects/qastream/zhidao/test_zhidao.py	/^import collections$/;"	i
datetime	projects/qastream/zhidao/test_zhidao.py	/^import datetime$/;"	i
json	projects/qastream/zhidao/test_zhidao.py	/^import json$/;"	i
libregex	projects/qastream/zhidao/test_zhidao.py	/^from hzlib import libregex$/;"	i
main	projects/qastream/zhidao/test_zhidao.py	/^def main():$/;"	f
os	projects/qastream/zhidao/test_zhidao.py	/^import os$/;"	i
re	projects/qastream/zhidao/test_zhidao.py	/^import re$/;"	i
sys	projects/qastream/zhidao/test_zhidao.py	/^import sys$/;"	i
test	projects/qastream/zhidao/test_zhidao.py	/^def test():$/;"	f
urllib	projects/qastream/zhidao/test_zhidao.py	/^import urllib$/;"	i
BATCH_ID	projects/qastream/zhidao/zhidao_scheduler.py	/^BATCH_ID = {$/;"	v
Cache	projects/qastream/zhidao/zhidao_scheduler.py	/^from downloader.cache import Cache$/;"	i
DownloadWrapper	projects/qastream/zhidao/zhidao_scheduler.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
Scheduler	projects/qastream/zhidao/zhidao_scheduler.py	/^class Scheduler(object):$/;"	c
__init__	projects/qastream/zhidao/zhidao_scheduler.py	/^    def __init__(self, cacheserver):$/;"	m	class:Scheduler
division	projects/qastream/zhidao/zhidao_scheduler.py	/^from __future__ import print_function, division$/;"	i
instance	projects/qastream/zhidao/zhidao_scheduler.py	/^    def instance(cls, *args):$/;"	m	class:Scheduler
print_function	projects/qastream/zhidao/zhidao_scheduler.py	/^from __future__ import print_function, division$/;"	i
run	projects/qastream/zhidao/zhidao_scheduler.py	/^    def run(self, qword, gap=3, timeout=10):$/;"	m	class:Scheduler
urllib	projects/qastream/zhidao/zhidao_scheduler.py	/^import urllib$/;"	i
zhidao_answer	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_answer(self, qid, rid, gap, timeout):$/;"	m	class:Scheduler
zhidao_question	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_question(self, qid, gap, timeout):$/;"	m	class:Scheduler
zhidao_results	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_results(self, qids, gap, timeout=10):$/;"	m	class:Scheduler
zhidao_search	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_search(self, qword, batch_id, gap=3, timeout=10, refresh=True):$/;"	m	class:Scheduler
zhidao_search_list_json	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_search_list_json(self, qword, batch_id, gap=3, timeout=10, refresh=False):$/;"	m	class:Scheduler
zhidao_search_select_best	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_search_select_best(self, qword, gap=3, timeout=2):$/;"	m	class:Scheduler
zhidao_search_select_best_qids	projects/qastream/zhidao/zhidao_scheduler.py	/^    def zhidao_search_select_best_qids(self, qword, gap=3, timeout=2):$/;"	m	class:Scheduler
AWS_ACCESS_KEY_ID	projects/qichacha/business/awscontrol.py	/^from secret import AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY$/;"	i
AWS_SECRET_ACCESS_KEY	projects/qichacha/business/awscontrol.py	/^from secret import AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY$/;"	i
InstanceMgr	projects/qichacha/business/awscontrol.py	/^class InstanceMgr:$/;"	c
THE_WORKER_NUM	projects/qichacha/business/awscontrol.py	/^THE_WORKER_NUM = 20$/;"	v
__init__	projects/qichacha/business/awscontrol.py	/^    def __init__(self):$/;"	m	class:InstanceMgr
_execute_cmd	projects/qichacha/business/awscontrol.py	/^    def _execute_cmd(self, host, user, cmds):$/;"	m	class:InstanceMgr
boto3	projects/qichacha/business/awscontrol.py	/^import boto3$/;"	i
clear	projects/qichacha/business/awscontrol.py	/^    def clear(self):$/;"	m	class:InstanceMgr
codecs	projects/qichacha/business/awscontrol.py	/^import codecs$/;"	i
collections	projects/qichacha/business/awscontrol.py	/^import collections$/;"	i
create	projects/qichacha/business/awscontrol.py	/^    def create(self, crawler_num):$/;"	m	class:InstanceMgr
datetime	projects/qichacha/business/awscontrol.py	/^import datetime$/;"	i
gcounter	projects/qichacha/business/awscontrol.py	/^gcounter = collections.Counter()$/;"	v
glob	projects/qichacha/business/awscontrol.py	/^import glob$/;"	i
hashlib	projects/qichacha/business/awscontrol.py	/^import hashlib$/;"	i
json	projects/qichacha/business/awscontrol.py	/^import json$/;"	i
list	projects/qichacha/business/awscontrol.py	/^    def list(self):$/;"	m	class:InstanceMgr
logging	projects/qichacha/business/awscontrol.py	/^import logging$/;"	i
main	projects/qichacha/business/awscontrol.py	/^def main():$/;"	f
os	projects/qichacha/business/awscontrol.py	/^import os$/;"	i
paramiko	projects/qichacha/business/awscontrol.py	/^import paramiko$/;"	i
re	projects/qichacha/business/awscontrol.py	/^import re$/;"	i
run	projects/qichacha/business/awscontrol.py	/^    def run(self, worker_num, cmd_option):$/;"	m	class:InstanceMgr
select	projects/qichacha/business/awscontrol.py	/^    def select(self, state=None):$/;"	m	class:InstanceMgr
start	projects/qichacha/business/awscontrol.py	/^    def start(self, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/qichacha/business/awscontrol.py	/^    def stop(self):$/;"	m	class:InstanceMgr
subprocess	projects/qichacha/business/awscontrol.py	/^import subprocess$/;"	i
sys	projects/qichacha/business/awscontrol.py	/^import sys$/;"	i
time	projects/qichacha/business/awscontrol.py	/^import time$/;"	i
upload	projects/qichacha/business/awscontrol.py	/^    def upload(self, worker_num):$/;"	m	class:InstanceMgr
BATCH_ID_FETCH	projects/qichacha/business/crawljob.py	/^BATCH_ID_FETCH ='qichacha_fetch_20160603'$/;"	v
BATCH_ID_JSON_FETCH	projects/qichacha/business/crawljob.py	/^BATCH_ID_JSON_FETCH ='qichacha20160607jsonfetch'$/;"	v
BATCH_ID_JSON_RAWITEM	projects/qichacha/business/crawljob.py	/^BATCH_ID_JSON_RAWITEM = 'qichacha20160607rawitem'$/;"	v
BATCH_ID_JSON_SEARCH	projects/qichacha/business/crawljob.py	/^BATCH_ID_JSON_SEARCH ='qichacha20160607jsonsearch'$/;"	v
BATCH_ID_SEARCH	projects/qichacha/business/crawljob.py	/^BATCH_ID_SEARCH ='qichacha_search_20160603'$/;"	v
COOKIE_INDEX_FETCH	projects/qichacha/business/crawljob.py	/^COOKIE_INDEX_FETCH = "fetch"$/;"	v
COOKIE_INDEX_PREFETCH	projects/qichacha/business/crawljob.py	/^COOKIE_INDEX_PREFETCH = "prefetch"$/;"	v
COOKIE_INDEX_SEARCH	projects/qichacha/business/crawljob.py	/^COOKIE_INDEX_SEARCH = "search"$/;"	v
COOKIE_INDEX_TEST	projects/qichacha/business/crawljob.py	/^COOKIE_INDEX_TEST = "test"$/;"	v
COOKIE_INDEX_VIP	projects/qichacha/business/crawljob.py	/^COOKIE_INDEX_VIP = "vip"$/;"	v
Cache	projects/qichacha/business/crawljob.py	/^from core.cache import Cache$/;"	i
FILE_CONFIG	projects/qichacha/business/crawljob.py	/^FILE_CONFIG = getTheFile("..\/config\/conf.fs.json")$/;"	v
Qichacha	projects/qichacha/business/crawljob.py	/^from core.qichacha2 import Qichacha$/;"	i
_cache_rawitem	projects/qichacha/business/crawljob.py	/^def _cache_rawitem(config, rawitem):$/;"	f
_fetch_with_cache	projects/qichacha/business/crawljob.py	/^def _fetch_with_cache(key_num, name, crawler, fetch_tag, counter, cache_only=False):$/;"	f
_get_fetch_company_uri	projects/qichacha/business/crawljob.py	/^def _get_fetch_company_uri(fetch_tag, key_num):$/;"	f
_get_fetch_index	projects/qichacha/business/crawljob.py	/^def _get_fetch_index(filename_fetch_index):$/;"	f
_get_json	projects/qichacha/business/crawljob.py	/^def _get_json(config, batch_id, uri):$/;"	f
_get_rawitem_uri	projects/qichacha/business/crawljob.py	/^def _get_rawitem_uri(key_num):$/;"	f
_get_search_index	projects/qichacha/business/crawljob.py	/^def _get_search_index(filename_search_index):$/;"	f
_get_search_keyword_uri	projects/qichacha/business/crawljob.py	/^def _get_search_keyword_uri(stype, keyword):$/;"	f
_put_json	projects/qichacha/business/crawljob.py	/^def _put_json(config, batch_id, uri, data):$/;"	f
codecs	projects/qichacha/business/crawljob.py	/^import codecs$/;"	i
collections	projects/qichacha/business/crawljob.py	/^import collections$/;"	i
crawl_search	projects/qichacha/business/crawljob.py	/^def crawl_search(batch, path_expr, limit=None, refresh=False, worker_id=None, worker_num=1, cookie_index=COOKIE_INDEX_SEARCH):$/;"	f
crawl_search_pass	projects/qichacha/business/crawljob.py	/^def crawl_search_pass( seeds, search_option, searched, filename_search_index=None, limit=None, refresh=None, skip_index_max=None, worker_id=None, worker_num=1, cookie_index=None):$/;"	f
datetime	projects/qichacha/business/crawljob.py	/^import datetime$/;"	i
defaultdict	projects/qichacha/business/crawljob.py	/^from collections import defaultdict$/;"	i
expand_agent	projects/qichacha/business/crawljob.py	/^def expand_agent(batch, limit=5):$/;"	f
expand_agent_pass1	projects/qichacha/business/crawljob.py	/^def expand_agent_pass1(front_agents, company_raw, company_name_selected, depth):$/;"	f
expand_agent_pass2	projects/qichacha/business/crawljob.py	/^def expand_agent_pass2(front_agents, company_raw, company_name_selected, depth):$/;"	f
expand_get_tree	projects/qichacha/business/crawljob.py	/^def expand_get_tree(selected, company_raw):$/;"	f
expand_putian	projects/qichacha/business/crawljob.py	/^def expand_putian(batch, limit=10):$/;"	f
expand_putian_pass	projects/qichacha/business/crawljob.py	/^def expand_putian_pass(front, company_raw, map_agent_related, depth):$/;"	f
expand_stat	projects/qichacha/business/crawljob.py	/^def expand_stat(front_agents, company_raw, depth):$/;"	f
fetch_detail	projects/qichacha/business/crawljob.py	/^def fetch_detail(batch, worker_id=None, worker_num=1, expand=True, cookie_index=COOKIE_INDEX_PREFETCH, refresh=False):$/;"	f
fetch_output_all	projects/qichacha/business/crawljob.py	/^def fetch_output_all(batch):$/;"	f
fetch_output_putian	projects/qichacha/business/crawljob.py	/^def fetch_output_putian(batch):$/;"	f
fetch_prepare_all	projects/qichacha/business/crawljob.py	/^def fetch_prepare_all(batch):$/;"	f
gcounter	projects/qichacha/business/crawljob.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/qichacha/business/crawljob.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/qichacha/business/crawljob.py	/^def getTheFile(filename):$/;"	f
get_company_putian_index	projects/qichacha/business/crawljob.py	/^def get_company_putian_index(batch, tag):$/;"	f
get_crawler	projects/qichacha/business/crawljob.py	/^def get_crawler(batch_id, option, worker_id=None, worker_num=None, cache_only=False):$/;"	f
get_filename_search_index	projects/qichacha/business/crawljob.py	/^def get_filename_search_index(batch):$/;"	f
glob	projects/qichacha/business/crawljob.py	/^import glob$/;"	i
hashlib	projects/qichacha/business/crawljob.py	/^import hashlib$/;"	i
init_dir	projects/qichacha/business/crawljob.py	/^def init_dir(batch):$/;"	f
json	projects/qichacha/business/crawljob.py	/^import json$/;"	i
libfile	projects/qichacha/business/crawljob.py	/^import libfile$/;"	i
libnlp	projects/qichacha/business/crawljob.py	/^import libnlp$/;"	i
load_candidates_skip	projects/qichacha/business/crawljob.py	/^def load_candidates_skip(batch):$/;"	f
logging	projects/qichacha/business/crawljob.py	/^import logging$/;"	i
lxml	projects/qichacha/business/crawljob.py	/^    import lxml$/;"	i
main	projects/qichacha/business/crawljob.py	/^def main():$/;"	f
os	projects/qichacha/business/crawljob.py	/^import os$/;"	i
re	projects/qichacha/business/crawljob.py	/^import re$/;"	i
stat	projects/qichacha/business/crawljob.py	/^def stat(batch):$/;"	f
sys	projects/qichacha/business/crawljob.py	/^import sys$/;"	i
test	projects/qichacha/business/crawljob.py	/^def test():$/;"	f
test2	projects/qichacha/business/crawljob.py	/^def test2():$/;"	f
test3	projects/qichacha/business/crawljob.py	/^def test3():$/;"	f
test_cache_get	projects/qichacha/business/crawljob.py	/^def test_cache_get(keyword, index, page, province):$/;"	f
test_cookie	projects/qichacha/business/crawljob.py	/^def test_cookie(limit=None):$/;"	f
test_count	projects/qichacha/business/crawljob.py	/^def test_count():$/;"	f
test_count_x	projects/qichacha/business/crawljob.py	/^def test_count_x(keyword, index, page, province):$/;"	f
test_fetch	projects/qichacha/business/crawljob.py	/^def test_fetch(name, key_num):$/;"	f
test_search	projects/qichacha/business/crawljob.py	/^def test_search():$/;"	f
traceback	projects/qichacha/business/crawljob.py	/^            import traceback$/;"	i
traceback	projects/qichacha/business/crawljob.py	/^        import traceback$/;"	i
CityData	projects/qichacha/business/libcity.py	/^class CityData():$/;"	c
LIST_NATIONAL	projects/qichacha/business/libcity.py	/^LIST_NATIONAL= [$/;"	v
PATTERN_NATIONAL	projects/qichacha/business/libcity.py	/^PATTERN_NATIONAL = u'({})'.format(u'|'.join(LIST_NATIONAL))$/;"	v
PATTERN_NATIONAL2	projects/qichacha/business/libcity.py	/^PATTERN_NATIONAL2 = u'({})'.format(u'?|'.join([x for x in LIST_NATIONAL if len(x)>2]))$/;"	v
__init__	projects/qichacha/business/libcity.py	/^    def __init__(self):$/;"	m	class:CityData
_get_list_province_unique	projects/qichacha/business/libcity.py	/^    def _get_list_province_unique(self, list_citycode):$/;"	m	class:CityData
codecs	projects/qichacha/business/libcity.py	/^import codecs$/;"	i
collections	projects/qichacha/business/libcity.py	/^import collections$/;"	i
datetime	projects/qichacha/business/libcity.py	/^import datetime$/;"	i
defaultdict	projects/qichacha/business/libcity.py	/^from collections import defaultdict$/;"	i
gcounter	projects/qichacha/business/libcity.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/qichacha/business/libcity.py	/^def getTheFile(filename):$/;"	f
glob	projects/qichacha/business/libcity.py	/^import glob$/;"	i
guess_province	projects/qichacha/business/libcity.py	/^    def guess_province(self, addresses):$/;"	m	class:CityData
hashlib	projects/qichacha/business/libcity.py	/^import hashlib$/;"	i
json	projects/qichacha/business/libcity.py	/^import json$/;"	i
main	projects/qichacha/business/libcity.py	/^def main():$/;"	f
normalize_city	projects/qichacha/business/libcity.py	/^def normalize_city(name):$/;"	f
normalize_district	projects/qichacha/business/libcity.py	/^def normalize_district(name):$/;"	f
normalize_national	projects/qichacha/business/libcity.py	/^def normalize_national(name):$/;"	f
normalize_province	projects/qichacha/business/libcity.py	/^def normalize_province(name):$/;"	f
os	projects/qichacha/business/libcity.py	/^import os$/;"	i
re	projects/qichacha/business/libcity.py	/^import re$/;"	i
show_help	projects/qichacha/business/libcity.py	/^def show_help():$/;"	f
stat	projects/qichacha/business/libcity.py	/^    def stat(self):$/;"	m	class:CityData
sys	projects/qichacha/business/libcity.py	/^import sys$/;"	i
test	projects/qichacha/business/libcity.py	/^def test():$/;"	f
codecs	projects/qichacha/business/libfile.py	/^import codecs$/;"	i
collections	projects/qichacha/business/libfile.py	/^import collections$/;"	i
defaultdict	projects/qichacha/business/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/qichacha/business/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/qichacha/business/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/qichacha/business/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/qichacha/business/libfile.py	/^import glob$/;"	i
hashlib	projects/qichacha/business/libfile.py	/^import hashlib$/;"	i
items2file	projects/qichacha/business/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/qichacha/business/libfile.py	/^import json$/;"	i
json2file	projects/qichacha/business/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/qichacha/business/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/qichacha/business/libfile.py	/^import os$/;"	i
re	projects/qichacha/business/libfile.py	/^import re$/;"	i
readExcel	projects/qichacha/business/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1):$/;"	f
sys	projects/qichacha/business/libfile.py	/^import sys$/;"	i
writeExcel	projects/qichacha/business/libfile.py	/^def writeExcel(items, keys, filename):$/;"	f
xlrd	projects/qichacha/business/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/qichacha/business/libfile.py	/^    import xlwt$/;"	i
classify_agent_type	projects/qichacha/business/libnlp.py	/^def classify_agent_type(name):$/;"	f
classify_agent_type2	projects/qichacha/business/libnlp.py	/^def classify_agent_type2(name):$/;"	f
classify_company_name	projects/qichacha/business/libnlp.py	/^def classify_company_name(name):$/;"	f
classify_company_name_medical	projects/qichacha/business/libnlp.py	/^def classify_company_name_medical(name, strict):$/;"	f
classify_default	projects/qichacha/business/libnlp.py	/^def classify_default(name):$/;"	f
classify_hospital	projects/qichacha/business/libnlp.py	/^def classify_hospital(name):$/;"	f
classify_invest	projects/qichacha/business/libnlp.py	/^def classify_invest(name):$/;"	f
classify_medical_invests	projects/qichacha/business/libnlp.py	/^def classify_medical_invests(name):$/;"	f
codecs	projects/qichacha/business/libnlp.py	/^import codecs$/;"	i
collections	projects/qichacha/business/libnlp.py	/^import collections$/;"	i
datetime	projects/qichacha/business/libnlp.py	/^import datetime$/;"	i
defaultdict	projects/qichacha/business/libnlp.py	/^from collections import defaultdict$/;"	i
get_item_name	projects/qichacha/business/libnlp.py	/^def get_item_name(item):$/;"	f
get_keywords	projects/qichacha/business/libnlp.py	/^def get_keywords(sentences, regex_skip_word,  limit=100 ):$/;"	f
glob	projects/qichacha/business/libnlp.py	/^import glob$/;"	i
hashlib	projects/qichacha/business/libnlp.py	/^import hashlib$/;"	i
is_label_medical	projects/qichacha/business/libnlp.py	/^def is_label_medical(label, strict=True):$/;"	f
is_rawitem_putian_canidate	projects/qichacha/business/libnlp.py	/^def is_rawitem_putian_canidate(rawitem, putian_list, min_intersection=1):$/;"	f
jieba	projects/qichacha/business/libnlp.py	/^    import jieba$/;"	i
json	projects/qichacha/business/libnlp.py	/^import json$/;"	i
list_item_agent_name	projects/qichacha/business/libnlp.py	/^def list_item_agent_name(item, includeme=False, skip=None, exclusive=None):$/;"	f
os	projects/qichacha/business/libnlp.py	/^import os$/;"	i
re	projects/qichacha/business/libnlp.py	/^import re$/;"	i
sys	projects/qichacha/business/libnlp.py	/^import sys$/;"	i
getTheFile	projects/qichacha/business/testpagerank.py	/^def getTheFile(filename):$/;"	f
name	projects/qichacha/business/testpagerank.py	/^def name():$/;"	f
nx	projects/qichacha/business/testpagerank.py	/^import networkx as nx$/;"	i
os	projects/qichacha/business/testpagerank.py	/^import os$/;"	i
personal	projects/qichacha/business/testpagerank.py	/^def personal():$/;"	f
scale	projects/qichacha/business/testpagerank.py	/^def scale():$/;"	f
weight	projects/qichacha/business/testpagerank.py	/^def weight():$/;"	f
AGENTS	projects/qichacha/core/agents.py	/^AGENTS=["Mozilla\/5.0 (X11; Linux x86_64; rv:27.0) Gecko\/20100101 Firefox\/27.0"]$/;"	v
AGENTS_ALL	projects/qichacha/core/agents.py	/^AGENTS_ALL = [$/;"	v
AGENT_GOOGLE_IMAGE	projects/qichacha/core/agents.py	/^AGENT_GOOGLE_IMAGE=["Googlebot-Image\/1.0"]$/;"	v
Cache	projects/qichacha/core/cache.py	/^class Cache(object):$/;"	c
__init__	projects/qichacha/core/cache.py	/^    def __init__(self, config, batch_id, server=None):$/;"	m	class:Cache
base64	projects/qichacha/core/cache.py	/^import base64$/;"	i
division	projects/qichacha/core/cache.py	/^from __future__ import print_function, division$/;"	i
get	projects/qichacha/core/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/qichacha/core/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/qichacha/core/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/qichacha/core/cache.py	/^import requests$/;"	i
urlparse	projects/qichacha/core/cache.py	/^import urlparse$/;"	i
Cache	projects/qichacha/core/downloader.py	/^from cache import Cache$/;"	i
Downloader	projects/qichacha/core/downloader.py	/^class Downloader(object):$/;"	c
Proxy	projects/qichacha/core/downloader.py	/^from proxy import Proxy$/;"	i
__init__	projects/qichacha/core/downloader.py	/^    def __init__(self, config, request=False, batch_id='', groups=None, refresh=False, cache_only=False):$/;"	m	class:Downloader
_get_sleep_period	projects/qichacha/core/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
access_page_with_cache	projects/qichacha/core/downloader.py	/^    def access_page_with_cache(self, url, groups=None, refresh=False):$/;"	m	class:Downloader
check_content_invalid	projects/qichacha/core/downloader.py	/^    def check_content_invalid(self, content):$/;"	m	class:Downloader
choice_agent	projects/qichacha/core/downloader.py	/^from headers import choice_agent, choice_proxy$/;"	i
choice_proxy	projects/qichacha/core/downloader.py	/^from headers import choice_agent, choice_proxy$/;"	i
close	projects/qichacha/core/downloader.py	/^    def close(self):$/;"	m	class:Downloader
collections	projects/qichacha/core/downloader.py	/^import collections$/;"	i
division	projects/qichacha/core/downloader.py	/^from __future__ import print_function, division$/;"	i
get_a_cookie	projects/qichacha/core/downloader.py	/^    def get_a_cookie(self):$/;"	m	class:Downloader
get_cur_cookie	projects/qichacha/core/downloader.py	/^    def get_cur_cookie(self):$/;"	m	class:Downloader
json	projects/qichacha/core/downloader.py	/^import json$/;"	i
login	projects/qichacha/core/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/qichacha/core/downloader.py	/^import os$/;"	i
pick_cookie_agent_proxy	projects/qichacha/core/downloader.py	/^    def pick_cookie_agent_proxy(self, url):$/;"	m	class:Downloader
print_function	projects/qichacha/core/downloader.py	/^from __future__ import print_function, division$/;"	i
random	projects/qichacha/core/downloader.py	/^import random$/;"	i
re	projects/qichacha/core/downloader.py	/^        import re$/;"	i
request_download	projects/qichacha/core/downloader.py	/^    def request_download(self, url):$/;"	m	class:Downloader
requests	projects/qichacha/core/downloader.py	/^import requests$/;"	i
save_cache	projects/qichacha/core/downloader.py	/^        def save_cache(url, content, groups, refresh):$/;"	f	function:Downloader.access_page_with_cache
selenium_download	projects/qichacha/core/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
split_url	projects/qichacha/core/downloader.py	/^    def split_url(self, url):$/;"	m	class:Downloader
sys	projects/qichacha/core/downloader.py	/^import sys$/;"	i
time	projects/qichacha/core/downloader.py	/^import time$/;"	i
urllib	projects/qichacha/core/downloader.py	/^        import urllib$/;"	i
webdriver	projects/qichacha/core/downloader.py	/^            from selenium import webdriver$/;"	i
AGENTS_ALL	projects/qichacha/core/headers.py	/^from agents import AGENTS_ALL$/;"	i
OrderedDict	projects/qichacha/core/headers.py	/^from collections import OrderedDict$/;"	i
Proxy	projects/qichacha/core/headers.py	/^from proxy import Proxy$/;"	i
choice_agent	projects/qichacha/core/headers.py	/^def choice_agent():$/;"	f
choice_cookie	projects/qichacha/core/headers.py	/^def choice_cookie(cookies):$/;"	f
choice_proxy	projects/qichacha/core/headers.py	/^def choice_proxy(config, url):$/;"	f
division	projects/qichacha/core/headers.py	/^from __future__ import print_function, division$/;"	i
print_function	projects/qichacha/core/headers.py	/^from __future__ import print_function, division$/;"	i
random	projects/qichacha/core/headers.py	/^import random$/;"	i
time	projects/qichacha/core/headers.py	/^import time$/;"	i
Proxy	projects/qichacha/core/proxy.py	/^class Proxy(object):$/;"	c
__init__	projects/qichacha/core/proxy.py	/^    def __init__(self, config, server=None):$/;"	m	class:Proxy
base64	projects/qichacha/core/proxy.py	/^import base64$/;"	i
division	projects/qichacha/core/proxy.py	/^from __future__ import print_function, division$/;"	i
get	projects/qichacha/core/proxy.py	/^    def get(self, url, max_last_time):$/;"	m	class:Proxy
instance	projects/qichacha/core/proxy.py	/^    def instance(cls):$/;"	m	class:Proxy
post	projects/qichacha/core/proxy.py	/^    def post(self, url, proxy):$/;"	m	class:Proxy
print_function	projects/qichacha/core/proxy.py	/^from __future__ import print_function, division$/;"	i
requests	projects/qichacha/core/proxy.py	/^import requests$/;"	i
urlparse	projects/qichacha/core/proxy.py	/^import urlparse$/;"	i
Downloader	projects/qichacha/core/qichacha.py	/^from downloader import Downloader$/;"	i
QiParser	projects/qichacha/core/qichacha.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/qichacha/core/qichacha.py	/^class Qichacha(object):$/;"	c
__init__	projects/qichacha/core/qichacha.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/qichacha/core/qichacha.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/qichacha/core/qichacha.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/qichacha/core/qichacha.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/qichacha/core/qichacha.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/qichacha/core/qichacha.py	/^import collections$/;"	i
crawl_ancestors_company	projects/qichacha/core/qichacha.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/qichacha/core/qichacha.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_investment	projects/qichacha/core/qichacha.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/qichacha/core/qichacha.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/qichacha/core/qichacha.py	/^from __future__ import print_function, division$/;"	i
etree	projects/qichacha/core/qichacha.py	/^import lxml.etree$/;"	i
get_keyword_search_count	projects/qichacha/core/qichacha.py	/^    def get_keyword_search_count(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/qichacha/core/qichacha.py	/^import lxml.html$/;"	i
input_name_output_id	projects/qichacha/core/qichacha.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/qichacha/core/qichacha.py	/^import json$/;"	i
list_keyword_search	projects/qichacha/core/qichacha.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/qichacha/core/qichacha.py	/^    def list_keyword_search_onepass(self, keyword, index, province, max_page, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/qichacha/core/qichacha.py	/^import lxml.etree$/;"	i
lxml	projects/qichacha/core/qichacha.py	/^import lxml.html$/;"	i
print_function	projects/qichacha/core/qichacha.py	/^from __future__ import print_function, division$/;"	i
re	projects/qichacha/core/qichacha.py	/^import re$/;"	i
urllib	projects/qichacha/core/qichacha.py	/^import urllib$/;"	i
Downloader	projects/qichacha/core/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	projects/qichacha/core/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/qichacha/core/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	projects/qichacha/core/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/qichacha/core/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/qichacha/core/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/qichacha/core/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/qichacha/core/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/qichacha/core/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	projects/qichacha/core/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/qichacha/core/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	projects/qichacha/core/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	projects/qichacha/core/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/qichacha/core/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/qichacha/core/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	projects/qichacha/core/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	projects/qichacha/core/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	projects/qichacha/core/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/qichacha/core/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	projects/qichacha/core/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/qichacha/core/qichacha2.py	/^import json$/;"	i
list_keyword_search	projects/qichacha/core/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/qichacha/core/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/qichacha/core/qichacha2.py	/^import lxml.etree$/;"	i
lxml	projects/qichacha/core/qichacha2.py	/^import lxml.html$/;"	i
print_function	projects/qichacha/core/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	projects/qichacha/core/qichacha2.py	/^import re$/;"	i
traceback	projects/qichacha/core/qichacha2.py	/^            import traceback$/;"	i
urllib	projects/qichacha/core/qichacha2.py	/^import urllib$/;"	i
QiParser	projects/qichacha/core/qiparser.py	/^class QiParser(object):$/;"	c
__init__	projects/qichacha/core/qiparser.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/qichacha/core/qiparser.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/qichacha/core/qiparser.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/qichacha/core/qiparser.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/qichacha/core/qiparser.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/qichacha/core/qiparser.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/qichacha/core/qiparser.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_count	projects/qichacha/core/qiparser.py	/^    def parse_search_result_count(self, tree):$/;"	m	class:QiParser
print_function	projects/qichacha/core/qiparser.py	/^from __future__ import print_function, division$/;"	i
re	projects/qichacha/core/qiparser.py	/^import re$/;"	i
string	projects/qichacha/core/qiparser.py	/^import string$/;"	i
QiParser	projects/qichacha/core/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	projects/qichacha/core/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/qichacha/core/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/qichacha/core/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/qichacha/core/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/qichacha/core/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/qichacha/core/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/qichacha/core/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	projects/qichacha/core/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	projects/qichacha/core/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	projects/qichacha/core/qiparser2.py	/^import re$/;"	i
string	projects/qichacha/core/qiparser2.py	/^import string$/;"	i
Qichacha	projects/qichacha/tests/test_api.py	/^from core.qichacha import Qichacha$/;"	i
division	projects/qichacha/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
filename	projects/qichacha/tests/test_api.py	/^filename = getTheFile("..\/config\/conf.179.json")$/;"	v
getTheFile	projects/qichacha/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/qichacha/tests/test_api.py	/^import json$/;"	i
os	projects/qichacha/tests/test_api.py	/^import os$/;"	i
print_function	projects/qichacha/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
qichacha	projects/qichacha/tests/test_api.py	/^qichacha = Qichacha(config, batch_id='qichacha', groups='哈药')$/;"	v
sys	projects/qichacha/tests/test_api.py	/^import sys$/;"	i
test_ancestors	projects/qichacha/tests/test_api.py	/^def test_ancestors():$/;"	f
test_descendant	projects/qichacha/tests/test_api.py	/^def test_descendant():$/;"	f
test_detail	projects/qichacha/tests/test_api.py	/^def test_detail():$/;"	f
test_search_corporate	projects/qichacha/tests/test_api.py	/^def test_search_corporate():$/;"	f
test_search_corporate_count	projects/qichacha/tests/test_api.py	/^def test_search_corporate_count():$/;"	f
test_search_person	projects/qichacha/tests/test_api.py	/^def test_search_person():$/;"	f
Proxy	projects/qichacha/tests/test_proxy.py	/^from core.proxy import Proxy$/;"	i
choice_proxy	projects/qichacha/tests/test_proxy.py	/^from core.headers import choice_proxy$/;"	i
division	projects/qichacha/tests/test_proxy.py	/^from __future__ import print_function, division$/;"	i
print_function	projects/qichacha/tests/test_proxy.py	/^from __future__ import print_function, division$/;"	i
PRIVATE_KEY	projects/ruyiapitest/monitor.py	/^from secret import PUBLIC_KEY, PRIVATE_KEY$/;"	i
PUBLIC_KEY	projects/ruyiapitest/monitor.py	/^from secret import PUBLIC_KEY, PRIVATE_KEY$/;"	i
UlbPolicyClient	projects/ruyiapitest/monitor.py	/^class UlbPolicyClient(object):$/;"	c
__init__	projects/ruyiapitest/monitor.py	/^    def __init__(self, match):$/;"	m	class:UlbPolicyClient
backends	projects/ruyiapitest/monitor.py	/^backends = [$/;"	v
convert_backend_toanoter	projects/ruyiapitest/monitor.py	/^def convert_backend_toanoter(policy, working_ms):$/;"	f
create_policy	projects/ruyiapitest/monitor.py	/^    def create_policy(self, backend):$/;"	m	class:UlbPolicyClient
delete_policy	projects/ruyiapitest/monitor.py	/^    def delete_policy(self):$/;"	m	class:UlbPolicyClient
find_policy	projects/ruyiapitest/monitor.py	/^    def find_policy(self):$/;"	m	class:UlbPolicyClient
get_another_backend	projects/ruyiapitest/monitor.py	/^def get_another_backend(backend_id):$/;"	f
get_policy_id	projects/ruyiapitest/monitor.py	/^    def get_policy_id(self):$/;"	m	class:UlbPolicyClient
get_running_stat	projects/ruyiapitest/monitor.py	/^def get_running_stat(url_temlate):$/;"	f
get_signature	projects/ruyiapitest/monitor.py	/^    def get_signature(self, paras):$/;"	m	class:UlbPolicyClient
get_working_backend_id	projects/ruyiapitest/monitor.py	/^    def get_working_backend_id(self):$/;"	m	class:UlbPolicyClient
hashlib	projects/ruyiapitest/monitor.py	/^import hashlib$/;"	i
json	projects/ruyiapitest/monitor.py	/^import json$/;"	i
main	projects/ruyiapitest/monitor.py	/^def main(policy_name):$/;"	f
random	projects/ruyiapitest/monitor.py	/^import random$/;"	i
random_url	projects/ruyiapitest/monitor.py	/^def random_url(url, length=4):$/;"	f
requests	projects/ruyiapitest/monitor.py	/^import requests$/;"	i
slack	projects/ruyiapitest/monitor.py	/^def slack(msg):$/;"	f
string	projects/ruyiapitest/monitor.py	/^import string$/;"	i
time	projects/ruyiapitest/monitor.py	/^import time$/;"	i
update_policy	projects/ruyiapitest/monitor.py	/^    def update_policy(self, backend):$/;"	m	class:UlbPolicyClient
update_policy_group_attribute	projects/ruyiapitest/monitor.py	/^    def update_policy_group_attribute(self):$/;"	m	class:UlbPolicyClient
urllib	projects/ruyiapitest/monitor.py	/^import urllib$/;"	i
urlparse	projects/ruyiapitest/monitor.py	/^import urlparse$/;"	i
HOME	projects/ucloudbackup/backup.py	/^HOME = '\/data\/baidu_dir\/back'$/;"	v
PRIVATE_KEY	projects/ucloudbackup/backup.py	/^from secret import PUBLIC_KEY, PRIVATE_KEY$/;"	i
PUBLIC_KEY	projects/ucloudbackup/backup.py	/^from secret import PUBLIC_KEY, PRIVATE_KEY$/;"	i
UcloudApiClient	projects/ucloudbackup/backup.py	/^class UcloudApiClient(object):$/;"	c
__init__	projects/ucloudbackup/backup.py	/^    def __init__(self, public_key, private_key, region='cn-bj2', DBId='udb-sbjftb'):$/;"	m	class:UcloudApiClient
check_folders	projects/ucloudbackup/backup.py	/^def check_folders():$/;"	f
datetime	projects/ucloudbackup/backup.py	/^import datetime$/;"	i
download_newest_backup	projects/ucloudbackup/backup.py	/^def download_newest_backup(folder):$/;"	f
get_newest_backup_id	projects/ucloudbackup/backup.py	/^    def get_newest_backup_id(self):$/;"	m	class:UcloudApiClient
get_newest_backup_url	projects/ucloudbackup/backup.py	/^    def get_newest_backup_url(self):$/;"	m	class:UcloudApiClient
get_signature	projects/ucloudbackup/backup.py	/^    def get_signature(self, params):$/;"	m	class:UcloudApiClient
hashlib	projects/ucloudbackup/backup.py	/^import hashlib$/;"	i
json	projects/ucloudbackup/backup.py	/^import json$/;"	i
main	projects/ucloudbackup/backup.py	/^def main():$/;"	f
os	projects/ucloudbackup/backup.py	/^import os$/;"	i
re	projects/ucloudbackup/backup.py	/^import re$/;"	i
requests	projects/ucloudbackup/backup.py	/^import requests$/;"	i
urllib	projects/ucloudbackup/backup.py	/^import urllib$/;"	i
urlparse	projects/ucloudbackup/backup.py	/^import urlparse$/;"	i
MongoClient	projects/ucloudbackup/check.py	/^from pymongo import MongoClient$/;"	i
STANDARD_COLLECTION_LIST	projects/ucloudbackup/check.py	/^STANDARD_COLLECTION_LIST = [u'intentScenario', $/;"	v
check_time	projects/ucloudbackup/check.py	/^def check_time():$/;"	f
client	projects/ucloudbackup/check.py	/^client = MongoClient()$/;"	v
collection_list	projects/ucloudbackup/check.py	/^collection_list = db.collection_names()$/;"	v
datetime	projects/ucloudbackup/check.py	/^import time,datetime$/;"	i
db	projects/ucloudbackup/check.py	/^db = client.today$/;"	v
flag_collection	projects/ucloudbackup/check.py	/^flag_collection = (sorted(collection_list) == sorted(STANDARD_COLLECTION_LIST))$/;"	v
restore	projects/ucloudbackup/check.py	/^from restore import restore$/;"	i
slack	projects/ucloudbackup/check.py	/^def slack(msg):$/;"	f
statistic	projects/ucloudbackup/check.py	/^def statistic():$/;"	f
time	projects/ucloudbackup/check.py	/^import time,datetime$/;"	i
unpack	projects/ucloudbackup/check.py	/^from unpack import unpack$/;"	i
find_deep_path	projects/ucloudbackup/restore.py	/^def find_deep_path(current):$/;"	f
os	projects/ucloudbackup/restore.py	/^import os$/;"	i
restore	projects/ucloudbackup/restore.py	/^def restore():$/;"	f
MongoClient	projects/ucloudbackup/unpack.py	/^from pymongo import MongoClient$/;"	i
datetime	projects/ucloudbackup/unpack.py	/^import datetime$/;"	i
from_path	projects/ucloudbackup/unpack.py	/^from_path = '\/data\/baidu_dir\/back\/{}\/{}'$/;"	v
get_real_path	projects/ucloudbackup/unpack.py	/^def get_real_path():$/;"	f
json	projects/ucloudbackup/unpack.py	/^import json$/;"	i
os	projects/ucloudbackup/unpack.py	/^import os$/;"	i
output_name	projects/ucloudbackup/unpack.py	/^output_name = 'ucloud_mongon_udb_backup_{}.tgz'.format(datetime.datetime.now().strftime('%Y%m%d'))$/;"	v
pymongo	projects/ucloudbackup/unpack.py	/^import pymongo$/;"	i
requests	projects/ucloudbackup/unpack.py	/^import requests$/;"	i
subprocess	projects/ucloudbackup/unpack.py	/^import subprocess$/;"	i
to_path	projects/ucloudbackup/unpack.py	/^to_path   = '\/data\/monitor\/check'$/;"	v
unpack	projects/ucloudbackup/unpack.py	/^def unpack():$/;"	f
KEY	projects/weathercache/weather.py	/^KEY = 'ruyi-action-heweather-cache'$/;"	v
citys	projects/weathercache/weather.py	/^citys = []$/;"	v
content	projects/weathercache/weather.py	/^    content = requests.get(url+date)$/;"	v
count	projects/weathercache/weather.py	/^count = 0$/;"	v
date	projects/weathercache/weather.py	/^date = now.strftime("%Y-%m-%d")$/;"	v
datetime	projects/weathercache/weather.py	/^import datetime$/;"	i
f	projects/weathercache/weather.py	/^f = open(file_name, 'r')$/;"	v
field	projects/weathercache/weather.py	/^    field = '{}_{}'.format(date, city)$/;"	v
file_name	projects/weathercache/weather.py	/^file_name = '\/Users\/johnson\/my\/cache_city_list.txt'$/;"	v
ip_10	projects/weathercache/weather.py	/^ip_10 ='10.10.84.141'$/;"	v
ip_179	projects/weathercache/weather.py	/^ip_179 = '192.168.1.179'$/;"	v
now	projects/weathercache/weather.py	/^now =  datetime.datetime.now()$/;"	v
r	projects/weathercache/weather.py	/^r = redis.Redis(host = ip_179, port=6379, db=0)$/;"	v
redis	projects/weathercache/weather.py	/^import redis$/;"	i
requests	projects/weathercache/weather.py	/^import requests$/;"	i
XiamiDataMover	projects/xiami/xiami_cleansing.py	/^class XiamiDataMover(object):$/;"	c
a	projects/xiami/xiami_cleansing.py	/^    a = XiamiDataMover()$/;"	v	class:XiamiDataMover
datetime	projects/xiami/xiami_cleansing.py	/^import datetime$/;"	i
hashlib	projects/xiami/xiami_cleansing.py	/^import hashlib$/;"	i
hprice_cleaning	projects/xiami/xiami_cleansing.py	/^from cleansing_hcrawler import  hprice_cleaning$/;"	i
os	projects/xiami/xiami_cleansing.py	/^import os$/;"	i
paramiko	projects/xiami/xiami_cleansing.py	/^import paramiko$/;"	i
pytz	projects/xiami/xiami_cleansing.py	/^import pytz$/;"	i
read_and_insert	projects/xiami/xiami_cleansing.py	/^    def read_and_insert(self, dir_path):$/;"	m	class:XiamiDataMover
set_directory_list	projects/xiami/xiami_cleansing.py	/^    def set_directory_list(self):$/;"	m	class:XiamiDataMover
sys	projects/xiami/xiami_cleansing.py	/^import sys$/;"	i
time	projects/xiami/xiami_cleansing.py	/^import time$/;"	i
download_all_artists	projects/xiami/xiami_failed_save_artist.py	/^def download_all_artists():$/;"	f
header	projects/xiami/xiami_failed_save_artist.py	/^header = {$/;"	v
html	projects/xiami/xiami_failed_save_artist.py	/^import lxml.html$/;"	i
json	projects/xiami/xiami_failed_save_artist.py	/^import json$/;"	i
lxml	projects/xiami/xiami_failed_save_artist.py	/^import lxml.html$/;"	i
os	projects/xiami/xiami_failed_save_artist.py	/^import os$/;"	i
parse_all_artists	projects/xiami/xiami_failed_save_artist.py	/^def parse_all_artists():$/;"	f
path	projects/xiami/xiami_failed_save_artist.py	/^path = '\/Users\/bishop\/Documents\/海知智能\/xiami'$/;"	v
requests	projects/xiami/xiami_failed_save_artist.py	/^import requests$/;"	i
time	projects/xiami/xiami_failed_save_artist.py	/^import time$/;"	i
SITE	projects/yaodian/yaodian.py	/^SITE = "http:\/\/www.yaobiaozhun.com\/yd2015\/"$/;"	v
codecs	projects/yaodian/yaodian.py	/^import codecs$/;"	i
datetime	projects/yaodian/yaodian.py	/^from datetime import datetime$/;"	i
etree	projects/yaodian/yaodian.py	/^from lxml import etree$/;"	i
has_key	projects/yaodian/yaodian.py	/^def has_key(info, key):$/;"	f
hashlib	projects/yaodian/yaodian.py	/^import hashlib$/;"	i
json	projects/yaodian/yaodian.py	/^import json$/;"	i
parse	projects/yaodian/yaodian.py	/^def parse(detail, index, lurl):$/;"	f
re	projects/yaodian/yaodian.py	/^import re$/;"	i
requests	projects/yaodian/yaodian.py	/^import requests$/;"	i
run	projects/yaodian/yaodian.py	/^def run():$/;"	f
sys	projects/yaodian/yaodian.py	/^import sys$/;"	i
time	projects/yaodian/yaodian.py	/^import time$/;"	i
Cache	projects/zhidaoprefetch/downloader/cache.py	/^class Cache(object):$/;"	c
__init__	projects/zhidaoprefetch/downloader/cache.py	/^    def __init__(self, batch_id, server):$/;"	m	class:Cache
base64	projects/zhidaoprefetch/downloader/cache.py	/^import base64$/;"	i
division	projects/zhidaoprefetch/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
exists	projects/zhidaoprefetch/downloader/cache.py	/^    def exists(self, url):$/;"	m	class:Cache
get	projects/zhidaoprefetch/downloader/cache.py	/^    def get(self, url):$/;"	m	class:Cache
post	projects/zhidaoprefetch/downloader/cache.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:Cache
print_function	projects/zhidaoprefetch/downloader/cache.py	/^from __future__ import print_function, division$/;"	i
requests	projects/zhidaoprefetch/downloader/cache.py	/^import requests$/;"	i
urlparse	projects/zhidaoprefetch/downloader/cache.py	/^import urlparse$/;"	i
CachePeriod	projects/zhidaoprefetch/downloader/cacheperiod.py	/^class CachePeriod(object):$/;"	c
__init__	projects/zhidaoprefetch/downloader/cacheperiod.py	/^    def __init__(self, batch_id, server):$/;"	m	class:CachePeriod
division	projects/zhidaoprefetch/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
exists	projects/zhidaoprefetch/downloader/cacheperiod.py	/^    def exists(self, url):$/;"	m	class:CachePeriod
get	projects/zhidaoprefetch/downloader/cacheperiod.py	/^    def get(self, url):$/;"	m	class:CachePeriod
hashlib	projects/zhidaoprefetch/downloader/cacheperiod.py	/^import hashlib$/;"	i
post	projects/zhidaoprefetch/downloader/cacheperiod.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CachePeriod
print_function	projects/zhidaoprefetch/downloader/cacheperiod.py	/^from __future__ import print_function, division$/;"	i
requests	projects/zhidaoprefetch/downloader/cacheperiod.py	/^import requests$/;"	i
urlparse	projects/zhidaoprefetch/downloader/cacheperiod.py	/^import urlparse$/;"	i
CacheS3	projects/zhidaoprefetch/downloader/caches3.py	/^class CacheS3(object):$/;"	c
S3Object	projects/zhidaoprefetch/downloader/caches3.py	/^from awsapi.s3object import S3Object$/;"	i
__init__	projects/zhidaoprefetch/downloader/caches3.py	/^    def __init__(self, batch_id, region_name='ap-northeast-1'):$/;"	m	class:CacheS3
division	projects/zhidaoprefetch/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
exists	projects/zhidaoprefetch/downloader/caches3.py	/^    def exists(self, url):$/;"	m	class:CacheS3
get	projects/zhidaoprefetch/downloader/caches3.py	/^    def get(self, url):$/;"	m	class:CacheS3
hashlib	projects/zhidaoprefetch/downloader/caches3.py	/^import hashlib$/;"	i
post	projects/zhidaoprefetch/downloader/caches3.py	/^    def post(self, url, content, groups=None, refresh=False):$/;"	m	class:CacheS3
print_function	projects/zhidaoprefetch/downloader/caches3.py	/^from __future__ import print_function, division$/;"	i
Cache	projects/zhidaoprefetch/downloader/downloader.py	/^            from .cache import Cache$/;"	i
CacheS3	projects/zhidaoprefetch/downloader/downloader.py	/^            from .caches3 import CacheS3$/;"	i
Downloader	projects/zhidaoprefetch/downloader/downloader.py	/^class Downloader(object):$/;"	c
__init__	projects/zhidaoprefetch/downloader/downloader.py	/^    def __init__(self, batch_id, cacheserver=None, request=False, gap=0, timeout=10, groups=None, refresh=False, region_name='ap-northeast-1'):$/;"	m	class:Downloader
_get_sleep_period	projects/zhidaoprefetch/downloader/downloader.py	/^    def _get_sleep_period(self):$/;"	m	class:Downloader
chardet	projects/zhidaoprefetch/downloader/downloader.py	/^            import chardet$/;"	i
close	projects/zhidaoprefetch/downloader/downloader.py	/^    def close(self):$/;"	m	class:Downloader
division	projects/zhidaoprefetch/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
login	projects/zhidaoprefetch/downloader/downloader.py	/^    def login(self):$/;"	m	class:Downloader
os	projects/zhidaoprefetch/downloader/downloader.py	/^import os$/;"	i
print_function	projects/zhidaoprefetch/downloader/downloader.py	/^from __future__ import print_function, division$/;"	i
re	projects/zhidaoprefetch/downloader/downloader.py	/^import re$/;"	i
request_download	projects/zhidaoprefetch/downloader/downloader.py	/^    def request_download(self, url, method='get', encoding=None, redirect_check=False, error_check=False, data=None):$/;"	m	class:Downloader
requests	projects/zhidaoprefetch/downloader/downloader.py	/^import requests$/;"	i
requests_with_cache	projects/zhidaoprefetch/downloader/downloader.py	/^    def requests_with_cache(self,$/;"	m	class:Downloader
save_cache	projects/zhidaoprefetch/downloader/downloader.py	/^        def save_cache(url, source, groups, refresh):$/;"	f	function:Downloader.requests_with_cache
selenium_download	projects/zhidaoprefetch/downloader/downloader.py	/^    def selenium_download(self, url):$/;"	m	class:Downloader
str2unicode	projects/zhidaoprefetch/downloader/downloader.py	/^    def str2unicode(content, encoding=None):$/;"	m	class:Downloader
sys	projects/zhidaoprefetch/downloader/downloader.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/downloader/downloader.py	/^import time$/;"	i
update_header	projects/zhidaoprefetch/downloader/downloader.py	/^    def update_header(self, header):$/;"	m	class:Downloader
url2domain	projects/zhidaoprefetch/downloader/downloader.py	/^    def url2domain(url):$/;"	m	class:Downloader
urlparse	projects/zhidaoprefetch/downloader/downloader.py	/^        from urlparse import urlparse$/;"	i
DownloadWrapper	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^class DownloadWrapper(object):$/;"	c
Downloader	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^from .downloader import Downloader$/;"	i
__init__	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^    def __init__(self, cacheserver=None, headers={}, region_name='ap-northeast-1'):$/;"	m	class:DownloadWrapper
division	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
download_with_cache	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^    def download_with_cache(self, url, batch_id, gap, method, timeout, encoding, redirect_check, error_check, data, refresh):$/;"	m	class:DownloadWrapper
downloader_wrapper	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^    def downloader_wrapper(self,$/;"	m	class:DownloadWrapper
print_function	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^from __future__ import print_function, division$/;"	i
time	projects/zhidaoprefetch/downloader/downloader_wrapper.py	/^import time$/;"	i
CachePeriod	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^from cacheperiod import CachePeriod$/;"	i
LOCAL	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^LOCAL = 'http:\/\/127.0.0.1:8000'$/;"	v
batch_id	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^batch_id = 'chemppi'$/;"	v
json	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^import json$/;"	i
main	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^def main():$/;"	f
requests	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^import requests$/;"	i
test_cache_get	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^def test_cache_get():$/;"	f
test_cache_get_false	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^def test_cache_get_false():$/;"	f
test_cache_post	projects/zhidaoprefetch/downloader/test_cacheperiod.py	/^def test_cache_post():$/;"	f
Downloader	projects/zhidaoprefetch/downloader/test_download.py	/^from downloader import Downloader$/;"	i
chardet	projects/zhidaoprefetch/downloader/test_download.py	/^    import chardet$/;"	i
codecs	projects/zhidaoprefetch/downloader/test_download.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/downloader/test_download.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/downloader/test_download.py	/^import datetime$/;"	i
json	projects/zhidaoprefetch/downloader/test_download.py	/^import json$/;"	i
main	projects/zhidaoprefetch/downloader/test_download.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/downloader/test_download.py	/^import os$/;"	i
re	projects/zhidaoprefetch/downloader/test_download.py	/^import re$/;"	i
requests	projects/zhidaoprefetch/downloader/test_download.py	/^    import requests$/;"	i
sys	projects/zhidaoprefetch/downloader/test_download.py	/^import sys$/;"	i
test_encoding_gb18030_20160619a	projects/zhidaoprefetch/downloader/test_download.py	/^def test_encoding_gb18030_20160619a():$/;"	f
test_encoding_gb18030_20160619b	projects/zhidaoprefetch/downloader/test_download.py	/^def test_encoding_gb18030_20160619b():$/;"	f
test_url2domain	projects/zhidaoprefetch/downloader/test_download.py	/^def test_url2domain():$/;"	f
time	projects/zhidaoprefetch/downloader/test_download.py	/^import time$/;"	i
urllib	projects/zhidaoprefetch/downloader/test_download.py	/^import urllib$/;"	i
INDEX_OPTION_DELETE	projects/zhidaoprefetch/es/es_api.py	/^INDEX_OPTION_DELETE = "delete"$/;"	v
INDEX_OPTION_INDEX	projects/zhidaoprefetch/es/es_api.py	/^INDEX_OPTION_INDEX = "index"$/;"	v
batch_init	projects/zhidaoprefetch/es/es_api.py	/^def batch_init(esconfig, datasets):$/;"	f
batch_stat	projects/zhidaoprefetch/es/es_api.py	/^def batch_stat(datasets):$/;"	f
batch_upload	projects/zhidaoprefetch/es/es_api.py	/^def batch_upload(esconfig, datasets, suffix_esdata, esbulk_size=1000):$/;"	f
codecs	projects/zhidaoprefetch/es/es_api.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/es/es_api.py	/^import collections$/;"	i
es_api_post	projects/zhidaoprefetch/es/es_api.py	/^def es_api_post(esconfig, url, text):$/;"	f
es_api_put	projects/zhidaoprefetch/es/es_api.py	/^def es_api_put(esconfig, url, text):$/;"	f
gen_es_id	projects/zhidaoprefetch/es/es_api.py	/^def gen_es_id(text):$/;"	f
getTheFile	projects/zhidaoprefetch/es/es_api.py	/^def getTheFile(filename):$/;"	f
get_esconfig	projects/zhidaoprefetch/es/es_api.py	/^def get_esconfig(config_option):$/;"	f
hashlib	projects/zhidaoprefetch/es/es_api.py	/^import hashlib$/;"	i
json	projects/zhidaoprefetch/es/es_api.py	/^import json$/;"	i
os	projects/zhidaoprefetch/es/es_api.py	/^import os$/;"	i
os	projects/zhidaoprefetch/es/es_api.py	/^import os.path$/;"	i
path	projects/zhidaoprefetch/es/es_api.py	/^import os.path$/;"	i
requests	projects/zhidaoprefetch/es/es_api.py	/^import requests$/;"	i
run_batch	projects/zhidaoprefetch/es/es_api.py	/^def run_batch(datasets, es_index, option, argv, esbulk_size=1000):$/;"	f
run_es_create_index	projects/zhidaoprefetch/es/es_api.py	/^def run_es_create_index(esconfig, es_index):$/;"	f
run_es_create_mapping	projects/zhidaoprefetch/es/es_api.py	/^def run_es_create_mapping(esconfig, es_index, es_type, mapping_json):$/;"	f
run_es_delete_query	projects/zhidaoprefetch/es/es_api.py	/^def run_es_delete_query(esconfig, es_index, es_type, es_search_url=None):$/;"	f
run_es_get_mapping	projects/zhidaoprefetch/es/es_api.py	/^def run_es_get_mapping(esconfig, es_index, es_type):$/;"	f
run_es_search	projects/zhidaoprefetch/es/es_api.py	/^def run_es_search(esconfig, es_index, es_type, params):$/;"	f
run_esbulk	projects/zhidaoprefetch/es/es_api.py	/^def run_esbulk(index_option, esconfig, es_index, es_type, filename_esdata, cnt=None, esbulk_size=1000):$/;"	f
run_esbulk_rows	projects/zhidaoprefetch/es/es_api.py	/^def run_esbulk_rows(esrows, index_option, esconfig, dataset):$/;"	f
sys	projects/zhidaoprefetch/es/es_api.py	/^import sys$/;"	i
test	projects/zhidaoprefetch/es/es_api.py	/^def test():$/;"	f
test_echo	projects/zhidaoprefetch/es/es_api.py	/^def test_echo(text):$/;"	f
test_upload_local	projects/zhidaoprefetch/es/es_api.py	/^def test_upload_local():$/;"	f
urllib	projects/zhidaoprefetch/es/es_api.py	/^import urllib$/;"	i
InstanceMgr	projects/zhidaoprefetch/hzlib/api_aws.py	/^class InstanceMgr:$/;"	c
__init__	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def __init__(self, config, region_id="tokyo"):$/;"	m	class:InstanceMgr
_execute_cmd	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def _execute_cmd(self, host, username, cmds, filename_pem):$/;"	m	class:InstanceMgr
boto3	projects/zhidaoprefetch/hzlib/api_aws.py	/^import boto3$/;"	i
codecs	projects/zhidaoprefetch/hzlib/api_aws.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/api_aws.py	/^import collections$/;"	i
config	projects/zhidaoprefetch/hzlib/api_aws.py	/^        config = json.load(f)$/;"	v
create	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def create(self, job_index, worker_num):$/;"	m	class:InstanceMgr
datetime	projects/zhidaoprefetch/hzlib/api_aws.py	/^import datetime$/;"	i
filename	projects/zhidaoprefetch/hzlib/api_aws.py	/^    filename = getTheFile("local\/config\/config_aws.json")$/;"	v
getTheFile	projects/zhidaoprefetch/hzlib/api_aws.py	/^def getTheFile(filename):$/;"	f
glob	projects/zhidaoprefetch/hzlib/api_aws.py	/^import glob$/;"	i
hashlib	projects/zhidaoprefetch/hzlib/api_aws.py	/^import hashlib$/;"	i
json	projects/zhidaoprefetch/hzlib/api_aws.py	/^import json$/;"	i
list	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def list(self, job_index):$/;"	m	class:InstanceMgr
logging	projects/zhidaoprefetch/hzlib/api_aws.py	/^import logging$/;"	i
main	projects/zhidaoprefetch/hzlib/api_aws.py	/^def main(config):$/;"	f
os	projects/zhidaoprefetch/hzlib/api_aws.py	/^import os$/;"	i
paramiko	projects/zhidaoprefetch/hzlib/api_aws.py	/^import paramiko$/;"	i
print_ssh	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def print_ssh(self, job_index, i):$/;"	m	class:InstanceMgr
re	projects/zhidaoprefetch/hzlib/api_aws.py	/^import re$/;"	i
run	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def run(self, job_index, worker_num, cmds_option, filename_pem):$/;"	m	class:InstanceMgr
select	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def select(self, job_index, state=None):$/;"	m	class:InstanceMgr
start	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def start(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
stop	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def stop(self, job_index, worker_num=None):$/;"	m	class:InstanceMgr
subprocess	projects/zhidaoprefetch/hzlib/api_aws.py	/^import subprocess$/;"	i
sys	projects/zhidaoprefetch/hzlib/api_aws.py	/^import sys$/;"	i
terminate	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def terminate(self, job_index):$/;"	m	class:InstanceMgr
time	projects/zhidaoprefetch/hzlib/api_aws.py	/^import time$/;"	i
upload	projects/zhidaoprefetch/hzlib/api_aws.py	/^    def upload(self, job_index, worker_num, cmds_option, ip=None):$/;"	m	class:InstanceMgr
Bunch	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TextClassifier	projects/zhidaoprefetch/hzlib/api_classify.py	/^class TextClassifier():$/;"	c
VarianceThreshold	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
__init__	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def __init__(self):$/;"	m	class:TextClassifier
_load_input	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def _load_input(self, dirinput):$/;"	m	class:TextClassifier
chi2	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/zhidaoprefetch/hzlib/api_classify.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/api_classify.py	/^import collections$/;"	i
corpora	projects/zhidaoprefetch/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn import datasets$/;"	i
datetime	projects/zhidaoprefetch/hzlib/api_classify.py	/^import datetime$/;"	i
gensim	projects/zhidaoprefetch/hzlib/api_classify.py	/^import gensim$/;"	i
glob	projects/zhidaoprefetch/hzlib/api_classify.py	/^import glob$/;"	i
hashlib	projects/zhidaoprefetch/hzlib/api_classify.py	/^import hashlib$/;"	i
items2sentences	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TextClassifier
jieba	projects/zhidaoprefetch/hzlib/api_classify.py	/^import jieba$/;"	i
json	projects/zhidaoprefetch/hzlib/api_classify.py	/^import json$/;"	i
metrics	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn import metrics$/;"	i
models	projects/zhidaoprefetch/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/zhidaoprefetch/hzlib/api_classify.py	/^import os$/;"	i
pprint	projects/zhidaoprefetch/hzlib/api_classify.py	/^from pprint import pprint$/;"	i
re	projects/zhidaoprefetch/hzlib/api_classify.py	/^import re$/;"	i
sentences2dict	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TextClassifier
sentences2texts	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TextClassifier
similarities	projects/zhidaoprefetch/hzlib/api_classify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/zhidaoprefetch/hzlib/api_classify.py	/^from sklearn import svm$/;"	i
sys	projects/zhidaoprefetch/hzlib/api_classify.py	/^import sys$/;"	i
train	projects/zhidaoprefetch/hzlib/api_classify.py	/^    def train(self, items):$/;"	m	class:TextClassifier
urllib	projects/zhidaoprefetch/hzlib/api_classify.py	/^import urllib$/;"	i
DownloadWrapper	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import collections$/;"	i
cut_text	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import datetime$/;"	i
detect_skip_groups	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def detect_skip_groups(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import difflib$/;"	i
download	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^def getTheFile(filename):$/;"	f
get_answer_filter_word	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def get_answer_filter_word(self, answer):$/;"	m	class:ZhidaoNlp
get_chat_label	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_question_baike	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^        import jieba$/;"	i
jieba	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import json$/;"	i
libfile	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import libfile$/;"	i
os	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import os$/;"	i
parse_query	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0707	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^from parsers.zhidao_parser import parse_search_json_v0707$/;"	i
prepare_query	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import random$/;"	i
re	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import re$/;"	i
requests	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^        import requests$/;"	i
rewrite_zhidao_query	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def rewrite_zhidao_query(self, question):$/;"	m	class:ZhidaoNlp
search_all	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None, keep_result=False):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0630	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def select_best_qapair_0630(self,query, search_result_json, question_len_max=30, answer_len_max=90, answer_len_min=2 ):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=100, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sim	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^    def sim(self, q1, q2):$/;"	m	class:ZhidaoFetch
sys	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import time$/;"	i
urllib	projects/zhidaoprefetch/hzlib/api_zhidao.py	/^import urllib$/;"	i
DownloadWrapper	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^            from downloader.downloader_wrapper import DownloadWrapper$/;"	i
ZhidaoFetch	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^class ZhidaoFetch():$/;"	c
ZhidaoNlp	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^class ZhidaoNlp():$/;"	c
__init__	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def __init__(self, config={}):$/;"	m	class:ZhidaoFetch
__init__	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def __init__(self, debug=False):$/;"	m	class:ZhidaoNlp
clean_question	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def clean_question(self, question):$/;"	m	class:ZhidaoNlp
clean_sentence	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def clean_sentence(self, sentence):$/;"	m	class:ZhidaoNlp
codecs	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import collections$/;"	i
cut_text	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def cut_text(self, text):$/;"	m	class:ZhidaoNlp
datetime	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import datetime$/;"	i
detect_skip_words	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def detect_skip_words(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
detect_skip_words_0618	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0618(self, text, skip_words=None):$/;"	m	class:ZhidaoNlp
detect_skip_words_0624	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def detect_skip_words_0624(self, text, skip_words=None, check_list=["skip_words_all"]):$/;"	m	class:ZhidaoNlp
difflib	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import difflib$/;"	i
download	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def download(self, query_url):$/;"	m	class:ZhidaoFetch
download_direct	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def download_direct(self, query_url):$/;"	m	class:ZhidaoFetch
filter_chat	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def filter_chat(self, q, a):$/;"	m	class:ZhidaoNlp
getTheFile	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^def getTheFile(filename):$/;"	f
get_chat_label	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def get_chat_label(self, q, a):$/;"	m	class:ZhidaoNlp
get_search_url_qword	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def get_search_url_qword(self,query_unicode, query_parser=0, page_number=0):$/;"	m	class:ZhidaoFetch
is_answer_bad	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def is_answer_bad(self, answer):$/;"	m	class:ZhidaoNlp
is_question_baike	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def is_question_baike(self, question, query_filter=2, debug_item={}):$/;"	m	class:ZhidaoNlp
is_question_baike_0617	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0617(self, question):$/;"	m	class:ZhidaoNlp
is_question_baike_0618	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def is_question_baike_0618(self, question, use_pos=True, debug_item=None):$/;"	m	class:ZhidaoNlp
jieba	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^        import jieba$/;"	i
jieba	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
json	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import json$/;"	i
libfile	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import libfile$/;"	i
os	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import os$/;"	i
parse_query	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def parse_query(self,query_unicode, query_parser=0):$/;"	m	class:ZhidaoFetch
parse_search_json_v0615	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^from parsers.zhidao_parser import parse_search_json_v0615$/;"	i
prepare_query	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def prepare_query(self, query, query_filter, query_parser, use_skip_words=True, page_number=0, debug_item=None):$/;"	m	class:ZhidaoFetch
pseg	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^        import jieba.posseg as pseg$/;"	i
random	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import random$/;"	i
re	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import re$/;"	i
requests	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^        import requests$/;"	i
search_all	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def search_all(self, query, query_filter=0, query_parser=0, limit=10):$/;"	m	class:ZhidaoFetch
search_baike_best	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def search_baike_best(self,query, query_filter=2, query_parser=0, debug_item=None):$/;"	m	class:ZhidaoFetch
search_chat_best	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def search_chat_best(self,query, query_filter=2, query_parser=0):$/;"	m	class:ZhidaoFetch
search_chat_top_n	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def search_chat_top_n(self,query,num_answers_needed=3,query_filter=2, query_parser=0, select_best=True):$/;"	m	class:ZhidaoFetch
select_best_qapair_0616	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0616(self,search_result_json):$/;"	m	class:ZhidaoFetch
select_best_qapair_0617	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def select_best_qapair_0617(self,query, search_result_json):$/;"	m	class:ZhidaoFetch
select_qapair_0624	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def select_qapair_0624(self, query, search_result_json, result_limit=3, answer_len_limit=40, question_len_limit=30, question_match_limit=0.3):$/;"	m	class:ZhidaoNlp
select_top_n_chat_0621	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0621(self, query, search_result_json, num_answers_needed):$/;"	m	class:ZhidaoFetch
select_top_n_chat_0622	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^    def select_top_n_chat_0622(self, query, search_result_json, result_limit=3, answer_len_limit=30, question_len_limit=20, question_match_limit=0.4):$/;"	m	class:ZhidaoFetch
sys	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import time$/;"	i
urllib	projects/zhidaoprefetch/hzlib/api_zhidao_0627.py	/^import urllib$/;"	i
json	projects/zhidaoprefetch/hzlib/eval_classify.py	/^import json$/;"	i
libdata	projects/zhidaoprefetch/hzlib/eval_classify.py	/^import libdata$/;"	i
nose	projects/zhidaoprefetch/hzlib/eval_classify.py	/^import nose$/;"	i
test_good_answer	projects/zhidaoprefetch/hzlib/eval_classify.py	/^def test_good_answer():$/;"	f
Bunch	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.datasets.base import Bunch$/;"	i
ExtraTreesClassifier	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.ensemble import ExtraTreesClassifier$/;"	i
GradientBoostingClassifier	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.ensemble import GradientBoostingClassifier$/;"	i
Imputer	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.preprocessing import Imputer$/;"	i
KNeighborsClassifier	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.neighbors import KNeighborsClassifier$/;"	i
LinearSVC	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.svm import LinearSVC$/;"	i
Pipeline	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.pipeline import Pipeline$/;"	i
SGDClassifier	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.linear_model import SGDClassifier$/;"	i
SelectFromModel	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectFromModel$/;"	i
SelectKBest	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.feature_selection import SelectKBest$/;"	i
StandardScaler	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.preprocessing import StandardScaler$/;"	i
TopicClassifier	projects/zhidaoprefetch/hzlib/libclassify.py	/^class TopicClassifier():$/;"	c
VarianceThreshold	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.feature_selection import VarianceThreshold$/;"	i
chi2	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn.feature_selection import chi2$/;"	i
codecs	projects/zhidaoprefetch/hzlib/libclassify.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/libclassify.py	/^import collections$/;"	i
corpora	projects/zhidaoprefetch/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
cross_validation	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn import cross_validation$/;"	i
datasets	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn import datasets$/;"	i
datetime	projects/zhidaoprefetch/hzlib/libclassify.py	/^import datetime$/;"	i
file2items	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def file2items(self, filepath):$/;"	m	class:TopicClassifier
gcounter	projects/zhidaoprefetch/hzlib/libclassify.py	/^gcounter = collections.Counter()$/;"	v
gensim	projects/zhidaoprefetch/hzlib/libclassify.py	/^import gensim$/;"	i
getLocalFile	projects/zhidaoprefetch/hzlib/libclassify.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/zhidaoprefetch/hzlib/libclassify.py	/^def getTheFile(filename):$/;"	f
glob	projects/zhidaoprefetch/hzlib/libclassify.py	/^import glob$/;"	i
hashlib	projects/zhidaoprefetch/hzlib/libclassify.py	/^import hashlib$/;"	i
is_question_baike	projects/zhidaoprefetch/hzlib/libclassify.py	/^def is_question_baike(question):$/;"	f
items2sentences	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def items2sentences(self, items, cat=None):$/;"	m	class:TopicClassifier
jieba	projects/zhidaoprefetch/hzlib/libclassify.py	/^import jieba$/;"	i
json	projects/zhidaoprefetch/hzlib/libclassify.py	/^import json$/;"	i
libfile	projects/zhidaoprefetch/hzlib/libclassify.py	/^    import libfile$/;"	i
main	projects/zhidaoprefetch/hzlib/libclassify.py	/^def main():$/;"	f
metrics	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn import metrics$/;"	i
models	projects/zhidaoprefetch/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
os	projects/zhidaoprefetch/hzlib/libclassify.py	/^import os$/;"	i
pickle	projects/zhidaoprefetch/hzlib/libclassify.py	/^import pickle$/;"	i
pprint	projects/zhidaoprefetch/hzlib/libclassify.py	/^from pprint import pprint$/;"	i
re	projects/zhidaoprefetch/hzlib/libclassify.py	/^import re$/;"	i
sentences2dict	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def sentences2dict(self, sentences):$/;"	m	class:TopicClassifier
sentences2texts	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def sentences2texts(self, sentences):$/;"	m	class:TopicClassifier
similarities	projects/zhidaoprefetch/hzlib/libclassify.py	/^from gensim import corpora, models, similarities$/;"	i
svm	projects/zhidaoprefetch/hzlib/libclassify.py	/^from sklearn import svm$/;"	i
sys	projects/zhidaoprefetch/hzlib/libclassify.py	/^import sys$/;"	i
test_is_question_baike	projects/zhidaoprefetch/hzlib/libclassify.py	/^def test_is_question_baike():$/;"	f
topic	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def topic(self, items, topn=100):$/;"	m	class:TopicClassifier
train	projects/zhidaoprefetch/hzlib/libclassify.py	/^    def train(self, items):$/;"	m	class:TopicClassifier
urllib	projects/zhidaoprefetch/hzlib/libclassify.py	/^import urllib$/;"	i
Enum	projects/zhidaoprefetch/hzlib/libdata.py	/^class Enum(set):$/;"	c
__getattr__	projects/zhidaoprefetch/hzlib/libdata.py	/^    def __getattr__(self, name):$/;"	m	class:Enum	file:
any2utf8	projects/zhidaoprefetch/hzlib/libdata.py	/^def any2utf8(data):$/;"	f
codecs	projects/zhidaoprefetch/hzlib/libdata.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/libdata.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/hzlib/libdata.py	/^import datetime$/;"	i
eval_f1	projects/zhidaoprefetch/hzlib/libdata.py	/^def eval_f1(target, predicted, target_names):$/;"	f
eval_fn	projects/zhidaoprefetch/hzlib/libdata.py	/^def eval_fn(tests, target_names, fn_classify, api_obj=None):$/;"	f
extract_zh	projects/zhidaoprefetch/hzlib/libdata.py	/^def extract_zh(text):$/;"	f
items2sample	projects/zhidaoprefetch/hzlib/libdata.py	/^def items2sample(data, limit=10):$/;"	f
json	projects/zhidaoprefetch/hzlib/libdata.py	/^import json$/;"	i
json_update_by_copy	projects/zhidaoprefetch/hzlib/libdata.py	/^def json_update_by_copy(json_to, json_from, list_field, flag_incremental):$/;"	f
jsonp	projects/zhidaoprefetch/hzlib/libdata.py	/^def jsonp(query, output):$/;"	f
metrics	projects/zhidaoprefetch/hzlib/libdata.py	/^    from sklearn import metrics$/;"	i
os	projects/zhidaoprefetch/hzlib/libdata.py	/^import os$/;"	i
print_json	projects/zhidaoprefetch/hzlib/libdata.py	/^def print_json(data):$/;"	f
random	projects/zhidaoprefetch/hzlib/libdata.py	/^import random$/;"	i
re	projects/zhidaoprefetch/hzlib/libdata.py	/^import re$/;"	i
requests	projects/zhidaoprefetch/hzlib/libdata.py	/^    import requests$/;"	i
slack_msg	projects/zhidaoprefetch/hzlib/libdata.py	/^def slack_msg(msg, channel_url = 'https:\/\/hooks.slack.com\/services\/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'):$/;"	f
strip_good_answer	projects/zhidaoprefetch/hzlib/libdata.py	/^def strip_good_answer(text):$/;"	f
sys	projects/zhidaoprefetch/hzlib/libdata.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/libdata.py	/^import time$/;"	i
codecs	projects/zhidaoprefetch/hzlib/libfile.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/libfile.py	/^import collections$/;"	i
defaultdict	projects/zhidaoprefetch/hzlib/libfile.py	/^from collections import defaultdict$/;"	i
file2list	projects/zhidaoprefetch/hzlib/libfile.py	/^def file2list(filename, encoding='utf-8'):$/;"	f
file2set	projects/zhidaoprefetch/hzlib/libfile.py	/^def file2set(filename, encoding='utf-8'):$/;"	f
genEsId	projects/zhidaoprefetch/hzlib/libfile.py	/^def genEsId(text):$/;"	f
glob	projects/zhidaoprefetch/hzlib/libfile.py	/^import glob$/;"	i
hashlib	projects/zhidaoprefetch/hzlib/libfile.py	/^import hashlib$/;"	i
items2file	projects/zhidaoprefetch/hzlib/libfile.py	/^def items2file(items, filename,encoding ='utf-8', modifier='w'):$/;"	f
json	projects/zhidaoprefetch/hzlib/libfile.py	/^import json$/;"	i
json2file	projects/zhidaoprefetch/hzlib/libfile.py	/^def json2file(data, filename,encoding ='utf-8'):$/;"	f
lines2file	projects/zhidaoprefetch/hzlib/libfile.py	/^def lines2file(lines, filename, encoding='utf-8'):$/;"	f
os	projects/zhidaoprefetch/hzlib/libfile.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/libfile.py	/^import re$/;"	i
readExcel	projects/zhidaoprefetch/hzlib/libfile.py	/^def readExcel(headers, filename, start_row=0, non_empty_col=-1, file_contents=None):$/;"	f
readExcel2	projects/zhidaoprefetch/hzlib/libfile.py	/^def readExcel2(filename, non_empty_col=0, file_contents=None):$/;"	f
read_file	projects/zhidaoprefetch/hzlib/libfile.py	/^def read_file(fname, jsn=False):$/;"	f
read_file_iter	projects/zhidaoprefetch/hzlib/libfile.py	/^def read_file_iter(fname, jsn=False):$/;"	f
sys	projects/zhidaoprefetch/hzlib/libfile.py	/^import sys$/;"	i
writeExcel	projects/zhidaoprefetch/hzlib/libfile.py	/^def writeExcel(items, keys, filename, page_size=60000):$/;"	f
write_file	projects/zhidaoprefetch/hzlib/libfile.py	/^def write_file(fname, lines, jsn=False):$/;"	f
xlrd	projects/zhidaoprefetch/hzlib/libfile.py	/^    import xlrd$/;"	i
xlwt	projects/zhidaoprefetch/hzlib/libfile.py	/^    import xlwt$/;"	i
SimpleNlp	projects/zhidaoprefetch/hzlib/libnlp.py	/^class SimpleNlp():$/;"	c
__init__	projects/zhidaoprefetch/hzlib/libnlp.py	/^    def __init__(self, debug=False):$/;"	m	class:SimpleNlp
codecs	projects/zhidaoprefetch/hzlib/libnlp.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/libnlp.py	/^import collections$/;"	i
cut_text	projects/zhidaoprefetch/hzlib/libnlp.py	/^    def cut_text(self, text):$/;"	m	class:SimpleNlp
datetime	projects/zhidaoprefetch/hzlib/libnlp.py	/^import datetime$/;"	i
detect_skip_groups	projects/zhidaoprefetch/hzlib/libnlp.py	/^    def detect_skip_groups(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
detect_skip_words	projects/zhidaoprefetch/hzlib/libnlp.py	/^    def detect_skip_words(self, text, skip_words_user=None, skip_words_groups=["skip_words_all"]):$/;"	m	class:SimpleNlp
getTheFile	projects/zhidaoprefetch/hzlib/libnlp.py	/^def getTheFile(filename):$/;"	f
jieba	projects/zhidaoprefetch/hzlib/libnlp.py	/^        import jieba$/;"	i
json	projects/zhidaoprefetch/hzlib/libnlp.py	/^import json$/;"	i
libfile	projects/zhidaoprefetch/hzlib/libnlp.py	/^import libfile$/;"	i
os	projects/zhidaoprefetch/hzlib/libnlp.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/libnlp.py	/^import re$/;"	i
sys	projects/zhidaoprefetch/hzlib/libnlp.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/libnlp.py	/^import time$/;"	i
codecs	projects/zhidaoprefetch/hzlib/libregex.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/libregex.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/hzlib/libregex.py	/^import datetime$/;"	i
getTheFile	projects/zhidaoprefetch/hzlib/libregex.py	/^def getTheFile(filename):$/;"	f
is_question_baike	projects/zhidaoprefetch/hzlib/libregex.py	/^def is_question_baike(question):$/;"	f
json	projects/zhidaoprefetch/hzlib/libregex.py	/^import json$/;"	i
libfile	projects/zhidaoprefetch/hzlib/libregex.py	/^    import libfile$/;"	i
main	projects/zhidaoprefetch/hzlib/libregex.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/hzlib/libregex.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/libregex.py	/^import re$/;"	i
sys	projects/zhidaoprefetch/hzlib/libregex.py	/^import sys$/;"	i
test_is_question_baike	projects/zhidaoprefetch/hzlib/libregex.py	/^def test_is_question_baike():$/;"	f
urllib	projects/zhidaoprefetch/hzlib/libregex.py	/^import urllib$/;"	i
TextClassifier	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^from api_classify import TextClassifier$/;"	i
ZhidaoFetch	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import datetime$/;"	i
json	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import json$/;"	i
libdata	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import libdata$/;"	i
libfile	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import libfile$/;"	i
main	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import re$/;"	i
show_help	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^def show_help():$/;"	f
sys	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import time$/;"	i
urllib	projects/zhidaoprefetch/hzlib/task_api_classify.py	/^import urllib$/;"	i
ZhidaoFetch	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoFetch$/;"	i
ZhidaoNlp	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^from api_zhidao import ZhidaoNlp$/;"	i
codecs	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import datetime$/;"	i
eval_filter	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^def eval_filter(query_filters=[1,3,2], flag_debug=False):$/;"	f
fn_query_filter	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^def fn_query_filter(line, api_obj, test_expect=None, test_data=None):$/;"	f
gcounter	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^gcounter = collections.Counter()$/;"	v
getLocalFile	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^def getTheFile(filename):$/;"	f
json	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import json$/;"	i
libdata	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import libdata$/;"	i
libfile	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import libfile$/;"	i
main	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import re$/;"	i
sys	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import sys$/;"	i
time	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import time$/;"	i
urllib	projects/zhidaoprefetch/hzlib/task_api_zhidao.py	/^import urllib$/;"	i
ZhidaoNlp	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^from api_zhidao import ZhidaoNlp$/;"	i
clean_skip_words_all	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def clean_skip_words_all():$/;"	f
codecs	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import datetime$/;"	i
eval_fn	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def eval_fn():$/;"	f
export_skip_words	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def export_skip_words():$/;"	f
false_negative	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^false_negative = []$/;"	v
false_positive	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^false_positive = []$/;"	v
fn_classify_0619	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def fn_classify_0619(line, api, test_expect=None, test_data=None):$/;"	f
gcounter	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^gcounter = collections.Counter()$/;"	v
getTheFile	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def getTheFile(filename):$/;"	f
glob	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import glob$/;"	i
json	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import json$/;"	i
learn_skip_words_0619	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def learn_skip_words_0619():$/;"	f
libdata	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import libdata$/;"	i
libfile	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import libfile$/;"	i
main	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import os$/;"	i
re	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import re$/;"	i
removeLen1Word	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def removeLen1Word(words):$/;"	f
sys	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import sys$/;"	i
test	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^def test(text):$/;"	f
time	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import time$/;"	i
true_negative	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^true_negative = []$/;"	v
true_positive	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^true_positive = []$/;"	v
urllib	projects/zhidaoprefetch/hzlib/task_learn_skip_words.py	/^import urllib$/;"	i
json	projects/zhidaoprefetch/hzlib/test_libdata.py	/^import json$/;"	i
libdata	projects/zhidaoprefetch/hzlib/test_libdata.py	/^import libdata$/;"	i
nose	projects/zhidaoprefetch/hzlib/test_libdata.py	/^import nose$/;"	i
set_ok	projects/zhidaoprefetch/hzlib/test_libdata.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/zhidaoprefetch/hzlib/test_libdata.py	/^def setup():  #模块的setup代码$/;"	f
teardown	projects/zhidaoprefetch/hzlib/test_libdata.py	/^def teardown(): #模块的teardown代码$/;"	f
test_strip_answer	projects/zhidaoprefetch/hzlib/test_libdata.py	/^def test_strip_answer():$/;"	f
with_setup	projects/zhidaoprefetch/hzlib/test_libdata.py	/^from nose import with_setup$/;"	i
json	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^import json$/;"	i
libdata	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^import libdata$/;"	i
libnlp	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^import libnlp$/;"	i
main	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def main():$/;"	f
nose	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^import nose$/;"	i
run_skip_words	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def run_skip_words(text):$/;"	f
set_ok	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def set_ok():  #只针对test_ok的setup代码$/;"	f
setup	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def setup():  #模块的setup代码$/;"	f
sys	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^import sys$/;"	i
teardown	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def teardown(): #模块的teardown代码$/;"	f
test_skip_words	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^def test_skip_words():$/;"	f
with_setup	projects/zhidaoprefetch/hzlib/test_libnlp.py	/^from nose import with_setup$/;"	i
getBrowserType	projects/zhidaoprefetch/hzlib/tests/examples/question1.html	/^            function getBrowserType() {$/;"	f
here	projects/zhidaoprefetch/hzlib/tests/examples/question1.html	/^<a id="here" name="here"><\/a><div class="line info f-light-gray mb-5 f-12">$/;"	a
logPV	projects/zhidaoprefetch/hzlib/tests/examples/question1.html	/^        function logPV(){$/;"	f
division	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
getTheFile	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^def getTheFile(filename):$/;"	f
json	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^import json$/;"	i
os	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^import os$/;"	i
print_function	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^from __future__ import print_function, division$/;"	i
sys	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^import sys$/;"	i
test_parse_title	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^def test_parse_title():$/;"	f
test_search	projects/zhidaoprefetch/hzlib/tests/test_api.py	/^def test_search():$/;"	f
Downloader	projects/zhidaoprefetch/parsers/qichacha2.py	/^from downloader import Downloader$/;"	i
QiParser	projects/zhidaoprefetch/parsers/qichacha2.py	/^from qiparser2 import QiParser$/;"	i
Qichacha	projects/zhidaoprefetch/parsers/qichacha2.py	/^class Qichacha(object):$/;"	c
__init__	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def __init__(self, config, batch_id=None, groups=None,  refresh=False, request=True, cache_only=False):$/;"	m	class:Qichacha
_crawl_company_detail_by_name_id	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def _crawl_company_detail_by_name_id(self, name, key_num):$/;"	m	class:Qichacha
_crawl_company_investment_single_page	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def _crawl_company_investment_single_page(self, name, key_num, page, max_page_num=None):$/;"	m	class:Qichacha
_parse_invests_inqueue	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def _parse_invests_inqueue(self,$/;"	m	class:Qichacha
_parse_shareholders_inqueue	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def _parse_shareholders_inqueue(self,$/;"	m	class:Qichacha
collections	projects/zhidaoprefetch/parsers/qichacha2.py	/^import collections$/;"	i
crawl_ancestors_company	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def crawl_ancestors_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_detail	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def crawl_company_detail(self, name, key_num=None, subcompany=True):$/;"	m	class:Qichacha
crawl_company_expand	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def crawl_company_expand(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
crawl_company_investment	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def crawl_company_investment(self, name, key_num):$/;"	m	class:Qichacha
crawl_descendant_company	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def crawl_descendant_company(self, name, key_num=None, limit=None):$/;"	m	class:Qichacha
division	projects/zhidaoprefetch/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
etree	projects/zhidaoprefetch/parsers/qichacha2.py	/^import lxml.etree$/;"	i
get_info_url	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def get_info_url(self, tab, key_num, name, page=None):$/;"	m	class:Qichacha
get_keyword_search_result_info	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def get_keyword_search_result_info(self, keyword, index, refresh=False):$/;"	m	class:Qichacha
html	projects/zhidaoprefetch/parsers/qichacha2.py	/^import lxml.html$/;"	i
input_name_output_id	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def input_name_output_id(self, name):$/;"	m	class:Qichacha
json	projects/zhidaoprefetch/parsers/qichacha2.py	/^import json$/;"	i
list_keyword_search	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def list_keyword_search(self, keyword_list, index_list, limit=None, refresh=False, skip_index_max=None):$/;"	m	class:Qichacha
list_keyword_search_onepass	projects/zhidaoprefetch/parsers/qichacha2.py	/^    def list_keyword_search_onepass(self, keyword, index, province, limit, metadata_dict, summary_dict_onepass, refresh):$/;"	m	class:Qichacha
lxml	projects/zhidaoprefetch/parsers/qichacha2.py	/^import lxml.etree$/;"	i
lxml	projects/zhidaoprefetch/parsers/qichacha2.py	/^import lxml.html$/;"	i
print_function	projects/zhidaoprefetch/parsers/qichacha2.py	/^from __future__ import print_function, division$/;"	i
re	projects/zhidaoprefetch/parsers/qichacha2.py	/^import re$/;"	i
traceback	projects/zhidaoprefetch/parsers/qichacha2.py	/^            import traceback$/;"	i
urllib	projects/zhidaoprefetch/parsers/qichacha2.py	/^import urllib$/;"	i
QiParser	projects/zhidaoprefetch/parsers/qiparser2.py	/^class QiParser(object):$/;"	c
__init__	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def __init__(self):$/;"	m	class:QiParser
division	projects/zhidaoprefetch/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
parse_basic_info	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_basic_info(self, html):$/;"	m	class:QiParser
parse_company_investment	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_company_investment(self, tree):$/;"	m	class:QiParser
parse_detail	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_detail(self, tree):$/;"	m	class:QiParser
parse_massive_info	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_massive_info(self, html):$/;"	m	class:QiParser
parse_search_result	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_search_result(self, tree):$/;"	m	class:QiParser
parse_search_result_info	projects/zhidaoprefetch/parsers/qiparser2.py	/^    def parse_search_result_info(self, tree):$/;"	m	class:QiParser
print_function	projects/zhidaoprefetch/parsers/qiparser2.py	/^from __future__ import print_function, division$/;"	i
re	projects/zhidaoprefetch/parsers/qiparser2.py	/^import re$/;"	i
string	projects/zhidaoprefetch/parsers/qiparser2.py	/^import string$/;"	i
URL_PATTERNS	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^URL_PATTERNS = [$/;"	v
clean_answers	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def clean_answers(answers):$/;"	f
division	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
generate_answer_json	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def generate_answer_json(ans_content):$/;"	f
generate_question_json	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def generate_question_json(qid, content):$/;"	f
html	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
json	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^import json$/;"	i
lxml	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^    import lxml.html$/;"	i
parse_answer_ids	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_answer_ids(content):$/;"	f
parse_asker_username	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_asker_username(content):$/;"	f
parse_page_title	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_page_title(content):$/;"	f
parse_q_content	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_q_content(content):$/;"	f
parse_q_time	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_q_time(content):$/;"	f
parse_search_get_best	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_search_get_best(content):$/;"	f
parse_search_json_v0615	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_search_json_v0615(content, start_result_index=0, use_recommend_only = False):$/;"	f
parse_search_json_v0707	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_search_json_v0707(content, word=None, start_result_index=0, use_recommend_only=False):$/;"	f
parse_search_result_item	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def parse_search_result_item(node):$/;"	f
print_function	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^from __future__ import print_function, division$/;"	i
re	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^import re$/;"	i
zhidao_search_parse_qids	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def zhidao_search_parse_qids(content):$/;"	f
zhidao_search_questions	projects/zhidaoprefetch/parsers/zhidao_parser.py	/^def zhidao_search_questions(content):$/;"	f
CONFIG	projects/zhidaoprefetch/zhidao/task_batch.py	/^CONFIG = {$/;"	v
CONFIG_T	projects/zhidaoprefetch/zhidao/task_batch.py	/^CONFIG_T = {$/;"	v
Cache	projects/zhidaoprefetch/zhidao/task_batch.py	/^from downloader.cache import Cache$/;"	i
DownloadWrapper	projects/zhidaoprefetch/zhidao/task_batch.py	/^from downloader.downloader_wrapper import DownloadWrapper$/;"	i
VERSION	projects/zhidaoprefetch/zhidao/task_batch.py	/^VERSION ='v20160526'$/;"	v
ZhidaoPrefetch	projects/zhidaoprefetch/zhidao/task_batch.py	/^class ZhidaoPrefetch(object):$/;"	c
__init__	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def __init__(self, config):$/;"	m	class:ZhidaoPrefetch
codecs	projects/zhidaoprefetch/zhidao/task_batch.py	/^import codecs$/;"	i
collections	projects/zhidaoprefetch/zhidao/task_batch.py	/^import collections$/;"	i
datetime	projects/zhidaoprefetch/zhidao/task_batch.py	/^import datetime$/;"	i
downloader	projects/zhidaoprefetch/zhidao/task_batch.py	/^import downloader$/;"	i
es	projects/zhidaoprefetch/zhidao/task_batch.py	/^import es$/;"	i
getLocalFile	projects/zhidaoprefetch/zhidao/task_batch.py	/^def getLocalFile(filename):$/;"	f
getTheFile	projects/zhidaoprefetch/zhidao/task_batch.py	/^def getTheFile(filename):$/;"	f
getWorkFile	projects/zhidaoprefetch/zhidao/task_batch.py	/^def getWorkFile(filename):$/;"	f
hzlib	projects/zhidaoprefetch/zhidao/task_batch.py	/^import hzlib$/;"	i
is_debug	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def is_debug(self):$/;"	m	class:ZhidaoPrefetch
jieba	projects/zhidaoprefetch/zhidao/task_batch.py	/^import jieba$/;"	i
libfile	projects/zhidaoprefetch/zhidao/task_batch.py	/^from hzlib import libfile$/;"	i
main	projects/zhidaoprefetch/zhidao/task_batch.py	/^def main():$/;"	f
os	projects/zhidaoprefetch/zhidao/task_batch.py	/^import os$/;"	i
run_gen_url_search_realtime	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_gen_url_search_realtime(self, filename):$/;"	m	class:ZhidaoPrefetch
run_get_best_search_realtime	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_get_best_search_realtime(self, filename):$/;"	m	class:ZhidaoPrefetch
run_query	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_query(self, query, max_page):$/;"	m	class:ZhidaoPrefetch
run_query_batch	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_query_batch(self, filename, limit):$/;"	m	class:ZhidaoPrefetch
run_query_entity	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_query_entity(self):$/;"	m	class:ZhidaoPrefetch
run_test_search_realtime	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def run_test_search_realtime(self, filename, limit):$/;"	m	class:ZhidaoPrefetch
search_zhidao_best	projects/zhidaoprefetch/zhidao/task_batch.py	/^from zhidao_fetch import search_zhidao_best$/;"	i
sys	projects/zhidaoprefetch/zhidao/task_batch.py	/^import sys$/;"	i
urllib	projects/zhidaoprefetch/zhidao/task_batch.py	/^import urllib$/;"	i
zhidao_answer	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def zhidao_answer(self, qid, rid):$/;"	m	class:ZhidaoPrefetch
zhidao_fetch	projects/zhidaoprefetch/zhidao/task_batch.py	/^import zhidao_fetch$/;"	i
zhidao_question	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def zhidao_question(self, qid):$/;"	m	class:ZhidaoPrefetch
zhidao_results	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def zhidao_results(self, qids):$/;"	m	class:ZhidaoPrefetch
zhidao_search	projects/zhidaoprefetch/zhidao/task_batch.py	/^    def zhidao_search(self, query, page_number=None, start_result_index=0):$/;"	m	class:ZhidaoPrefetch
get_question_dict	projects/zuoyebang/zyb.py	/^def get_question_dict(dom):$/;"	f
html	projects/zuoyebang/zyb.py	/^import lxml.html$/;"	i
json	projects/zuoyebang/zyb.py	/^import json$/;"	i
lxml	projects/zuoyebang/zyb.py	/^import lxml.html$/;"	i
os	projects/zuoyebang/zyb.py	/^import os$/;"	i
parse_q_id	projects/zuoyebang/zyb.py	/^def parse_q_id(url):$/;"	f
parse_question	projects/zuoyebang/zyb.py	/^def parse_question(dom):$/;"	f
parse_zuoyebang	projects/zuoyebang/zyb.py	/^def parse_zuoyebang(content):$/;"	f
re	projects/zuoyebang/zyb.py	/^import re$/;"	i
requests	projects/zuoyebang/zyb.py	/^import requests$/;"	i
sys	projects/zuoyebang/zyb.py	/^import sys$/;"	i
time	projects/zuoyebang/zyb.py	/^import time$/;"	i
Future	tests/semaphore_asyn.py	/^from tornado.concurrent import Future$/;"	i
IOLoop	tests/semaphore_asyn.py	/^from tornado.ioloop import IOLoop$/;"	i
MainHandler	tests/semaphore_asyn.py	/^class MainHandler(tornado.web.RequestHandler):$/;"	c
Queue	tests/semaphore_asyn.py	/^from tornado.queues import Queue$/;"	i
Semaphore	tests/semaphore_asyn.py	/^from tornado.locks import Semaphore$/;"	i
deque	tests/semaphore_asyn.py	/^from collections import deque$/;"	i
division	tests/semaphore_asyn.py	/^from __future__ import print_function, division$/;"	i
futures_q	tests/semaphore_asyn.py	/^futures_q = deque([Future() for _ in range(3)])$/;"	v
gen	tests/semaphore_asyn.py	/^from tornado import gen$/;"	i
get	tests/semaphore_asyn.py	/^    def get(self):$/;"	m	class:MainHandler
get_other	tests/semaphore_asyn.py	/^def get_other(worker_id, ret):$/;"	f
make_app	tests/semaphore_asyn.py	/^def make_app():$/;"	f
print_function	tests/semaphore_asyn.py	/^from __future__ import print_function, division$/;"	i
runner	tests/semaphore_asyn.py	/^def runner(result):$/;"	f
sem	tests/semaphore_asyn.py	/^sem = Semaphore(10)$/;"	v
simulator	tests/semaphore_asyn.py	/^def simulator(futures):$/;"	f
time	tests/semaphore_asyn.py	/^import time$/;"	i
tornado	tests/semaphore_asyn.py	/^import tornado.web$/;"	i
use_some_resource	tests/semaphore_asyn.py	/^def use_some_resource(worker_id, ret):$/;"	f
web	tests/semaphore_asyn.py	/^import tornado.web$/;"	i
worker	tests/semaphore_asyn.py	/^def worker(worker_id, ret):$/;"	f
add_func	tests/test_gevent_signal.py	/^def add_func(x):$/;"	f
blocking_callback	tests/test_gevent_signal.py	/^def blocking_callback():$/;"	f
blocking_callback_v2	tests/test_gevent_signal.py	/^def blocking_callback_v2():$/;"	f
callback	tests/test_gevent_signal.py	/^def callback(green):$/;"	f
callback_v2	tests/test_gevent_signal.py	/^def callback_v2(green):$/;"	f
catch_signal	tests/test_gevent_signal.py	/^def catch_signal():$/;"	f
division	tests/test_gevent_signal.py	/^from __future__ import print_function, division$/;"	i
gevent	tests/test_gevent_signal.py	/^import gevent$/;"	i
inner	tests/test_gevent_signal.py	/^  def inner(*args, **kwargs):$/;"	f	function:patch_greenlet
monkey	tests/test_gevent_signal.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
patch_all	tests/test_gevent_signal.py	/^from gevent import monkey; monkey.patch_all()$/;"	i
patch_greenlet	tests/test_gevent_signal.py	/^def patch_greenlet(func):$/;"	f
print_function	tests/test_gevent_signal.py	/^from __future__ import print_function, division$/;"	i
signal	tests/test_gevent_signal.py	/^from gevent import signal$/;"	i
signal_handler	tests/test_gevent_signal.py	/^def signal_handler(*_):$/;"	f
time	tests/test_gevent_signal.py	/^import time$/;"	i
Schedule	tests/test_signal.py	/^class Schedule(object):$/;"	c
__init__	tests/test_signal.py	/^    def __init__(self, num):$/;"	m	class:Schedule
division	tests/test_signal.py	/^from __future__ import print_function, division$/;"	i
init	tests/test_signal.py	/^def init(schedule):$/;"	f
instance	tests/test_signal.py	/^    def instance(cls, *args):$/;"	m	class:Schedule
print_function	tests/test_signal.py	/^from __future__ import print_function, division$/;"	i
schedule	tests/test_signal.py	/^schedule = Schedule.instance(5)$/;"	v
signal	tests/test_signal.py	/^from gevent import signal$/;"	i
signal_handler	tests/test_signal.py	/^def signal_handler(signum, frame):$/;"	f
stop	tests/test_signal.py	/^    def stop(self, signum=15, frame=None):$/;"	m	class:Schedule
time	tests/test_signal.py	/^import time$/;"	i
division	tests/zhidao_cookie_search.py	/^from __future__ import print_function, division$/;"	i
hash	tests/zhidao_cookie_search.py	/^hash = lambda x: hashlib.md5(x).hexdigest()$/;"	v
hashlib	tests/zhidao_cookie_search.py	/^import hashlib$/;"	i
print_function	tests/zhidao_cookie_search.py	/^from __future__ import print_function, division$/;"	i
r1	tests/zhidao_cookie_search.py	/^    r1 = hash(i)$/;"	v
r2	tests/zhidao_cookie_search.py	/^    r2 = hash(r1)$/;"	v
r3	tests/zhidao_cookie_search.py	/^    r3 = hash(r2)$/;"	v
r4	tests/zhidao_cookie_search.py	/^    r4 = hash(r3)$/;"	v
r5	tests/zhidao_cookie_search.py	/^    r5 = hash(r4)$/;"	v
source	tests/zhidao_cookie_search.py	/^source = [$/;"	v
target	tests/zhidao_cookie_search.py	/^target = '6859ce5aaf00fb00387e6434e4fcc925'$/;"	v
target	tests/zhidao_cookie_search.py	/^target = 'f4fa68ef6541217a317954f8e5a83b09'$/;"	v
